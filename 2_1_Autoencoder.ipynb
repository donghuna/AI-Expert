{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/2_1_Autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "   # Autoencoders\n",
        "\n",
        "## Overview\n",
        "\n",
        "이번 실습은 autoencoder를 설계하고, 실제로 학습해보는 실습입니다.\n",
        "\n",
        "시작하기에 앞서, 실습에 필요한 packages를 import 하겠습니다."
      ],
      "metadata": {
        "id": "j5VcMN25U08p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "from torchvision.utils import save_image, make_grid\n",
        "\n",
        "DEVICE = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "vuX8dBvnU1T7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST 데이터셋 로드\n",
        "\n",
        "Fashion MNIST 데이터셋은 28x28 크기의 그레이 스케일 이미지로 구성된 데이터셋입니다.  \n",
        "총 10개의 클래스를 합쳐 60,000개의 train set, 10,000개의 test set으로 구성되어있습니다.  \n",
        "이번 실습은 Fashion MNIST 이미지 데이터를 latent vector로 압축하는 encoder와, 다시 이미지로 복구하는 decoder를 구현해보는 실습입니다.  \n",
        "\n",
        "실습에 앞서 필요한 데이터를 로드하도록 하겠습니다.\n",
        "아래 코드는 Fashion MNIST 데이터를 로드하는 코드입니다."
      ],
      "metadata": {
        "id": "HIf_RDR2U7np"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import FashionMNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "dataset_path = '~/datasets'\n",
        "batch_size = 100\n",
        "test_batch_size = 1000\n",
        "\n",
        "fashionmnist_transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "\n",
        "train_dataset = FashionMNIST(dataset_path, transform=fashionmnist_transform, train=True, download=True)\n",
        "test_dataset  = FashionMNIST(dataset_path, transform=fashionmnist_transform, train=False, download=True)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader  = DataLoader(dataset=test_dataset,  batch_size=test_batch_size, shuffle=False, **kwargs)"
      ],
      "metadata": {
        "id": "6HrdKZd8VB3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic autoencoder\n",
        "\n",
        "다음 코드는 Fashion MNIST 데이터를 압축/복원하는 auto encoder 코드입니다.\n",
        "\n",
        "### Implementation: auto encoder 구현\n",
        "* input / latent / output  \n",
        "  * input shape: batch x 28 x 28  \n",
        "  * latent shape: batch x 64  \n",
        "  * output shape: batch x 28 x 28  \n",
        "* call  \n",
        "  * input $x$ → latent $z$ → output $\\hat{x}$\n",
        "\n",
        "Example:\n",
        "* Encoder  \n",
        "  reshape: [batch, 1, 28, 28] → [batch, 784]  \n",
        "  fc: [batch, 784] → [batch, latent_dim(64)]  \n",
        "\n",
        "* Decoder  \n",
        "  fc: [batch, latent_dim(64)] → [batch, 784]  \n",
        "  reshape: [batch, 784] → [batch, 1, 28, 28] \\\\\n",
        "  sigmoid: value_range: (-∞,∞) → (0, 1)    \n",
        "\n"
      ],
      "metadata": {
        "id": "NGmZaNXsVR_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = 784\n",
        "height = 28\n",
        "width = 28\n",
        "channel = 1\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "  def __init__(self, latent_dim=64):\n",
        "    super().__init__()\n",
        "\n",
        "    ############### ToDo ###############\n",
        "    self.encoder = nn.Sequential(\n",
        "\n",
        "    )\n",
        "    self.decoder = nn.Sequential(\n",
        "\n",
        "    )\n",
        "    #####################################\n",
        "\n",
        "  def encode(self, x):\n",
        "    x = x.reshape((-1, input_dim))\n",
        "    z = self.encoder(x)\n",
        "    return z\n",
        "\n",
        "  def decode(self, z):\n",
        "    x_hat = self.decoder(z)\n",
        "    x_hat = x_hat.reshape((-1, channel, height, width))\n",
        "    return x_hat\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = self.encode(x)\n",
        "    x_hat = self.decode(z)\n",
        "    return x_hat, z"
      ],
      "metadata": {
        "id": "VwAmuqqZVQWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 64\n",
        "model = AutoEncoder(latent_dim).to(DEVICE)"
      ],
      "metadata": {
        "id": "ZpB6bycwXc18"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음 코드는 auto encoder를 학습하기 위한 코드입니다."
      ],
      "metadata": {
        "id": "mYvoWX5HW6uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "\n",
        "lr = 1e-2\n",
        "optimizer = Adam(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "WSnINghsXZA4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    overall_loss = 0\n",
        "    for batch_idx, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        x_hat, z = model(x)\n",
        "        ############### ToDo ###############\n",
        "        loss =\n",
        "        ####################################\n",
        "\n",
        "        overall_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"\\tEpoch\", epoch + 1, \"complete!\", \"\\tAverage Loss: \", overall_loss / (batch_idx*batch_size))\n",
        "\n",
        "print(\"Finish!!\")"
      ],
      "metadata": {
        "id": "S3N--imfWzBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드는 학습된 auto encoder 모델로 reconstruction을 진행하는 코드입니다."
      ],
      "metadata": {
        "id": "cvzYczsRaK66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    x_test, y_test = next(iter(test_loader))\n",
        "    x_hat_test, z_test = model(x_test.to(DEVICE))\n",
        "    x_hat_test = x_hat_test.cpu()\n",
        "    z_test = z_test.cpu()\n",
        "\n",
        "n = 10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  # display original\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(x_test[i].permute(1, 2, 0))\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  # display reconstruction\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(x_hat_test[i].permute(1, 2, 0))\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EVL9ox1haMTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# T-SNE\n",
        "\n",
        "고차원의 복잡한 데이터들을 직관적으로 이해하기 어렵기 때문에, 일반적으로 낮은 차원으로 변환하여 시각화를 하여 분석을 하게 됩니다.  \n",
        "t-SNE(t-Distributed Stochastic Neighbor Embedding)는 대표적인 차원 축소(dimensionality reduction) 기법입니다.  \n",
        "아래 코드는 t-SNE를 이용하여 auto encoder로 얻어낸 embedding들을 시각화하는 코드입니다."
      ],
      "metadata": {
        "id": "FOoOKcW_XqjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "def plot_tsne(inputs, labels):\n",
        "  n_samples = len(labels)\n",
        "  tsne = TSNE(n_components=2, perplexity=10, n_iter=300)\n",
        "  tsne_features = tsne.fit_transform(inputs[:n_samples].reshape(n_samples, -1))\n",
        "  df = pd.DataFrame({\n",
        "      'x': tsne_features[:,0],\n",
        "      'y': tsne_features[:,1],\n",
        "      'label': labels[:n_samples]\n",
        "  })\n",
        "\n",
        "  sns.scatterplot(data=df, x='x', y='y', hue='label', palette=\"deep\")\n",
        "\n",
        "def plot(inputs, labels):\n",
        "  n_samples = len(labels)\n",
        "\n",
        "  df = pd.DataFrame({\n",
        "      'x': inputs[:,0],\n",
        "      'y': inputs[:,1],\n",
        "      'label': labels[:n_samples]\n",
        "  })\n",
        "\n",
        "  sns.scatterplot(data=df, x='x', y='y', hue='label', palette=\"deep\")"
      ],
      "metadata": {
        "id": "OHZunOqhXsIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(z_test, y_test)"
      ],
      "metadata": {
        "id": "bKoSfyulXuP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tsne(x_test, y_test)"
      ],
      "metadata": {
        "id": "BrQqId5qYatw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    z_random = torch.randn(test_batch_size, latent_dim).to(DEVICE)\n",
        "    x_hat_gen = model.decode(z_random)\n",
        "    x_hat_gen = x_hat_gen.cpu()\n",
        "\n",
        "\n",
        "n = 10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(x_hat_gen[i].permute(1, 2, 0))\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)"
      ],
      "metadata": {
        "id": "B-9zKLNQb5SM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}