{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9pKkqEUr6sl2M9faZ1wgp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/TimeSformer-k400.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 환경설정"
      ],
      "metadata": {
        "id": "-JvTtKK027Ex"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2q3qhZsK0U4Z",
        "outputId": "5c5e1869-9b05-4637-c86f-b6c73f12ce4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (18.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.3)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->timm) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch->timm) (0.43.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->timm) (3.27.9)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->timm) (18.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: pytorchvideo in /usr/local/lib/python3.10/dist-packages (0.1.5)\n",
            "Requirement already satisfied: fvcore in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (0.1.5.post20221221)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (12.1.0)\n",
            "Requirement already satisfied: parameterized in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: iopath in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (0.1.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pytorchvideo) (3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (1.25.2)\n",
            "Requirement already satisfied: yacs>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (0.1.8)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (6.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (4.66.4)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (9.4.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fvcore->pytorchvideo) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from iopath->pytorchvideo) (4.12.2)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath->pytorchvideo) (2.8.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision\n",
        "!pip install timm\n",
        "!pip install pytorchvideo\n",
        "# !pip install torchvision==0.15.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 임포트"
      ],
      "metadata": {
        "id": "axOUY-0W2-uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from pytorchvideo.data import Kinetics\n",
        "from pytorchvideo.transforms import (\n",
        "    ApplyTransformToKey,\n",
        "    RandomShortSideScale,\n",
        "    Normalize,\n",
        ")\n",
        "from torchvision.transforms import (\n",
        "    RandomCrop,\n",
        "    RandomHorizontalFlip\n",
        ")\n",
        "# from pytorchvideo.models.hub import timesformer\n",
        "import timm"
      ],
      "metadata": {
        "id": "04gNxNDI05XP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 로드 및 전처리"
      ],
      "metadata": {
        "id": "VbpRYFZr3BbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_kinetics_dataloader(data_path, video_path_prefix, batch_size, num_workers=4):\n",
        "    transform = transforms.Compose([\n",
        "        ApplyTransformToKey(\n",
        "            key=\"video\",\n",
        "            transform=transforms.Compose([\n",
        "                RandomShortSideScale(min_size=256, max_size=320),\n",
        "                RandomCrop(224),\n",
        "                RandomHorizontalFlip(),\n",
        "                Normalize(\n",
        "                    mean=[0.45, 0.45, 0.45],\n",
        "                    std=[0.225, 0.225, 0.225]\n",
        "                )\n",
        "            ])\n",
        "        )\n",
        "    ])\n",
        "\n",
        "    dataset = Kinetics(\n",
        "        data_path=data_path,\n",
        "        clip_sampler=\"uniform\",\n",
        "        video_sampler=torch.utils.data.RandomSampler,\n",
        "        transform=transform,\n",
        "        video_path_prefix=video_path_prefix,\n",
        "        decode_audio=False\n",
        "    )\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=num_workers,\n",
        "        pin_memory=True\n",
        "    )\n",
        "    return dataloader\n",
        "\n",
        "train_dataloader = make_kinetics_dataloader('path/to/kinetics/train', 'path/to/kinetics/train', batch_size=8)\n",
        "val_dataloader = make_kinetics_dataloader('path/to/kinetics/val', 'path/to/kinetics/val', batch_size=8)\n"
      ],
      "metadata": {
        "id": "1EOxFNQk1V9H",
        "outputId": "c8324c45-050d-43ae-d2ec-cdc90d5f18da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "path/to/kinetics/train not found.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-9707a0791648>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_kinetics_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/kinetics/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'path/to/kinetics/train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0mval_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_kinetics_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'path/to/kinetics/val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'path/to/kinetics/val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-9707a0791648>\u001b[0m in \u001b[0;36mmake_kinetics_dataloader\u001b[0;34m(data_path, video_path_prefix, batch_size, num_workers)\u001b[0m\n\u001b[1;32m     15\u001b[0m     ])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     dataset = Kinetics(\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mclip_sampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"uniform\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/kinetics.py\u001b[0m in \u001b[0;36mKinetics\u001b[0;34m(data_path, clip_sampler, video_sampler, transform, video_path_prefix, decode_audio, decoder)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PYTORCHVIDEO.dataset.Kinetics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     return labeled_video_dataset(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mclip_sampler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/labeled_video_dataset.py\u001b[0m in \u001b[0;36mlabeled_video_dataset\u001b[0;34m(data_path, clip_sampler, video_sampler, transform, video_path_prefix, decode_audio, decoder)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \"\"\"\n\u001b[0;32m--> 286\u001b[0;31m     \u001b[0mlabeled_video_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabeledVideoPaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0mlabeled_video_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_path_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     dataset = LabeledVideoDataset(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorchvideo/data/labeled_video_paths.py\u001b[0m in \u001b[0;36mfrom_path\u001b[0;34m(cls, data_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mLabeledVideoPaths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{data_path} not found.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: path/to/kinetics/train not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Kinetics?"
      ],
      "metadata": {
        "id": "dMqsZlM4202z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, TimesformerForVideoClassification\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "video = np.random.randn(8, 3, 224, 224) # 8개 프레임은 3채널(RGB)과 224x224\n",
        "video = (video - video.min()) / (video.max() - video.min())  # Normalize to [0, 1]\n",
        "video = list(video)  # 리스트로 변환\n",
        "\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\") # 입력 비디오를 모델이 처리할 수 있는 텐서로 변환하는 processor\n",
        "model = TimesformerForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "\n",
        "inputs = processor(video, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "  logits = outputs.logits\n",
        "\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])\n"
      ],
      "metadata": {
        "id": "Gm4pVZQI3NcG",
        "outputId": "0c988f8b-69c2-4e6b-bb97-6e34dcef8cc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "It looks like you are trying to rescale already rescaled images. If the input images have pixel values between 0 and 1, set `do_rescale=False` to avoid rescaling them again.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/feature_extraction_utils.py:141: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  return torch.tensor(value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: singing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kinetics-400 데이터셋의 예제 비디오 다운로드  \n"
      ],
      "metadata": {
        "id": "apo8YO-8EBhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf archery*\n",
        "\n",
        "# !wget https://github.com/pytorch/vision/blob/master/test/assets/videos/R6llTwEh07w.mp4 -O archery-raw.mp4\n",
        "!wget https://github.com/pytorch/vision/blob/master/test/assets/videos/SOX5yA1l24A.mp4 -O archery-raw.mp4\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "al6eGsnY4hdJ",
        "outputId": "6cb438d5-3fdc-4d36-e165-3f9715e00651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-14 10:09:35--  https://github.com/pytorch/vision/blob/master/test/assets/videos/SOX5yA1l24A.mp4\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/pytorch/vision/blob/main/test/assets/videos/SOX5yA1l24A.mp4 [following]\n",
            "--2024-06-14 10:09:35--  https://github.com/pytorch/vision/blob/main/test/assets/videos/SOX5yA1l24A.mp4\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘archery-raw.mp4’\n",
            "\n",
            "archery-raw.mp4         [  <=>               ] 272.21K  1016KB/s    in 0.3s    \n",
            "\n",
            "2024-06-14 10:09:36 (1016 KB/s) - ‘archery-raw.mp4’ saved [278746]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get remove -y ffmpeg\n",
        "\n",
        "# ffmpeg 3.4.2 다운로드\n",
        "!wget https://www.johnvansickle.com/ffmpeg/old-releases/ffmpeg-3.4.2-64bit-static.tar.xz\n",
        "\n",
        "# 압축 해제\n",
        "!tar -xJf ffmpeg-3.4.2-64bit-static.tar.xz\n",
        "\n",
        "# ffmpeg 3.4.2 설치\n",
        "!cp ffmpeg-3.4.2-64bit-static/ffmpeg /usr/bin/ffmpeg\n",
        "!cp ffmpeg-3.4.2-64bit-static/ffprobe /usr/bin/ffprobe\n",
        "\n",
        "# 설치 확인\n",
        "!ffmpeg -version"
      ],
      "metadata": {
        "id": "e4zsTg2ePTiY",
        "outputId": "151eb0b6-57ef-4fc5-e3bc-4207dbab3462",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package 'ffmpeg' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "--2024-06-14 10:19:50--  https://www.johnvansickle.com/ffmpeg/old-releases/ffmpeg-3.4.2-64bit-static.tar.xz\n",
            "Resolving www.johnvansickle.com (www.johnvansickle.com)... 107.180.57.212\n",
            "Connecting to www.johnvansickle.com (www.johnvansickle.com)|107.180.57.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17278680 (16M) [application/x-xz]\n",
            "Saving to: ‘ffmpeg-3.4.2-64bit-static.tar.xz.2’\n",
            "\n",
            "ffmpeg-3.4.2-64bit- 100%[===================>]  16.48M  73.4MB/s    in 0.2s    \n",
            "\n",
            "2024-06-14 10:19:51 (73.4 MB/s) - ‘ffmpeg-3.4.2-64bit-static.tar.xz.2’ saved [17278680/17278680]\n",
            "\n",
            "ffmpeg version 3.4.2-static https://johnvansickle.com/ffmpeg/  Copyright (c) 2000-2018 the FFmpeg developers\n",
            "built with gcc 6.3.0 (Debian 6.3.0-18) 20170516\n",
            "configuration: --enable-gpl --enable-version3 --enable-static --disable-debug --disable-ffplay --disable-indev=sndio --disable-outdev=sndio --cc=gcc-6 --enable-fontconfig --enable-frei0r --enable-gnutls --enable-gray --enable-libfribidi --enable-libass --enable-libfreetype --enable-libmp3lame --enable-libopencore-amrnb --enable-libopencore-amrwb --enable-libopenjpeg --enable-librubberband --enable-libsoxr --enable-libspeex --enable-libvorbis --enable-libopus --enable-libtheora --enable-libvidstab --enable-libvo-amrwbenc --enable-libvpx --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libzimg\n",
            "libavutil      55. 78.100 / 55. 78.100\n",
            "libavcodec     57.107.100 / 57.107.100\n",
            "libavformat    57. 83.100 / 57. 83.100\n",
            "libavdevice    57. 10.100 / 57. 10.100\n",
            "libavfilter     6.107.100 /  6.107.100\n",
            "libswscale      4.  8.100 /  4.  8.100\n",
            "libswresample   2.  9.100 /  2.  9.100\n",
            "libpostproc    54.  7.100 / 54.  7.100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!ffmpeg -i archery-raw.mp4\n",
        "!ffmpeg -i archery-raw.mp4 -c copy -movflags faststart archery-fixed.mp4\n",
        "# !ffmpeg -i archery-raw.mp4 -vcodec libx264 -acodec aac archery.mp4"
      ],
      "metadata": {
        "id": "yHJ5by3bLqR4",
        "outputId": "e8df0370-1d44-45c4-a27b-345800bbe7b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "archery-raw.mp4  ffmpeg-3.4.2-64bit-static.tar.xz  sample_data\n",
            "/bin/bash: line 1: ffmpeg: command not found\n",
            "/bin/bash: line 1: ffmpeg: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "VKrfkfYKL4jg",
        "outputId": "23ba12af-a804-4ba8-f825-5ec654e798bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "archery-raw.mp4  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from transformers import AutoImageProcessor, TimesformerForVideoClassification\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 비디오 파일을 로드하고 프레임을 추출\n",
        "def load_video(video_path):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    frame_count = 0\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        frame = cv2.resize(frame, (224, 224))\n",
        "        frames.append(frame)\n",
        "        frame_count += 1\n",
        "        if frame_count <= 2:  # 처음 2개의 프레임 출력\n",
        "            print(f\"Frame {frame_count} shape: {frame.shape}\")\n",
        "    cap.release()\n",
        "    print(f\"Total frames extracted: {len(frames)}\")\n",
        "    return frames"
      ],
      "metadata": {
        "id": "_lpuK62jDnDr"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 비디오 파일 존재 확인\n",
        "video_path = './archery-raw.mp4'\n",
        "if os.path.exists(video_path):\n",
        "    print(f\"{video_path} exists.\")\n",
        "else:\n",
        "    print(f\"{video_path} does not exist.\")\n",
        "\n",
        "frames = load_video(video_path)\n",
        "\n",
        "# 첫 8개의 프레임 사용\n",
        "video = frames[:8]\n",
        "\n",
        "print(f\"Video shape: {len(video)} frames\")\n",
        "print(f\"Each frame shape: {video[0].shape}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "R3xAqrjeFltC",
        "outputId": "95e0f21d-7b79-4c84-8910-c2672b2cf0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./archery-raw.mp4 exists.\n",
            "Total frames extracted: 0\n",
            "Video shape: 0 frames\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-a14a317442dd>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Video shape: {len(video)} frames\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Each frame shape: {video[0].shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 프로세서와 모델 로드\n",
        "processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "model = TimesformerForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "\n",
        "# 입력 데이터 전처리\n",
        "inputs = processor([video], return_tensors=\"pt\")\n",
        "\n",
        "# 모델 추론\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# 예측된 클래스 추출 및 출력\n",
        "predicted_class_idx = logits.argmax(-1).item()\n",
        "print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
      ],
      "metadata": {
        "id": "HE6A5vKnHsG1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}