{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/3_1_DCGAN_unconditional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Convolutional Generative Adversarial Network"
      ],
      "metadata": {
        "id": "4cN2n4y9dXKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "이번 실습에서는 DCGAN을 현하고, MNIST dataset을 이용하여 학습해보록 하겠습니다.\n",
        "\n",
        "2016년에 제안된 DCGAN(Deep Convolution GAN)은 가장 기본적인 GAN 구조 중 하나입니다.\n",
        "\n",
        "- 이 실습자료는 [GAN-Tutorial](https://github.com/Yangyangii/GAN-Tutorial)을 기반으로 작성되었습니다."
      ],
      "metadata": {
        "id": "U3F8NnYIdZZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup\n",
        "\n",
        "우선, DCGAN 구현을 위해 필요한 패키지들을 설치하고 import하도록 하겠습니다."
      ],
      "metadata": {
        "id": "k2AH1PlEdrN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os, sys\n",
        "\n",
        "from matplotlib.pyplot import imshow, imsave\n",
        "\n",
        "DEVICE = torch.device('cuda')"
      ],
      "metadata": {
        "id": "SKzf77HadbKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and prepare the dataset\n",
        "\n",
        "이번 실습에서 사용할 MNIST dataset을 다운로드하고, 로드하겠습니다."
      ],
      "metadata": {
        "id": "eK8enqDidzCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5],\n",
        "                                std=[0.5])]\n",
        ")\n",
        "\n",
        "mnist = datasets.MNIST(root='./data/', train=True, transform=transform, download=True)\n",
        "data_loader = DataLoader(dataset=mnist, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "hwizpnoDd0PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DCGAN 구현\n",
        "\n",
        "지금부터 DCGAN 모델을 구현하도록 하겠습니다."
      ],
      "metadata": {
        "id": "6kF1vrMUd-wP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Generator\n",
        "\n",
        "Convolutional Auto Encoder의 Decoder와 마찬가지로 transposed convolution을 활용하여, latent $z$로부터 MNIST dataset 이미지를 생성하는 Generator 모델을 만들어보겠습니다.\n",
        "\n",
        "실제 DCGAN의 Generator는 64x64 이미지를 생성하지만, 이번 실습에서는 MNIST dataset의 사이즈에 맞추어 100차원 latent vector $z$로부터 28x28 이미지를 생성해보도록 하겠습니다.\n",
        "\n",
        "모델의 구조는 다음과 같습니다.  \n",
        "\n",
        "1. **Input**: latent $z$, [batch, 100]  \n",
        "\n",
        "2. **FC**: [batch, 100] → [batch, 512x4x4=8192]\n",
        "3. **ReLU**\n",
        "4. **Reshape**: [batch, 512x4x4=8192] → [batch, 512, 4, 4]\n",
        "5. **ConvTranspose2d**: [batch, 512, 4, 4] → [batch, 256, 7, 7], kernel_size=3, stride=2 padding=1, bias=False\n",
        "6. **BatchNorm2d**: channel 256\n",
        "7. **ReLU**\n",
        "8. **ConvTranspose2d**: [batch, 256, 7, 7] → [batch, 128, 14, 14], kernel_size=4, stride=2, padding=1, bias=False\n",
        "9. **BatchNorm2d** : channel 128\n",
        "10. **ReLU**\n",
        "11. **ConvTranspose2d**: [batch, 128, 14, 14] → [batch, 1, 28, 28], kernel_size=4, stride=2, padding=1, bias=False\n",
        "12. **Tanh**\n",
        "\n",
        "\n",
        "Q. 왜 마지막 layer는 Tanh를 사용할까?\n"
      ],
      "metadata": {
        "id": "xRY44E5IeAKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Generator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=100):\n",
        "        super(Generator, self).__init__()\n",
        "        ################ ToDo ##################\n",
        "        self.fc = nn.Sequential(\n",
        "            # input : input size, output : 4x4x512\n",
        "\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            # input: 4x4, output: 7x7\n",
        "\n",
        "            # input: 7x7, output: 14x14\n",
        "\n",
        "            # input: 14x14, output: 28x28\n",
        "\n",
        "        )\n",
        "        #########################################\n",
        "\n",
        "    def forward(self, z):\n",
        "        x = z.view(z.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), 512, 4, 4)\n",
        "        x = self.conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "U_LCD0fMeI8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator().to(DEVICE)"
      ],
      "metadata": {
        "id": "mkekj_toJjGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아직 학습이 되지 않은 Generator를 이용하여 random sampling된 latent vector로부터 이미지를 생성해보겠습니다."
      ],
      "metadata": {
        "id": "f_jOfW52fbT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "G.eval()\n",
        "\n",
        "n_samples = 100\n",
        "\n",
        "with torch.no_grad():\n",
        "  z = torch.randn(n_samples, 100).to(DEVICE)\n",
        "  x_hat = G(z)\n",
        "\n",
        "img = make_grid(x_hat, nrow=10, normalize=True, value_range=(-1., 1.)).permute(1, 2, 0).cpu().data.numpy()\n",
        "imshow(img, cmap='gray')"
      ],
      "metadata": {
        "id": "P2x3UVgJffeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2, Discriminator\n",
        "\n",
        "Generator가 생성한 이미지의, real/fake 여부를 구분하는 Discriminator를 구현해보도록 하겠습니다.\n",
        "\n",
        "모델의 구조는 다음과 같습니다.  \n",
        "\n",
        "1. **Input**: image $x$, [batch, 28, 28, 1]  \n",
        "2. **Conv2d**: [batch, 1, 28, 28] → [batch, 512, 14, 14], kernel_size=3, stride=2, padding=1, bias=False\n",
        "3. **BatchNorm2d**\n",
        "4. **LeakyReLU**  \n",
        "5. **Conv2d**: [batch, 512, 14, 14] → [batch, 256, 7, 7], kernel_size=5\n",
        "6. **BatchNorm2d**\n",
        "7. **LeakyReLU**\n",
        "8. **Conv2d**: [batch, 256, 7, 7] → [batch, 128, 4, 4],\n",
        "9. **BatchNorm2d**\n",
        "10. **LeakyReLU**\n",
        "11. **AvgPool2d**\n",
        "12. **reshape**: [batch, 128, 4, 4] → [batch, 128x4x4=2048],\n",
        "13. **Linear**: [batch, 128x4x4=2048] → [batch, 1]\n",
        "14. **Sigmoid**\n",
        "  \n",
        "Q. 왜 마지막 layer는 sigmoid 일까?"
      ],
      "metadata": {
        "id": "r6njw3NHfuUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Discriminator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channel=1, num_classes=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "        ################ ToDo ##################\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            # input: 28x28, output: 14x14\n",
        "\n",
        "            # input: 14x14, output: 7x7\n",
        "\n",
        "            # input: 7x7, output: 4x4\n",
        "\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "            # input : 128, output : 1\n",
        "\n",
        "        )\n",
        "        ##########################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        y_ = self.conv(x)\n",
        "        y_ = y_.view(y_.size(0), -1)\n",
        "        y_ = self.fc(y_)\n",
        "        return y_"
      ],
      "metadata": {
        "id": "1IJilr8yfyOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator().to(DEVICE)"
      ],
      "metadata": {
        "id": "anraH21tLyqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Discriminator를 이용하여 앞에서 생성한 이미지에 대한 real/fake 여부를 판정해보겠습니다.\n",
        "\n",
        "Discriminator는 real image일 확률을 리턴합니다."
      ],
      "metadata": {
        "id": "z_zI3rYZh71Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  decision = D(x_hat)\n",
        "print (decision[:10].squeeze())"
      ],
      "metadata": {
        "id": "c0CyfxqVh8Y0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss와 Optimizer 정의\n",
        "\n",
        "모델 학습을 위해 loss와 optimizer를 선언해주도록 하겠습니다."
      ],
      "metadata": {
        "id": "0h9_33j_MWK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator loss\n",
        "\n",
        "아래 코드는 Discriminator를 위한 loss 구현 코드입니다.  \n",
        "Discriminator의 학습 목표는, real image에 대해서는 1(or 높은 확률값)을 반환하고, fake image에 대해서는 0(or 낮은 확률값)을 반환하는 것입니다."
      ],
      "metadata": {
        "id": "khd1dKFeM9Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    ################ ToDo ##################\n",
        "    D_real_labels = torch.ones_like(real_output)\n",
        "    D_fake_labels = torch.zeros_like(fake_output)\n",
        "\n",
        "    real_loss =\n",
        "    fake_loss =\n",
        "    total_loss = real_loss + fake_loss\n",
        "    ########################################\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "w9-piqlaL7Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator loss\n",
        "아래 코드는 Generator를 위한 loss 구현 코드입니다.  \n",
        "Generator의 학습 목표는, discriminator를 속이는 것이며, 이는 fake output에 대해 1(or 높은 확률값)을 반환하도록 하는 것입니다."
      ],
      "metadata": {
        "id": "MllC_jWYNAUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "    ################ ToDo ##################\n",
        "    G_fake_labels =\n",
        "    loss =\n",
        "    ########################################\n",
        "    return loss"
      ],
      "metadata": {
        "id": "ySYHryMgM5mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드는 각각의 model에 대한 optimizer를 선언해주는 코드입니다."
      ],
      "metadata": {
        "id": "Gi1N_oDXNO7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D_opt = torch.optim.Adam(D.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=0.001, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "La7FGvkZNQhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the training loop"
      ],
      "metadata": {
        "id": "IQXfFrViNTXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "global_step = 0\n",
        "n_critic = 1"
      ],
      "metadata": {
        "id": "bKIVRBl8Ne1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드는 DCGAN 학습을 위한 train_step 코드입니다.  \n",
        "1. 각 train_step마다 Generator는 **BATCH_SIZE**개 만큼의 이미지를 생성합니다.  \n",
        "2. Discriminator는 Generator가 만든 **BATCH_SIZE**개의 이미지와, training set에서 가져온 **BATCH_SIZE**개의 이미지, 총 **2xBATCH_SIZE**개의 이미지에 대해 real/fake 판별을 진행합니다.\n",
        "3. 이후 Generator, Discriminator에 대한 loss를 계산하고, Gradient를 계산한 뒤\n",
        "4. Model의 Parameter를 업데이트해주게 됩니다."
      ],
      "metadata": {
        "id": "hV-Ulb2PNcoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G.train()\n",
        "D.train()\n",
        "\n",
        "G_train_loss_list = []\n",
        "D_train_loss_list = []\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for idx, (x, y) in enumerate(data_loader):\n",
        "        # Training Discriminator\n",
        "        x = x.to(DEVICE)\n",
        "        D_real_preds = D(x)\n",
        "\n",
        "        z = torch.randn(batch_size, noise_dim).to(DEVICE)\n",
        "        D_fake_preds = D(G(z))\n",
        "\n",
        "        D_loss = discriminator_loss(D_real_preds, D_fake_preds)\n",
        "\n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_opt.step()\n",
        "\n",
        "        if global_step % n_critic == 0:\n",
        "            # Training Generator\n",
        "            z = torch.randn(batch_size, noise_dim).to(DEVICE)\n",
        "            D_fake_preds = D(G(z))\n",
        "            G_loss = generator_loss(D_fake_preds)\n",
        "\n",
        "            D.zero_grad()\n",
        "            G.zero_grad()\n",
        "            G_loss.backward()\n",
        "            G_opt.step()\n",
        "\n",
        "        if global_step % 500 == 0:\n",
        "            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, EPOCHS, global_step, D_loss.item(), G_loss.item()))\n",
        "\n",
        "        if global_step % 50 == 0:\n",
        "            G_train_loss_list.append(G_loss.data.item())\n",
        "            D_train_loss_list.append(D_loss.data.item())\n",
        "\n",
        "        global_step += 1"
      ],
      "metadata": {
        "id": "Dnl88_dYNYWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(G_train_loss_list)\n",
        "plt.plot(D_train_loss_list)\n",
        "plt.xlabel('Steps')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kcRbsiyVOl_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and save images\n",
        "아래 코드는 모델로부터 이미지를 생성하고 이를 확인하는 코드입니다."
      ],
      "metadata": {
        "id": "ETPAUtvUPNFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "G.eval()\n",
        "\n",
        "n_samples = 100\n",
        "\n",
        "with torch.no_grad():\n",
        "  z = torch.randn(n_samples, 100).to(DEVICE)\n",
        "  x_hat = G(z)\n",
        "\n",
        "img = make_grid(x_hat, nrow=10, normalize=True, value_range=(-1., 1.)).permute(1, 2, 0).cpu().data.numpy()\n",
        "\n",
        "imshow(img, cmap='gray')"
      ],
      "metadata": {
        "id": "h0RuWsa2PeIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i_RucTT9UP1d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}