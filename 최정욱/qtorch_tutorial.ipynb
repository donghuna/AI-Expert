{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/%EC%B5%9C%EC%A0%95%EC%9A%B1/qtorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhWwfK2rbxhl"
      },
      "source": [
        "# Getting Started: Install QPyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1CDHP_XbJoO",
        "outputId": "cd1341f6-be10-4a42-a220-9ad942624f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# 자신의 Google Drive 를 Google Collab 에 마운트 시켜줍니다.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PniwZ4TTbDLh",
        "outputId": "6e7aa417-d1a8-4176-8092-d3bb821c499a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AI-Expert/최정욱/QPytorch\n",
            "PreResNet_fp32.pth  qtorch_tutorial.ipynb  requirements.txt\n"
          ]
        }
      ],
      "source": [
        "# Google Drive 폴더로 이동합니다.\n",
        "%cd /content/drive/MyDrive/AI-Expert/최정욱/QPytorch\n",
        "# 폴더 내 파일 목록 확인\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFvLKcLbPY1s",
        "outputId": "088302be-40e6-437d-89e5-196004b3d75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sphinx>=1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (5.0.2)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (5.5.6)\n",
            "Collecting nbsphinx (from -r requirements.txt (line 3))\n",
            "  Downloading nbsphinx-0.9.5-py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting Ninja (from -r requirements.txt (line 4))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.19.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (4.66.5)\n",
            "Collecting transformers==4.37.0 (from -r requirements.txt (line 8))\n",
            "  Downloading transformers-4.37.0-py3-none-any.whl.metadata (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.4/129.4 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting qtorch==0.3.0 (from -r requirements.txt (line 9))\n",
            "  Downloading qtorch-0.3.0-py3-none-any.whl.metadata (455 bytes)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (0.23.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (2.32.3)\n",
            "Collecting tokenizers<0.19,>=0.14 (from transformers==4.37.0->-r requirements.txt (line 8))\n",
            "  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.0->-r requirements.txt (line 8)) (0.4.4)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from qtorch==0.3.0->-r requirements.txt (line 9)) (2.4.0+cu121)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.1.0)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (2.16.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=1.4->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 2)) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 2)) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 2)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->-r requirements.txt (line 2)) (6.3.3)\n",
            "Requirement already satisfied: nbconvert!=5.4,>=5.3 in /usr/local/lib/python3.10/dist-packages (from nbsphinx->-r requirements.txt (line 3)) (6.5.4)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from nbsphinx->-r requirements.txt (line 3)) (5.10.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 5)) (9.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.3.0->-r requirements.txt (line 9)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.3.0->-r requirements.txt (line 9)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.3.0->-r requirements.txt (line 9)) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->qtorch==0.3.0->-r requirements.txt (line 9)) (2024.6.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (71.0.4)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 2))\n",
            "  Using cached jedi-0.19.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (3.0.47)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx>=1.4->-r requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (4.9.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (4.12.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (6.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (0.7.1)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.7 in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (5.7.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (0.3.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (0.8.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->nbsphinx->-r requirements.txt (line 3)) (2.20.0)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat->nbsphinx->-r requirements.txt (line 3)) (4.23.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0->-r requirements.txt (line 8)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0->-r requirements.txt (line 8)) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0->-r requirements.txt (line 8)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.37.0->-r requirements.txt (line 8)) (2024.7.4)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 2)) (24.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (0.8.4)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->nbsphinx->-r requirements.txt (line 3)) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->nbsphinx->-r requirements.txt (line 3)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->nbsphinx->-r requirements.txt (line 3)) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat->nbsphinx->-r requirements.txt (line 3)) (0.20.0)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core>=4.7->nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (4.2.2)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->-r requirements.txt (line 2)) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->jupyter-client->ipykernel->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (2.6)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->nbconvert!=5.4,>=5.3->nbsphinx->-r requirements.txt (line 3)) (0.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->qtorch==0.3.0->-r requirements.txt (line 9)) (1.3.0)\n",
            "Downloading transformers-4.37.0-py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading qtorch-0.3.0-py3-none-any.whl (21 kB)\n",
            "Downloading nbsphinx-0.9.5-py3-none-any.whl (31 kB)\n",
            "Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "Installing collected packages: Ninja, jedi, tokenizers, qtorch, transformers, nbsphinx\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "Successfully installed Ninja-1.11.1.1 jedi-0.19.1 nbsphinx-0.9.5 qtorch-0.3.0 tokenizers-0.15.2 transformers-4.37.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXNTg39objEC"
      },
      "source": [
        "# Lab 1. Quantizer Tutorial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "b3YXBtJdPnmV",
        "outputId": "10c78dcd-3452-453d-e2bf-9d82b8197aa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:1965: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
            "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from qtorch.quant import Quantizer, quantizer\n",
        "from qtorch import FloatingPoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOG26L_hlyjO"
      },
      "source": [
        "### Input Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeKTakK2vy_G",
        "outputId": "3b039ef7-f81b-48fc-d70a-257271405853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3564, 0.5577, 0.3888],\n",
            "        [0.3668, 0.2829, 0.6164],\n",
            "        [0.9219, 0.8011, 0.5533]])\n"
          ]
        }
      ],
      "source": [
        "random_input = torch.rand([3,3])\n",
        "print(random_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EApY1jmgPnmY",
        "outputId": "8e7ca339-db6c-4ab6-d06d-12b424ca60af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 255.0000, -255.0000],\n",
            "        [   1.4000,    1.6000]])\n"
          ]
        }
      ],
      "source": [
        "constant_input = torch.tensor([[255., -255.],[1.4, 1.6]])\n",
        "print(constant_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6oOFQx-lyjO"
      },
      "source": [
        "### Quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "jDdkM_DIPnmZ"
      },
      "outputs": [],
      "source": [
        "# Example: FP4 (E2M1) Quantization\n",
        "bit = FloatingPoint(exp=2, man=1)\n",
        "quant = quantizer(forward_number=bit, forward_rounding=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhIfnjodPnmZ",
        "outputId": "0c51fa6b-00b5-46ba-96f5-0c2d57688a91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5000, 0.5000, 0.5000],\n",
            "        [0.5000, 0.5000, 0.5000],\n",
            "        [1.0000, 1.0000, 0.5000]])\n"
          ]
        }
      ],
      "source": [
        "random_output = quant(random_input)\n",
        "print(random_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQvwyONzPnma",
        "outputId": "db8bb616-c599-4854-d087-9a13c40a9e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 6.0000, -6.0000],\n",
            "        [ 1.5000,  1.5000]])\n"
          ]
        }
      ],
      "source": [
        "constant_output = quant(constant_input)\n",
        "print(constant_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFxoNyqQc3z7"
      },
      "source": [
        "# Lab 2. Reduced-Precision Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "G0yRBZ2PW4Ay"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from qtorch.quant import Quantizer, quantizer\n",
        "from qtorch.optim import OptimLP\n",
        "from torch.optim import SGD\n",
        "from qtorch import FloatingPoint\n",
        "from tqdm import tqdm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XESR-_sAW4A1",
        "outputId": "aaf44ed3-8250-4a4f-e134-d8f7dc313d7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/CIFAR10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:17<00:00, 9870881.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/CIFAR10/cifar-10-python.tar.gz to ./data/CIFAR10\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "# loading data\n",
        "ds = torchvision.datasets.CIFAR10\n",
        "path = os.path.join(\"./data\", \"CIFAR10\")\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "train_set = ds(path, train=True, download=True, transform=transform_train)\n",
        "test_set = ds(path, train=False, download=True, transform=transform_test)\n",
        "loaders = {\n",
        "        'train': torch.utils.data.DataLoader(\n",
        "            train_set,\n",
        "            batch_size=128,\n",
        "            shuffle=True,\n",
        "            num_workers=4,\n",
        "            pin_memory=True\n",
        "        ),\n",
        "        'test': torch.utils.data.DataLoader(\n",
        "            test_set,\n",
        "            batch_size=128,\n",
        "            num_workers=4,\n",
        "            pin_memory=True\n",
        "        )\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "mI5Eqkp0W4A3"
      },
      "outputs": [],
      "source": [
        "# define two floating point formats\n",
        "bit_8 = FloatingPoint(exp=5, man=2)\n",
        "bit_16 = FloatingPoint(exp=6, man=9)\n",
        "\n",
        "# define quantization functions\n",
        "weight_quant = quantizer(forward_number=bit_8,\n",
        "                        forward_rounding=\"nearest\")\n",
        "grad_quant = quantizer(forward_number=bit_8,\n",
        "                        forward_rounding=\"nearest\")\n",
        "momentum_quant = quantizer(forward_number=bit_16,\n",
        "                        forward_rounding=\"stochastic\")\n",
        "acc_quant = quantizer(forward_number=bit_16,\n",
        "                        forward_rounding=\"stochastic\")\n",
        "\n",
        "# define a lambda function so that the Quantizer module can be duplicated easily\n",
        "act_error_quant = lambda : Quantizer(forward_number=bit_8, backward_number=bit_8,\n",
        "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "HOImoaAsW4A4"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, quant, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.quant = quant()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        ####### FIXME #######\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.quant(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.quant(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.quant(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.quant(out)\n",
        "        #####################\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        return out\n",
        "\n",
        "class PreResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,quant, num_classes=10, depth=20):\n",
        "\n",
        "        super(PreResNet, self).__init__()\n",
        "        assert (depth - 2) % 6 == 0, 'depth should be 6n+2'\n",
        "        n = (depth - 2) // 6\n",
        "\n",
        "        block = BasicBlock\n",
        "\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.layer1 = self._make_layer(block, 16, n, quant)\n",
        "        self.layer2 = self._make_layer(block, 32, n, quant, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, n, quant, stride=2)\n",
        "        self.bn = nn.BatchNorm2d(64 * block.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "        self.quant = quant()\n",
        "        IBM_half = FloatingPoint(exp=6, man=9)\n",
        "        self.quant_half = Quantizer(IBM_half, IBM_half, \"nearest\", \"nearest\")\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, quant, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "            )\n",
        "\n",
        "        layers = list()\n",
        "        layers.append(block(self.inplanes, planes, quant , stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, quant))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant_half(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.quant(x)\n",
        "\n",
        "        x = self.layer1(x)  # 32x32\n",
        "        x = self.layer2(x)  # 16x16\n",
        "        x = self.layer3(x)  # 8x8\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.quant(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.quant_half(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "14jRstmDW4A5"
      },
      "outputs": [],
      "source": [
        "model = PreResNet(act_error_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "X9AmXt_zW4A5"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' # change device to 'cuda' if you want to run this example on cuda\n",
        "model = model.to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "g-pH0RDHW4A5"
      },
      "outputs": [],
      "source": [
        "optimizer = SGD(model.parameters(), lr=0.05, momentum=0.9, weight_decay=5e-4)\n",
        "optimizer = OptimLP(optimizer,\n",
        "                    weight_quant=weight_quant,\n",
        "                    grad_quant=grad_quant,\n",
        "                    momentum_quant=momentum_quant,\n",
        "                    acc_quant=acc_quant,\n",
        "                    grad_scaling=1/1000 # do loss scaling\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "p0VLSx1oW4A5"
      },
      "outputs": [],
      "source": [
        "def run_epoch(loader, model, criterion, optimizer=None, phase=\"train\"):\n",
        "    assert phase in [\"train\", \"eval\"], \"invalid running phase\"\n",
        "    loss_sum = 0.0\n",
        "    correct = 0.0\n",
        "\n",
        "    if phase==\"train\": model.train()\n",
        "    elif phase==\"eval\": model.eval()\n",
        "\n",
        "    ttl = 0\n",
        "    with torch.autograd.set_grad_enabled(phase==\"train\"):\n",
        "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
        "            input = input.to(device=device)\n",
        "            target = target.to(device=device)\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            loss_sum += loss.cpu().item() * input.size(0)\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            ttl += input.size()[0]\n",
        "\n",
        "            if phase==\"train\":\n",
        "                loss = loss * 1000 # do loss scaling\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "    correct = correct.cpu().item()\n",
        "    return {\n",
        "        'loss': loss_sum / float(ttl),\n",
        "        'accuracy': correct / float(ttl) * 100.0,\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOm1gruUlyjQ"
      },
      "source": [
        "### Accuracy Before Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "_7bw-5x0lyjR",
        "outputId": "e5965a40-eb05-428b-9eae-54b0ea48d3a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:02<00:00, 39.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 3.2637169151306153, 'accuracy': 9.8}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
        "                        optimizer=optimizer, phase=\"eval\")\n",
        "print(test_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Grgd_LPplyjR"
      },
      "source": [
        "### 3-Epoch Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbgMAJtoW4A6",
        "outputId": "e4d023e1-4eaa-4268-cce3-0ffd44eaf0c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 28.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====> Epoch 0\n",
            "Train loss    : 1.6568851916122436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 391/391 [00:13<00:00, 28.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====> Epoch 1\n",
            "Train loss    : 1.1912027248764039\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 391/391 [00:13<00:00, 29.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====> Epoch 2\n",
            "Train loss    : 0.9807163693237305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(3):\n",
        "    train_res = run_epoch(loaders['train'], model, F.cross_entropy,\n",
        "                                optimizer=optimizer, phase=\"train\")\n",
        "    print(f'=====> Epoch {epoch}')\n",
        "    print(f'Train loss    : {train_res[\"loss\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T5qCj6XlyjR"
      },
      "source": [
        "### Accuracy After Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8-KyxWdlyjR",
        "outputId": "f829b54f-691e-4965-a644-14bad8ca6588"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 79/79 [00:00<00:00, 99.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.0952622838974, 'accuracy': 61.1}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_res = run_epoch(loaders['test'], model, F.cross_entropy,\n",
        "                        optimizer=optimizer, phase=\"eval\")\n",
        "print(test_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_MP5qXQdK20"
      },
      "source": [
        "# Lab 3.1. Trans-Precision Inference on CNN Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "WrNdpm-WXr7n"
      },
      "outputs": [],
      "source": [
        "# Define model\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, quant, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(inplanes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.quant = quant()\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.quant(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.quant(out)\n",
        "\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.quant(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.quant(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "\n",
        "        return out\n",
        "\n",
        "class PreResNet(nn.Module):\n",
        "\n",
        "    def __init__(self,quant, num_classes=10, depth=20):\n",
        "\n",
        "        super(PreResNet, self).__init__()\n",
        "        assert (depth - 2) % 6 == 0, 'depth should be 6n+2'\n",
        "        n = (depth - 2) // 6\n",
        "\n",
        "        block = BasicBlock\n",
        "\n",
        "        self.inplanes = 16\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1,\n",
        "                               bias=False)\n",
        "        self.layer1 = self._make_layer(block, 16, n, quant)\n",
        "        self.layer2 = self._make_layer(block, 32, n, quant, stride=2)\n",
        "        self.layer3 = self._make_layer(block, 64, n, quant, stride=2)\n",
        "        self.bn = nn.BatchNorm2d(64 * block.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.avgpool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64 * block.expansion, num_classes)\n",
        "        self.quant = quant()\n",
        "        IBM_half = FloatingPoint(exp=6, man=9)\n",
        "        self.quant_half = Quantizer(IBM_half, IBM_half, \"nearest\", \"nearest\")\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, quant, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "            )\n",
        "\n",
        "        layers = list()\n",
        "        layers.append(block(self.inplanes, planes, quant , stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, quant))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.quant_half(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.quant(x)\n",
        "\n",
        "        x = self.layer1(x)  # 32x32\n",
        "        x = self.layer2(x)  # 16x16\n",
        "        x = self.layer3(x)  # 8x8\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.quant(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "        x = self.quant_half(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "0Q0sOJlxXr7m"
      },
      "outputs": [],
      "source": [
        "# define Three floating point formats\n",
        "bit_8 = FloatingPoint(exp=5, man=2)\n",
        "bit_16 = FloatingPoint(exp=6, man=9)\n",
        "bit_32 = FloatingPoint(exp=8, man=23)\n",
        "\n",
        "# define a lambda function so that the Quantizer module can be duplicated easily\n",
        "act_error_quant = lambda : Quantizer(forward_number=bit_8, backward_number=bit_8,\n",
        "                        forward_rounding=\"nearest\", backward_rounding=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Df_x9rYgXr7n"
      },
      "outputs": [],
      "source": [
        "model = PreResNet(act_error_quant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6RYFGnwXr7o",
        "outputId": "5e4d0c62-4330-4fd9-b440-cf92f8c86219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-ad3a7199e419>:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load('./PreResNet_fp32.pth')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "checkpoint = torch.load('./PreResNet_fp32.pth')\n",
        "model.load_state_dict(checkpoint['model'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Iw_TioBwXr7o"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' # change device to 'cuda' if you want to run this example on cuda\n",
        "model = model.to(device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Rd5cwB5oXr7p"
      },
      "outputs": [],
      "source": [
        "def run_test(loader, model, criterion, optimizer=None):\n",
        "    loss_sum = 0.0\n",
        "    correct = 0.0\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    ttl = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (input, target) in tqdm(enumerate(loader), total=len(loader)):\n",
        "            input = input.to(device=device)\n",
        "            target = target.to(device=device)\n",
        "            output = model(input)\n",
        "            loss = criterion(output, target)\n",
        "            loss_sum += loss.cpu().item() * input.size(0)\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "            ttl += input.size()[0]\n",
        "\n",
        "    correct = correct.cpu().item()\n",
        "    return {\n",
        "        'loss': loss_sum / float(ttl),\n",
        "        'accuracy': correct / float(ttl) * 100.0,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD1nssfBXr7p",
        "outputId": "32e8c4c4-9f5d-4600-992d-781944c57096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 79/79 [00:00<00:00, 99.22it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.26722962763309477, 'accuracy': 92.12}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "test_res = run_test(loaders['test'], model, F.cross_entropy, optimizer=optimizer)\n",
        "print(test_res)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRAbPrBglyjS"
      },
      "source": [
        "# Lab 3.2. Trans-Precision Inference on LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "8WYdtXFwlyjS"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "Wo96ZePjlyjS",
        "outputId": "dc5174ed-c2f6-4cd9-accd-2f6df72f6aeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "model_id = \"Qwen/Qwen2-0.5B-Instruct\"\n",
        "device = \"cuda\" # the device to load the model onto\n",
        "\n",
        "LLM = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=torch.float32,\n",
        "    attn_implementation=\"eager\",\n",
        "    device_map=device\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "UFH37gMzlyjW"
      },
      "outputs": [],
      "source": [
        "prompt = \"Give me a short introduction of Samsung Electronics.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "2vaDGX0_lyjW",
        "outputId": "82fe500a-fdff-4742-debf-7777a92fe14d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:392: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:397: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.8` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:407: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samsung Electronics is one of the world's largest and most successful electronics companies, with a presence in over 190 countries. The company was founded in 1938 by Lee Dong-hwan and has since grown to become one of the world's leading producers of consumer electronics, including smartphones, TVs, computers, and other devices.\n",
            "\n",
            "Samsung Electronics operates several major divisions, including the Mobile Phone Division, which produces smartphones, tablets, and other mobile devices; the TV Division, which produces TVs, LCD monitors, and other home entertainment products; the Consumer Electronics Division, which produces a wide range of consumer electronics products, including televisions\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = LLM.generate(\n",
        "    model_inputs.input_ids,\n",
        "    num_beams=1,\n",
        "    do_sample=False,\n",
        "    max_new_tokens=128\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM"
      ],
      "metadata": {
        "id": "i_V7r79aukvH",
        "outputId": "64b8ef98-7577-4b5b-dc51-d8d3cbf91c5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm()\n",
              "        (post_attention_layernorm): Qwen2RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH8-a1XulyjW"
      },
      "source": [
        "## Define Quantized Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Fb-aFkmBlyjW"
      },
      "outputs": [],
      "source": [
        "from typing import List, Optional, Tuple, Union\n",
        "from transformers.cache_utils import Cache, DynamicCache\n",
        "\n",
        "class MatMul(nn.Module):\n",
        "    def forward(self, A, B):\n",
        "        return A @ B\n",
        "\n",
        "class QuantMatMul(nn.Module):\n",
        "    def __init__(self, qbit):\n",
        "        super().__init__()\n",
        "        self.quantizer = Quantizer(forward_number=qbit, backward_number=qbit,\n",
        "                     forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
        "    def forward(self, A, B):\n",
        "        qA = self.quantizer.quantize(A.data)\n",
        "        qB = self.quantizer.quantize(B.data)\n",
        "        return qA @ qB\n",
        "\n",
        "from transformers.models.qwen2.modeling_qwen2 import rotate_half, apply_rotary_pos_emb, repeat_kv\n",
        "\n",
        "def attn_forward(\n",
        "    self,\n",
        "    hidden_states: torch.Tensor,\n",
        "    attention_mask: Optional[torch.Tensor] = None,\n",
        "    position_ids: Optional[torch.LongTensor] = None,\n",
        "    past_key_value: Optional[Cache] = None,\n",
        "    output_attentions: bool = False,\n",
        "    use_cache: bool = False,\n",
        "    **kwargs,\n",
        ") -> Tuple[torch.Tensor, Optional[torch.Tensor], Optional[Tuple[torch.Tensor]]]:\n",
        "    if \"padding_mask\" in kwargs:\n",
        "        warnings.warn(\n",
        "            \"Passing `padding_mask` is deprecated and will be removed in v4.37. Please make sure use `attention_mask` instead.`\"\n",
        "        )\n",
        "    bsz, q_len, _ = hidden_states.size()\n",
        "\n",
        "    query_states = self.q_proj(hidden_states)\n",
        "    key_states = self.k_proj(hidden_states)\n",
        "    value_states = self.v_proj(hidden_states)\n",
        "\n",
        "    query_states = query_states.view(bsz, q_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "    key_states = key_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
        "    value_states = value_states.view(bsz, q_len, self.num_key_value_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "    kv_seq_len = key_states.shape[-2]\n",
        "    if past_key_value is not None:\n",
        "        if self.layer_idx is None:\n",
        "            raise ValueError(\n",
        "                f\"The cache structure has changed since version v4.36. If you are using {self.__class__.__name__} \"\n",
        "                \"for auto-regressive decoding with k/v caching, please make sure to initialize the attention class \"\n",
        "                \"with a layer index.\"\n",
        "            )\n",
        "        kv_seq_len += past_key_value.get_usable_length(kv_seq_len, self.layer_idx)\n",
        "    cos, sin = self.rotary_emb(value_states, seq_len=kv_seq_len)\n",
        "    query_states, key_states = apply_rotary_pos_emb(query_states, key_states, cos, sin, position_ids)\n",
        "\n",
        "    if past_key_value is not None:\n",
        "        cache_kwargs = {\"sin\": sin, \"cos\": cos}  # Specific to RoPE models\n",
        "        key_states, value_states = past_key_value.update(key_states, value_states, self.layer_idx, cache_kwargs)\n",
        "\n",
        "    # repeat k/v heads if n_kv_heads < n_heads\n",
        "    key_states = repeat_kv(key_states, self.num_key_value_groups)\n",
        "    value_states = repeat_kv(value_states, self.num_key_value_groups)\n",
        "\n",
        "    attn_weights = self.matmul1(query_states, key_states.transpose(2, 3)) / math.sqrt(self.head_dim)\n",
        "\n",
        "    if attn_weights.size() != (bsz, self.num_heads, q_len, kv_seq_len):\n",
        "        raise ValueError(\n",
        "            f\"Attention weights should be of size {(bsz, self.num_heads, q_len, kv_seq_len)}, but is\"\n",
        "            f\" {attn_weights.size()}\"\n",
        "        )\n",
        "\n",
        "    if attention_mask is not None:\n",
        "        if attention_mask.size() != (bsz, 1, q_len, kv_seq_len):\n",
        "            raise ValueError(\n",
        "                f\"Attention mask should be of size {(bsz, 1, q_len, kv_seq_len)}, but is {attention_mask.size()}\"\n",
        "            )\n",
        "\n",
        "        attn_weights = attn_weights + attention_mask\n",
        "\n",
        "    # upcast attention to fp32\n",
        "    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)\n",
        "    attn_weights = nn.functional.dropout(attn_weights, p=self.attention_dropout, training=self.training)\n",
        "    attn_output = self.matmul2(attn_weights, value_states)\n",
        "\n",
        "    if attn_output.size() != (bsz, self.num_heads, q_len, self.head_dim):\n",
        "        raise ValueError(\n",
        "            f\"`attn_output` should be of size {(bsz, self.num_heads, q_len, self.head_dim)}, but is\"\n",
        "            f\" {attn_output.size()}\"\n",
        "        )\n",
        "\n",
        "    attn_output = attn_output.transpose(1, 2).contiguous()\n",
        "    attn_output = attn_output.reshape(bsz, q_len, self.hidden_size)\n",
        "\n",
        "    attn_output = self.o_proj(attn_output)\n",
        "\n",
        "    if not output_attentions:\n",
        "        attn_weights = None\n",
        "\n",
        "    return attn_output, attn_weights, past_key_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "gkZr456QlyjX"
      },
      "outputs": [],
      "source": [
        "class QuantLinear(nn.Linear):\n",
        "    def __init__(self,in_features,out_features,bias,qbit):\n",
        "        super().__init__(in_features,out_features,bias)\n",
        "        self.quantizer_x = Quantizer(forward_number=qbit, backward_number=qbit,\n",
        "                     forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
        "        self.quantizer_w = Quantizer(forward_number=qbit, backward_number=qbit,\n",
        "                     forward_rounding=\"nearest\", backward_rounding=\"nearest\")\n",
        "    def forward(self,x):\n",
        "        w = self.weight.clone()\n",
        "        qx = self.quantizer_x.quantize(x.data)\n",
        "        qw = self.quantizer_w.quantize(w.data)\n",
        "        return F.linear(qx,qw,self.bias)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM.named_modules()"
      ],
      "metadata": {
        "id": "tk3MJPM_t5TH",
        "outputId": "7cfc16a1-2f84-4e47-df0c-07a5df5c4df5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object Module.named_modules at 0x7ca9cc0b86d0>"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM"
      ],
      "metadata": {
        "id": "gxdB8My4t7gO",
        "outputId": "682ab4a8-80ee-4048-d132-0f0c1146cf9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
              "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm()\n",
              "        (post_attention_layernorm): Qwen2RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM.model.layers[0].self_attn"
      ],
      "metadata": {
        "id": "IwvnLPujuHdP",
        "outputId": "8212db3f-83e8-48e2-cfbb-a864eaa3d54c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2Attention(\n",
              "  (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
              "  (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "  (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
              "  (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
              "  (rotary_emb): Qwen2RotaryEmbedding()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "EO6p4RAylyjX"
      },
      "outputs": [],
      "source": [
        "from types import MethodType\n",
        "\n",
        "def get_QLLM(LLM, qbit):\n",
        "    from transformers.models.qwen2.modeling_qwen2 import Qwen2Attention\n",
        "    for name, module in LLM.named_modules():\n",
        "        if isinstance(module, Qwen2Attention):\n",
        "            setattr(module, \"matmul1\", QuantMatMul(qbit))\n",
        "            setattr(module, \"matmul2\", QuantMatMul(qbit))\n",
        "            module.forward = MethodType(attn_forward, module)\n",
        "\n",
        "    wrapped_modules={}\n",
        "    module_dict={}\n",
        "    it=[(name,m) for name,m in LLM.named_modules()]\n",
        "    for name,m in it:\n",
        "        module_dict[name]=m\n",
        "        idx=name.rfind('.')\n",
        "        if idx==-1:\n",
        "            idx=0\n",
        "        father_name=name[:idx]\n",
        "        if father_name in module_dict:\n",
        "            father_module=module_dict[father_name]\n",
        "        else:\n",
        "            raise RuntimeError(f\"father module {father_name} not found\")\n",
        "        if isinstance(m,nn.Linear) and 'head' not in name:\n",
        "            idx = idx+1 if idx != 0 else idx\n",
        "            new_m = QuantLinear(m.in_features,m.out_features,m.bias is not None,qbit=qbit)\n",
        "            new_m.weight.data=m.weight.data\n",
        "            new_m.bias=m.bias\n",
        "            replace_m=new_m\n",
        "            wrapped_modules[name] = new_m\n",
        "            setattr(father_module,name[idx:],replace_m)\n",
        "    LLM.eval()\n",
        "    return wrapped_modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "LLdQfr23lyjX"
      },
      "outputs": [],
      "source": [
        "qbit = FloatingPoint(exp=5, man=2)\n",
        "wrapped_modules = get_QLLM(LLM, qbit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "6RcqDu9_lyjX"
      },
      "outputs": [],
      "source": [
        "prompt = \"Give me a short introduction of Samsung Electronics.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "G1_Px9PNlyjX",
        "outputId": "4d03b838-70ac-4e09-fa27-521652bc0d10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Samsung Electronics is a South Korean multinational corporation headquartered in Seoul, Korea. The company was founded in 1978 and has since become one of the world's largest electronics manufacturers with operations in over 100 countries worldwide.\n",
            "\n",
            "Samsung Electronics is known for its high-quality smartphones, tablets, smart TVs, and other consumer electronics products. It also produces various other consumer goods such as televisions, refrigerators, washing machines, and dishwashers.\n",
            "\n",
            "In addition to these products, Samsung Electronics also operates several other businesses including automotive, home appliances, and medical devices. The company has been recognized globally for its innovative technology and commitment to quality\n"
          ]
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True\n",
        ")\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(device)\n",
        "\n",
        "generated_ids = LLM.generate(\n",
        "    model_inputs.input_ids,\n",
        "    num_beams=1,\n",
        "    do_sample=False,\n",
        "    max_new_tokens=128\n",
        ")\n",
        "generated_ids = [\n",
        "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "]\n",
        "\n",
        "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LLM"
      ],
      "metadata": {
        "id": "enxJvEQRu5wX",
        "outputId": "92e1294c-7884-4129-c536-02d008e06f5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Qwen2ForCausalLM(\n",
              "  (model): Qwen2Model(\n",
              "    (embed_tokens): Embedding(151936, 896)\n",
              "    (layers): ModuleList(\n",
              "      (0-23): 24 x Qwen2DecoderLayer(\n",
              "        (self_attn): Qwen2Attention(\n",
              "          (q_proj): QuantLinear(\n",
              "            in_features=896, out_features=896, bias=True\n",
              "            (quantizer_x): Quantizer()\n",
              "            (quantizer_w): Quantizer()\n",
              "          )\n",
              "          (k_proj): QuantLinear(\n",
              "            in_features=896, out_features=128, bias=True\n",
              "            (quantizer_x): Quantizer()\n",
              "            (quantizer_w): Quantizer()\n",
              "          )\n",
              "          (v_proj): QuantLinear(\n",
              "            in_features=896, out_features=128, bias=True\n",
              "            (quantizer_x): Quantizer()\n",
              "            (quantizer_w): Quantizer()\n",
              "          )\n",
              "          (o_proj): QuantLinear(\n",
              "            in_features=896, out_features=896, bias=False\n",
              "            (quantizer_x): Quantizer()\n",
              "            (quantizer_w): Quantizer()\n",
              "          )\n",
              "          (rotary_emb): Qwen2RotaryEmbedding()\n",
              "          (matmul1): QuantMatMul(\n",
              "            (quantizer): Quantizer()\n",
              "          )\n",
              "          (matmul2): QuantMatMul(\n",
              "            (quantizer): Quantizer()\n",
              "          )\n",
              "        )\n",
              "        (mlp): Qwen2MLP(\n",
              "          (gate_proj): QuantLinear(\n",
              "            in_features=896, out_features=4864, bias=False\n",
              "            (quantizer_x): Quantizer()\n",
              "            (quantizer_w): Quantizer()\n",
              "          )\n",
              "          (up_proj): QuantLinear(\n",
              "            in_features=896, out_features=4864, bias=False\n",
              "            (quantizer_x): Quantizer()\n",
              "            (quantizer_w): Quantizer()\n",
              "          )\n",
              "          (down_proj): QuantLinear(\n",
              "            in_features=4864, out_features=896, bias=False\n",
              "            (quantizer_x): Quantizer()\n",
              "            (quantizer_w): Quantizer()\n",
              "          )\n",
              "          (act_fn): SiLU()\n",
              "        )\n",
              "        (input_layernorm): Qwen2RMSNorm()\n",
              "        (post_attention_layernorm): Qwen2RMSNorm()\n",
              "      )\n",
              "    )\n",
              "    (norm): Qwen2RMSNorm()\n",
              "  )\n",
              "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "kR4ZCBhYlyjX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}