{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMV6I6TXXwgPNpxElENutU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/timesformer/TimeSformer-huggingface-example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install av"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iP7zgLRCSpk3",
        "outputId": "d662ab3f-4839-450d-d467-cf9e1dc9a891"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting av\n",
            "  Downloading av-12.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-12.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ftplib import FTP\n",
        "import io\n",
        "\n",
        "# FTP 서버 정보\n",
        "ftp_server = \"121.136.96.223\"  # Synology NAS의 IP 주소\n",
        "ftp_port = 21  # 기본 포트 21, 다른 포트를 사용하는 경우 해당 포트 번호 입력\n",
        "ftp_user = \"donghuna_ftp\"  # NAS 로그인 사용자명\n",
        "ftp_password = \"Dlehdgns0892!@!?n\"  # NAS 로그인 비밀번호\n",
        "file_path = \"homes/donghuna/database/Diving48_rgb/rgb/_8Vy3dlHg2w_00000.mp4\"\n",
        "local_file_path = \"eating_spaghetti.mp4\"  # 로컬에 저장할 파일 이름\n",
        "\n",
        "# FTP 연결 설정\n",
        "ftp = FTP()\n",
        "ftp.connect(ftp_server, ftp_port)\n",
        "ftp.login(user=ftp_user, passwd=ftp_password)\n",
        "\n",
        "# 액티브 모드 설정 (패시브 모드 비활성화)\n",
        "ftp.set_pasv(True)\n",
        "\n",
        "# 파일 다운로드\n",
        "# with open(local_file_path, 'wb') as local_file:\n",
        "#     ftp.retrbinary(f'RETR {file_path}', local_file.write)\n",
        "\n",
        "# 동영상을 메모리에 저장\n",
        "video_data = io.BytesIO()\n",
        "ftp.retrbinary(f'RETR {file_path}', video_data.write)\n",
        "video_data.seek(0)\n",
        "\n",
        "# 연결 종료\n",
        "ftp.quit()\n",
        "\n",
        "# print(f\"File downloaded successfully to {local_file_path}\")"
      ],
      "metadata": {
        "id": "62cWKO05eGml",
        "outputId": "70e11a28-6d67-486e-a65e-e235966901c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'221 Goodbye. You uploaded 0 bytes and downloaded 757.35 KB.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import av # 동영상 파일을 처리하기 위한 라이브러리.\n",
        "import torch # PyTorch 라이브러리로, 모델 학습 및 추론에 사용.\n",
        "import numpy as np # 배열 및 수학적 연산을 위한 라이브러리.\n",
        "\n",
        "from transformers import AutoImageProcessor, TimesformerForVideoClassification # Hugging Face Transformers 라이브러리로, 여기서는 Timesformer 모델을 로드하고 사용.\n",
        "from huggingface_hub import hf_hub_download # Hugging Face Hub에서 데이터를 다운로드하기 위한 함수.\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# PyAV를 사용하여 지정된 인덱스의 프레임을 읽어오는 함수입니다.\n",
        "# container는 PyAV의 동영상 컨테이너 객체이고, indices는 읽어올 프레임 인덱스 리스트입니다.\n",
        "def read_video_pyav(container, indices):\n",
        "    '''\n",
        "    Decode the video with PyAV decoder.\n",
        "    Args:\n",
        "        container (`av.container.input.InputContainer`): PyAV container.\n",
        "        indices (`List[int]`): List of frame indices to decode.\n",
        "    Returns:\n",
        "        result (np.ndarray): np array of decoded frames of shape (num_frames, height, width, 3).\n",
        "    '''\n",
        "    frames = []\n",
        "    container.seek(0)\n",
        "    start_index = indices[0]\n",
        "    end_index = indices[-1]\n",
        "    for i, frame in enumerate(container.decode(video=0)):\n",
        "        if i > end_index:\n",
        "            break\n",
        "        if i >= start_index and i in indices:\n",
        "            frames.append(frame)\n",
        "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
        "\n",
        "\n",
        "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
        "    '''\n",
        "    Sample a given number of frame indices from the video.\n",
        "    Args:\n",
        "        clip_len (`int`): Total number of frames to sample.\n",
        "        frame_sample_rate (`int`): Sample every n-th frame.\n",
        "        seg_len (`int`): Maximum allowed index of sample's last frame.\n",
        "    Returns:\n",
        "        indices (`List[int]`): List of sampled frame indices\n",
        "    '''\n",
        "    converted_len = int(clip_len * frame_sample_rate)\n",
        "    end_idx = np.random.randint(converted_len, seg_len)\n",
        "    start_idx = end_idx - converted_len\n",
        "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
        "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
        "    return indices\n",
        "\n",
        "## huggingface hub에서 다운 받는 방법\n",
        "# video clip consists of 300 frames (10 seconds at 30 FPS)\n",
        "# file_path = hf_hub_download(\n",
        "#     repo_id=\"nielsr/video-demo\", filename=\"eating_spaghetti.mp4\", repo_type=\"dataset\"\n",
        "# )\n",
        "\n",
        "## local path에서 파일을 직접 불러오는 방법\n",
        "# file_path = \"./eating_spaghetti.mp4\"\n",
        "\n",
        "## PyAV를 사용해서 메모리에서 동영상 읽는 방법\n",
        "container = av.open(video_data)\n",
        "\n",
        "# sample 8 frames\n",
        "# sample_frame_indices(clip_len, frame_sample_rate, seg_len): 주어진 동영상에서 특정 프레임 인덱스를 샘플링하는 함수입니다.\n",
        "# clip_len은 샘플링할 총 프레임 수\n",
        "# frame_sample_rate는 샘플링할 프레임의 간격\n",
        "# seg_len은 동영상의 총 프레임 수입니다.\n",
        "indices = sample_frame_indices(clip_len=8, frame_sample_rate=1, seg_len=container.streams.video[0].frames)\n",
        "video = read_video_pyav(container, indices)\n",
        "\n",
        "# 이미지 전처리 및 모델 로드\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "model = TimesformerForVideoClassification.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
        "\n",
        "inputs = image_processor(list(video), return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "# model predicts one of the 400 Kinetics-400 classes\n",
        "predicted_label = logits.argmax(-1).item()\n",
        "print(model.config.id2label[predicted_label])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbQYCaJvSfZ3",
        "outputId": "5187720c-5039-4fde-e6ab-40a5afeb4f3e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "springboard diving\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GWxcdZd8SiHq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}