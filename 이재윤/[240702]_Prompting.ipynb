{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/%EC%9D%B4%EC%9E%AC%EC%9C%A4/%5B240702%5D_Prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PdN6jjSXJJLI",
        "outputId": "5548ca1b-f585-4361-b5f7-eb1edd73d52b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.35.7-py3-none-any.whl (327 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m327.5/327.5 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.35.7\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "private_key = userdata.get('OPEN-AI_KEY') # Your own secret key\n",
        "organization_id = \"org-CsaDwJgaYH1LgSRXtOwVARVC\" # SKI-ML Organization ID\n",
        "project_id = \"proj_OjWVsuIR4h3Yf6fmzDNXCp4H\" # Samsung AI_Expert project ID\n",
        "\n",
        "client = OpenAI(api_key=private_key,\n",
        "                organization=organization_id,\n",
        "                project=project_id)"
      ],
      "metadata": {
        "id": "VPuwwA2KJrgr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "def chatgpt(prompt: str) -> str:\n",
        "  completion = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "      {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "  )\n",
        "  return completion.choices[0].message.content.strip()"
      ],
      "metadata": {
        "id": "uBBEOZbZJ6ts"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Test\n",
        "\n",
        "chatgpt(\"hello\")"
      ],
      "metadata": {
        "id": "qbFE37TrKNb4",
        "outputId": "6b6f2c73-6f01-4069-d3b4-b764cdebe7aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I help you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot prompting\n",
        "Large language models (LLMs) today, such as GPT-3.5 Turbo, GPT-4, and Claude 3, are tuned to follow instructions and are trained on large amounts of data. Large-scale training makes these models capable of performing some tasks in a \"zero-shot\" manner. Zero-shot prompting means that the prompt used to interact with the model won't contain examples or demonstrations. The zero-shot prompt directly instructs the model to perform a task without any additional examples to steer it."
      ],
      "metadata": {
        "id": "CkK6isM0LrV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ZERO_SHOT=\"\"\"Classify the text into neutral, negative or positive.\n",
        "\n",
        "Text: I think the vacation is okay.\n",
        "Sentiment:\"\"\"\n",
        "chatgpt(ZERO_SHOT)"
      ],
      "metadata": {
        "id": "7S210nuRKRca",
        "outputId": "0852c161-4416-4047-a146-728e971231f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The sentiment of the text \"I think the vacation is okay\" is neutral.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your own zero shot prompt (in English or Korean)"
      ],
      "metadata": {
        "id": "G7Ore2ymr_Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_ZERO_SHOT_PROMPT=\"\"\"\n",
        "\"\"\"\n",
        "chatgpt(YOUR_ZERO_SHOT_PROMPT)"
      ],
      "metadata": {
        "id": "ChDCCH0Rr3DT",
        "outputId": "d12fd53b-9702-4a27-90c3-867e60db44c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Few-shot prompting\n",
        "While large-language models demonstrate remarkable zero-shot capabilities, they still fall short on more complex tasks when using the zero-shot setting. Few-shot prompting can be used as a technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance. The demonstrations serve as conditioning for subsequent examples where we would like the model to generate a response."
      ],
      "metadata": {
        "id": "FZ7pdAcWL21e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FEW_SHOT=\"\"\"\n",
        "Input: This is awesome!\n",
        "Output: Positive\n",
        "\n",
        "Input: This is bad!\n",
        "Output: Negative\n",
        "\n",
        "Input: Wow that movie was rad!\n",
        "Output: Positive\n",
        "\n",
        "Input: What a horrible show!\n",
        "Output: \"\"\"\n",
        "chatgpt(FEW_SHOT)"
      ],
      "metadata": {
        "id": "i4Myh8QrL0Hj",
        "outputId": "dabe38b7-92d5-45c2-8c92-2f34e438a9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Negative'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your own few shot prompt (in English)"
      ],
      "metadata": {
        "id": "F5-WfOgftuUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ZERO_SHOT=\"\"\"Find the next number in the sequence. Each number is doubled to get the next number.\n",
        "Input: 2, 4, 8, 16\n",
        "Output:\n",
        "\"\"\"\n",
        "print(chatgpt(ZERO_SHOT))"
      ],
      "metadata": {
        "id": "nYLXpyoHttQY",
        "outputId": "d3c830ce-a1db-4d5f-ea3d-ec1c35439e11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the next number in the sequence, we need to continue doubling the previous number. \n",
            "\n",
            "Given the sequence: 2, 4, 8, 16\n",
            "\n",
            "The next number would be obtained by multiplying the last number (16) by 2:\n",
            "\n",
            "16 * 2 = 32\n",
            "\n",
            "So, the next number in the sequence is 32.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YOUR_FEW_SHOT_PROMPT=\"\"\"Find the next number in the sequence. Each number is doubled to get the next number.\n",
        "\"\"\"\n",
        "print(chatgpt(YOUR_FEW_SHOT_PROMPT))"
      ],
      "metadata": {
        "id": "KS06WmSavQJr",
        "outputId": "36359012-42ff-4662-ed10-026dad87e675",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the next number in the sequence where each number is doubled to get the next number, we first need to know the initial number or numbers in the sequence. Once you provide me with the starting number or numbers, I can calculate the next number in the sequence for you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain-of-Thought Prompting\n",
        "Introduced in Wei et al. (2022), chain-of-thought (CoT) prompting enables complex reasoning capabilities through intermediate reasoning steps. You can combine it with few-shot prompting to get better results on more complex tasks that require reasoning before responding."
      ],
      "metadata": {
        "id": "pdTSu43uMrPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COT=\"\"\"The odd numbers in this group add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
        "A: Adding all the odd numbers (9, 15, 1) gives 25. The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  10, 19, 4, 8, 12, 24.\n",
        "A: Adding all the odd numbers (17, 19) gives 36. The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 16,  11, 14, 4, 8, 13, 24.\n",
        "A: Adding all the odd numbers (11, 13) gives 24. The answer is True.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\n",
        "A: Adding all the odd numbers (17, 9, 13) gives 39. The answer is False.\n",
        "\n",
        "The odd numbers in this group add up to an even number: 15, 32, 5, 13, 82, 7, 1.\n",
        "A:\"\"\"\n",
        "chatgpt(COT)"
      ],
      "metadata": {
        "id": "xJiKgYhnMO9c",
        "outputId": "8064b5d1-336e-4b8f-cb05-6b9f5e45e86e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Adding all the odd numbers (15, 5, 13, 7, 1) from the group gives 41. The answer is False.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-shot CoT"
      ],
      "metadata": {
        "id": "FlBXCmZTNSFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NORMAL_PROMPT=(\"I went to the market and bought 10 apples. \"\n",
        "               \"I gave 2 apples to the neighbor and 2 to the repairman. \"\n",
        "               \"I then went and bought 5 more apples and ate 1. \"\n",
        "               \"How many apples did I remain with?\")\n",
        "chatgpt(NORMAL_PROMPT)"
      ],
      "metadata": {
        "id": "GyVsdSJ3NT0N",
        "outputId": "fa248f3d-d8f9-4722-e778-696b67c31c2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'You started with 10 apples, gave 2 to the neighbor, and gave 2 to the repairman, which leaves you with 6 apples. \\n\\nAfter buying 5 more apples, you had a total of 6 + 5 = 11 apples.\\n\\nIf you ate 1 apple, you would have 11 - 1 = 10 apples remaining. \\n\\nTherefore, you remained with 10 apples.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ZERO_SHOT_COT=(\"I went to the market and bought 10 apples. \"\n",
        "               \"I gave 2 apples to the neighbor and 2 to the repairman. \"\n",
        "               \"I then went and bought 5 more apples and ate 1. \"\n",
        "               \"How many apples did I remain with? \"\n",
        "               \"Let's think step by step.\")\n",
        "chatgpt(ZERO_SHOT_COT)"
      ],
      "metadata": {
        "id": "paSom8G1Nlqq",
        "outputId": "e23097d4-d085-46e4-d597-b7e714eeb83d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Of course! Let's break it down step by step:\\n\\n1. You started with 10 apples.\\n2. You gave 2 apples to the neighbor, so you are left with 10 - 2 = 8 apples.\\n3. You gave another 2 apples to the repairman, so you now have 8 - 2 = 6 apples.\\n4. You then bought 5 more apples, adding them to your 6 apples, which gives you 6 + 5 = 11 apples.\\n5. After eating 1 of these apples, you will have 11 - 1 = 10 apples remaining.\\n\\nTherefore, you are left with 10 apples in total.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Chaining\n",
        "To improve the reliability and performance of LLMs, one of the important prompt engineering techniques is to break tasks into its subtasks. Once those subtasks have been identified, the LLM is prompted with a subtask and then its response is used as input to another prompt. This is what's referred to as prompt chaining, where a task is split into subtasks with the idea to create a chain of prompt operations."
      ],
      "metadata": {
        "id": "aWAyjRk7OMp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the first prompt\n",
        "prompt_1 = \"What are the key ingredients of a successful marketing campaign?\"\n",
        "\n",
        "# Get the response from the first prompt\n",
        "response_1 = chatgpt(prompt_1)\n",
        "\n",
        "# Define the second prompt, using the response from the first prompt as input\n",
        "prompt_2 = f\"Based on the key ingredients you mentioned, provide specific examples of how a business can implement them in their marketing campaign. Use the following format: \\n\\nIngredient: \\nExample:\\n\\n{response_1}\"\n",
        "\n",
        "# Get the response from the second prompt\n",
        "response_2 = chatgpt(prompt_2)\n",
        "\n",
        "# Print the responses from both prompts\n",
        "print(f\"Response to prompt 1: {response_1}\")\n",
        "print(f\"\\nResponse to prompt 2: {response_2}\")"
      ],
      "metadata": {
        "id": "UYTBxZMlAo41",
        "outputId": "2ed3e126-5ce9-44e2-938e-eca4c35f62c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response to prompt 1: Key ingredients of a successful marketing campaign include:\n",
            "\n",
            "1. Clear objectives and goals: Define what you want to achieve with your campaign.\n",
            "2. Knowing your target audience: Understand who your ideal customers are and what appeals to them.\n",
            "3. Strong branding: Develop a consistent brand identity that resonates with your audience.\n",
            "4. Compelling message: Create a message that is clear, concise, and resonates with your target audience.\n",
            "5. Multi-channel approach: Utilize a mix of different marketing channels to reach your audience where they are.\n",
            "6. Consistent and cohesive campaign: Ensure all aspects of your campaign work together seamlessly.\n",
            "7. Tracking and analytics: Monitor and measure the performance of your campaign to make data-driven decisions.\n",
            "8. Flexibility: Be prepared to adapt and adjust your campaign based on feedback and results.\n",
            "9. Budget management: Allocate resources wisely to maximize the impact of your campaign.\n",
            "10. Innovation and creativity: Stand out from the competition by introducing unique and engaging elements to your campaign.\n",
            "\n",
            "Response to prompt 2: Ingredient: Clear objectives and goals\n",
            "\n",
            "Example: A business launching a new product can set a specific objective of achieving 1,000 pre-orders within the first month of the campaign. By clearly defining this goal, the marketing team can tailor their strategies and tactics to drive pre-order sales, such as offering early-bird discounts or partnering with influencers to promote the product.\n",
            "\n",
            "Ingredient: Knowing your target audience\n",
            "\n",
            "Example: A boutique fitness studio targeting young professionals can create marketing content that highlights the convenience of their class schedule for busy individuals. By understanding the preferences and pain points of their target audience, the studio can design campaigns that resonate with this demographic, such as offering specialized classes during peak hours or showcasing testimonials from customers with similar lifestyles.\n",
            "\n",
            "Ingredient: Strong branding\n",
            "\n",
            "Example: A coffee shop with a rustic, eco-friendly brand identity can incorporate sustainable practices into their marketing campaign. This can include promoting their use of fair-trade coffee beans, biodegradable packaging, and energy-efficient equipment. By aligning their branding with their sustainability efforts, the coffee shop can attract environmentally conscious customers who value ethical practices.\n",
            "\n",
            "Ingredient: Compelling message\n",
            "\n",
            "Example: An outdoor gear retailer can create a campaign focused on the message of \"Empower Your Adventures\" to inspire customers to embrace outdoor activities and explore new experiences. The message can be conveyed through visually appealing content featuring adventurous individuals using the retailer's products in scenic locations, evoking a sense of excitement and freedom associated with outdoor exploration.\n",
            "\n",
            "Ingredient: Multi-channel approach\n",
            "\n",
            "Example: An e-commerce fashion brand targeting millennials can implement a multi-channel approach by combining social media advertising, influencer partnerships, email marketing, and a user-friendly website. By reaching customers through various channels where they spend their time online, the brand can increase visibility, engage with different audience segments, and drive conversions through integrated marketing efforts.\n",
            "\n",
            "Ingredient: Consistent and cohesive campaign\n",
            "\n",
            "Example: A restaurant launching a new menu can ensure cohesiveness by maintaining consistency in messaging, visuals, and promotions across all marketing channels. By using the same color scheme, tone of voice, and key selling points in their social media posts, email newsletters, website updates, and in-store signage, the restaurant can create a unified brand experience that reinforces the new menu offerings and encourages customer engagement.\n",
            "\n",
            "Ingredient: Tracking and analytics\n",
            "\n",
            "Example: An online beauty retailer can track the performance of their marketing campaign by analyzing key metrics such as website traffic, conversion rates, customer engagement, and ROI. By using tools like Google Analytics, social media insights, and email marketing analytics, the retailer can gain insights into which channels are driving the most revenue, which campaigns are resonating with customers, and where improvements can be made to optimize marketing efforts for better results.\n",
            "\n",
            "Ingredient: Flexibility\n",
            "\n",
            "Example: A software company running a digital marketing campaign can demonstrate flexibility by tweaking their ad creatives, targeting parameters, or messaging based on real-time feedback and performance data. If certain ads are underperforming, the company can quickly adjust the budget allocation, update the messaging, or test new visuals to improve campaign effectiveness and ROI.\n",
            "\n",
            "Ingredient: Budget management\n",
            "\n",
            "Example: A small business promoting a seasonal sale can effectively manage their budget by allocating resources based on the expected ROI of each marketing channel. For example, the business may invest a larger portion of the budget in online ads and social media promotions, which have a track record of driving sales during previous sales events, while allocating a smaller budget for print advertising or direct mail campaigns with lower conversion rates.\n",
            "\n",
            "Ingredient: Innovation and creativity\n",
            "\n",
            "Example: A tech startup launching a crowdfunding campaign for a new product can introduce innovation and creativity by engaging customers through interactive content, gamification elements, and personalized rewards. By offering backers the opportunity to customize their product features, unlock exclusive perks, and participate in virtual product demos, the startup can generate excitement, foster a sense of community, and differentiate their campaign from traditional fundraising efforts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write your own chaining prompt (in English or Korean)"
      ],
      "metadata": {
        "id": "JzThrJgGv2xO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = \"\"\n",
        "\n",
        "response_1 = chatgpt(prompt_1)\n",
        "\n",
        "prompt_2 = f\"{response_1}\"\n",
        "\n",
        "response_2 = chatgpt(prompt_2)\n",
        "\n",
        "print(f\"Response to prompt 1: {response_1}\")\n",
        "print(f\"\\nResponse to prompt 2: {response_2}\")"
      ],
      "metadata": {
        "id": "hEe2GLfOv2EB",
        "outputId": "dc88ebc6-d1b7-4d96-e588-9057f9c98b73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response to prompt 1: Hello! How can I assist you today?\n",
            "\n",
            "Response to prompt 2: Hello! I'm here to help. What do you need assistance with today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Directional Stimulus Prompting\n",
        "Li et al., (2023) proposes a new prompting technique to better guide the LLM in generating the desired summary.\n",
        "\n",
        "A tuneable policy LM is trained to generate the stimulus/hint. Seeing more use of RL to optimize LLMs.\n",
        "\n",
        "The figure below shows how Directional Stimulus Prompting compares with standard prompting. The policy LM can be small and optimized to generate the hints that guide a black-box frozen LLM.\n",
        "\n",
        "![image](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdsp.27a0005f.jpeg&w=3840&q=75)"
      ],
      "metadata": {
        "id": "RAIbbs_rORgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rouge-score"
      ],
      "metadata": {
        "id": "BWKMJ6q-DtZE",
        "outputId": "d3b25ed3-2be3-46cc-938c-0eb3cb055225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.25.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->rouge-score) (4.66.4)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=0c307a664919280bbc1805dbb55d736a3028fbf060cd0c0d3a4544a7e99134ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "def calculate_rouge1(system_summary, reference_summary):\n",
        "    # Create a ROUGE scorer for ROUGE-1\n",
        "    scorer = rouge_scorer.RougeScorer(['rouge1'], use_stemmer=True)\n",
        "    # Calculate the score\n",
        "    scores = scorer.score(reference_summary, system_summary)\n",
        "    return scores['rouge1']"
      ],
      "metadata": {
        "id": "nnqYfdrDCzOi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"\"\"Article: (CNN) For the first time in eight years, a TV legend returned to doing what he does best. Contestants told to \"come on down!\" on the April 1 edition of \"The Price Is Right\" encountered not host Drew Carey but another familiar face in charge of the proceedings. Instead, there was Bob Barker, who hosted the TV game show for 35 years before stepping down in 2007. Looking spry at 91, Barker handled the first price-guessing game of the show, the classic \"Lucky Seven,\" before turning hosting duties over to Carey, who finished up. Despite being away from the show for most of the past eight years, Barker didn't seem to miss a beat.\"\"\"\n",
        "reference_text = \"\"\"Bob Barker returned to host \"The Price Is Right\" on Wednesday. Barker, 91, had retired as host in 2007.\"\"\"\n",
        "NORMAL_PROMPT = f\"\"\"{input_text}\\n\n",
        "Q: Summarize the above article briefly in 2-3 sentences.\n",
        "\n",
        "Output:\n",
        "\"\"\"\n",
        "DSP_PROMPT = f\"\"\"{input_text}\\n\n",
        "Q: Summarize the above article briefly in 2-3 sentences based on the hint.\n",
        "Hint: Bob Barker; TV; April 1; \"The Price Is Right\"; 2007; 91.\n",
        "\n",
        "Output:\n",
        "\"\"\"\n",
        "normal_summary = chatgpt(NORMAL_PROMPT)\n",
        "dsp_summary = chatgpt(DSP_PROMPT)\n",
        "normal_rouge1_score = calculate_rouge1(normal_summary, reference_text)\n",
        "dsp_rouge1_score = calculate_rouge1(dsp_summary, reference_text)\n",
        "print(\"ROUGE-1 Score (Normal Prompt):\", normal_rouge1_score)\n",
        "print(\"ROUGE-1 Score (DSP Prompt):\", dsp_rouge1_score)\n"
      ],
      "metadata": {
        "id": "FaVkNbSfA3fR",
        "outputId": "dd4a9110-5409-41b1-b8ef-544972b1a8d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE-1 Score (Normal Prompt): Score(precision=0.17391304347826086, recall=0.631578947368421, fmeasure=0.2727272727272727)\n",
            "ROUGE-1 Score (DSP Prompt): Score(precision=0.25, recall=0.6842105263157895, fmeasure=0.36619718309859156)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ReACT Prompting\n",
        "ReAct is inspired by the synergies between \"acting\" and \"reasoning\" which allow humans to learn new tasks and make decisions or reasoning.\n",
        "\n",
        "Chain-of-thought (CoT) prompting has shown the capabilities of LLMs to carry out reasoning traces to generate answers to questions involving arithmetic and commonsense reasoning, among other tasks (Wei et al., 2022). But its lack of access to the external world or inability to update its knowledge can lead to issues like fact hallucination and error propagation.\n",
        "\n",
        "ReAct is a general paradigm that combines reasoning and acting with LLMs. ReAct prompts LLMs to generate verbal reasoning traces and actions for a task. This allows the system to perform dynamic reasoning to create, maintain, and adjust plans for acting while also enabling interaction to external environments (e.g., Wikipedia) to incorporate additional information into the reasoning. The figure below shows an example of ReAct and the different steps involved to perform question answering."
      ],
      "metadata": {
        "id": "zmqQAqQxOimL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community langchain-core\n",
        "!pip install -U google-search-results\n",
        "!pip install -U langchain-openai\n",
        "!pip install -U wikipedia"
      ],
      "metadata": {
        "id": "ebqaRjR6FuTg",
        "outputId": "aad381c1-5be5-4ac6-ba70-86a5d293e434",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core\n",
            "  Downloading langchain_core-0.2.10-py3-none-any.whl (332 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m332.8/332.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting langchain<0.3.0,>=0.2.6 (from langchain-community)\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl (975 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m975.5/975.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.2.0,>=0.1.0 (from langchain-community)\n",
            "  Downloading langsmith-0.1.83-py3-none-any.whl (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.5/127.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.4.2)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.7.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.6->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-community)\n",
            "  Downloading orjson-3.10.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.0/145.0 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: orjson, mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.6 langchain-community-0.2.6 langchain-core-0.2.10 langchain-text-splitters-0.2.2 langsmith-0.1.83 marshmallow-3.21.3 mypy-extensions-1.0.0 orjson-3.10.5 typing-inspect-0.9.0\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.6.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32004 sha256=1f333fde704ef4ca92b07bb2f7c9dfc07e12f6d0f56f4ec71a64a5423317c547\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.13-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.10)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.35.7)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.83)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.4.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.5)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
            "Installing collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.1.13 tiktoken-0.7.0\n",
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11680 sha256=2c21b6f090ae2630f7670e2d6761f7f453f1b356294a3c8d902164dca3bcfedf\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent, Tool"
      ],
      "metadata": {
        "id": "Pz7saQkENDDc"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents.react.base import DocstoreExplorer\n",
        "from langchain.agents import AgentType\n",
        "from langchain import Wikipedia\n",
        "docstore=DocstoreExplorer(Wikipedia())\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Search\",\n",
        "        func=docstore.search,\n",
        "        description=\"useful for when you need to ask with search\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Lookup\",\n",
        "        func=docstore.lookup,\n",
        "        description=\"useful for when you need to ask with lookup\"\n",
        "    )\n",
        "]\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model_name=\"gpt-3.5-turbo\", api_key=private_key, organization=organization_id)\n",
        "react = initialize_agent(tools, llm, agent=AgentType.REACT_DOCSTORE, verbose=True, handle_parsing_errors=True)\n",
        "\n",
        "react.run(\"Author David Chanoff has collaborated with a U.S. Navy admiral who served as the ambassador to the United Kingdom under which President?\")"
      ],
      "metadata": {
        "id": "ZmAqCZZwyOIK",
        "outputId": "c0b3313a-2055-4069-f875-5888741267a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `DocstoreExplorer` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search David Chanoff, find the U.S. Navy admiral he collaborated with, then find out which President the admiral served as the ambassador to the United Kingdom under.\n",
            "Action: Search[David Chanoff]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mDavid Chanoff (born November 15, 1943, in Philadelphia) is an American author of non-fiction work. His work has typically involved collaborations with the principal protagonist of the work concerned. His collaborators have included Augustus A. White, Joycelyn Elders, Đoàn Văn Toại, William J. Crowe, Ariel Sharon, Kenneth Good and Felix Zandman, among others. He has also written about a wide range of subjects including literary history, education and foreign for The Washington Post, The New Republic and The New York Times Magazine.\n",
            "Chanoff founded Sudbury Valley School in Framingham, Massachusetts in 1968. In the late 1970s and early 1980s, he taught English at Tufts University and Harvard University. \n",
            "In 2015, Chanoff's Breaking Ground: My Life in Medicine, co-written with  Louis W. Sullivan, won the NAACP Image Award for Outstanding Literary Work – Biography/Autobiography.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mDavid Chanoff has collaborated with Louis W. Sullivan. I need to search Louis W. Sullivan and find out which President he served as the ambassador to the United Kingdom under.\n",
            "Action: Search[Louis W. Sullivan]\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mLouis Wade Sullivan (born November 3, 1933) is an active health policy leader, minority health advocate, author, physician, and educator. He served as the Secretary of the United States Department of Health and Human Services during President George H. W. Bush's Administration and was Founding Dean of the Morehouse School of Medicine.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mLouis W. Sullivan served as the Secretary of the United States Department of Health and Human Services under President George H. W. Bush. So, the U.S. Navy admiral that David Chanoff collaborated with served as the ambassador to the United Kingdom under President George H. W. Bush.\n",
            "Action: Finish[George H. W. Bush]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'George H. W. Bush'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Print template used by LangChain\n",
        "print(react.agent.llm_chain.prompt.template)"
      ],
      "metadata": {
        "id": "Rk-Hiu7eNzdf",
        "outputId": "4412dcd3-3b2f-4844-9510-472e108ed1be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Question: What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\n",
            "Thought: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n",
            "Action: Search[Colorado orogeny]\n",
            "Observation: The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n",
            "Thought: It does not mention the eastern sector. So I need to look up eastern sector.\n",
            "Action: Lookup[eastern sector]\n",
            "Observation: (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.\n",
            "Thought: The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n",
            "Action: Search[High Plains]\n",
            "Observation: High Plains refers to one of two distinct land regions\n",
            "Thought: I need to instead search High Plains (United States).\n",
            "Action: Search[High Plains (United States)]\n",
            "Observation: The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).[3]\n",
            "Thought: High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n",
            "Action: Finish[1,800 to 7,000 ft]\n",
            "\n",
            "Question: Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening named after who?\n",
            "Thought: The question simplifies to \"The Simpsons\" character Milhouse is named after who. I only need to search Milhouse and find who it is named after.\n",
            "Action: Search[Milhouse]\n",
            "Observation: Milhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons voiced by Pamela Hayden and created by Matt Groening.\n",
            "Thought: The paragraph does not tell who Milhouse is named after, maybe I can look up \"named after\".\n",
            "Action: Lookup[named after]\n",
            "Observation: (Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\n",
            "Thought: Milhouse was named after U.S. president Richard Nixon, so the answer is Richard Nixon.\n",
            "Action: Finish[Richard Nixon]\n",
            "\n",
            "Question: Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\n",
            "Thought: I need to search Adam Clayton Powell and The Saimaa Gesture, and find which documentary is about Finnish rock groups.\n",
            "Action: Search[Adam Clayton Powell]\n",
            "Observation: Could not find [Adam Clayton Powell]. Similar: [’Adam Clayton Powell III’, ’Seventh Avenue (Manhattan)’, ’Adam Clayton Powell Jr. State Office Building’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell (film)’, ’Giancarlo Esposito’].\n",
            "Thought: To find the documentary, I can search Adam Clayton Powell (film).\n",
            "Action: Search[Adam Clayton Powell (film)]\n",
            "Observation: Adam Clayton Powell is a 1989 American documentary film directed by Richard Kilberg. The film is about the rise and fall of influential African-American politician Adam Clayton Powell Jr.[3][4] It was later aired as part of the PBS series The American Experience.\n",
            "Thought: Adam Clayton Powell (film) is a documentary about an African-American politician, not Finnish rock groups. So the documentary about Finnish rock groups must instead be The Saimaa Gesture.\n",
            "Action: Finish[The Saimaa Gesture]\n",
            "\n",
            "Question: What profession does Nicholas Ray and Elia Kazan have in common?\n",
            "Thought: I need to search Nicholas Ray and Elia Kazan, find their professions, then find the profession they have in common.\n",
            "Action: Search[Nicholas Ray]\n",
            "Observation: Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 - June 16, 1979) was an American film director, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\n",
            "Thought: Professions of Nicholas Ray are director, screenwriter, and actor. I need to search Elia Kazan next and find his professions.\n",
            "Action: Search[Elia Kazan]\n",
            "Observation: Elia Kazan was an American film and theatre director, producer, screenwriter and actor.\n",
            "Thought: Professions of Elia Kazan are director, producer, screenwriter, and actor. So profession Nicholas Ray and Elia Kazan have in common is director, screenwriter, and actor.\n",
            "Action: Finish[director, screenwriter, actor]\n",
            "\n",
            "Question: Which magazine was started first Arthur’s Magazine or First for Women?\n",
            "Thought: I need to search Arthur’s Magazine and First for Women, and find which was started first.\n",
            "Action: Search[Arthur’s Magazine]\n",
            "Observation: Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th century.\n",
            "Thought: Arthur’s Magazine was started in 1844. I need to search First for Women next.\n",
            "Action: Search[First for Women]\n",
            "Observation: First for Women is a woman’s magazine published by Bauer Media Group in the USA.[1] The magazine was started in 1989.\n",
            "Thought: First for Women was started in 1989. 1844 (Arthur’s Magazine) < 1989 (First for Women), so Arthur’s Magazine was started first.\n",
            "Action: Finish[Arthur’s Magazine]\n",
            "\n",
            "Question: Were Pavel Urysohn and Leonid Levin known for the same type of work?\n",
            "Thought: I need to search Pavel Urysohn and Leonid Levin, find their types of work, then find if they are the same.\n",
            "Action: Search[Pavel Urysohn]\n",
            "Observation: Pavel Samuilovich Urysohn (February 3, 1898 - August 17, 1924) was a Soviet mathematician who is best known for his contributions in dimension theory.\n",
            "Thought: Pavel Urysohn is a mathematician. I need to search Leonid Levin next and find its type of work.\n",
            "Action: Search[Leonid Levin]\n",
            "Observation: Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.\n",
            "Thought: Leonid Levin is a mathematician and computer scientist. So Pavel Urysohn and Leonid Levin have the same type of work.\n",
            "Action: Finish[yes]\n",
            "\n",
            "\n",
            "Question: {input}\n",
            "{agent_scratchpad}\n"
          ]
        }
      ]
    }
  ]
}