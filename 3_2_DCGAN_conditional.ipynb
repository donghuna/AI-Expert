{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/3_2_DCGAN_conditional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conditional Deep Convolutional Generative Adversarial Network"
      ],
      "metadata": {
        "id": "4cN2n4y9dXKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Overview\n",
        "이번 실습에서는 Conditional DCGAN을 구현하고, MNIST dataset을 이용하여 학습해보록 하겠습니다.  \n",
        "\n",
        "지금까지 실습했던 Generative model들은, 특정 class에 대한 생성이 불가능한 model들이었습니다.\n",
        "CGAN은 이미지 생성시에 Class condition을 활용하여, 특정 클래스의 이미지 생성이 가능합니다.\n",
        "\n",
        "- 이 실습자료는 [GAN-Tutorial](https://github.com/Yangyangii/GAN-Tutorial)을 기반으로 작성되었습니다."
      ],
      "metadata": {
        "id": "U3F8NnYIdZZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup\n",
        "\n",
        "우선, DCGAN 구현을 위해 필요한 패키지들을 설치하고 import하도록 하겠습니다."
      ],
      "metadata": {
        "id": "k2AH1PlEdrN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "import numpy as np\n",
        "import datetime\n",
        "import os, sys\n",
        "\n",
        "from matplotlib.pyplot import imshow, imsave\n",
        "\n",
        "DEVICE = torch.device('cuda')"
      ],
      "metadata": {
        "id": "SKzf77HadbKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load and prepare the dataset\n",
        "\n",
        "이번 실습에서 사용할 MNIST dataset을 다운로드하고, 로드하겠습니다."
      ],
      "metadata": {
        "id": "eK8enqDidzCh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize(mean=[0.5],\n",
        "                                std=[0.5])]\n",
        ")\n",
        "\n",
        "mnist = datasets.MNIST(root='./data/', train=True, transform=transform, download=True)\n",
        "data_loader = DataLoader(dataset=mnist, batch_size=batch_size, shuffle=True, drop_last=True)"
      ],
      "metadata": {
        "id": "hwizpnoDd0PR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CGAN 구현\n",
        "\n",
        "지금부터 CGAN 모델을 구현하도록 하겠습니다.\n",
        "이에 앞서 class condition 정보를 neural network가 받아들이기 편리하도록 0~1의 정수값에서 one hot vector로 만드는 코드를 준비하도록 하겠습니다.\n"
      ],
      "metadata": {
        "id": "6kF1vrMUd-wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_onehot(label, num_classes=10):\n",
        "    assert isinstance(label, int) or isinstance(label, (torch.LongTensor, torch.cuda.LongTensor))\n",
        "    if isinstance(label, int):\n",
        "        c = torch.zeros(1, num_classes).long()\n",
        "        c[0][label] = 1\n",
        "    else:\n",
        "        label = label.cpu()\n",
        "        c = torch.LongTensor(label.size(0), num_classes)\n",
        "        c.zero_()\n",
        "        c.scatter_(1, label, 1) # dim, index, src value\n",
        "    return c"
      ],
      "metadata": {
        "id": "mB5vp-7qSST0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Generator\n",
        "\n",
        "- Generator input:\n",
        "  - latent z: [batch, 100]\n",
        "  - class y: [batch, 10] (one-hot vector)\n",
        "\n",
        "- Generator output:\n",
        "  - generated image G(z): [batch, 1, 28, 28]\n",
        "\n",
        "- 기존 DCGAN과 대체로 유사하지만, input을 맞추어주는 layer가 추가로 필요합니다.\n",
        "  * **Concat & FC**: (z, one-hot vector) [batch, 100+10] -> hidden feature [batch, 512x512x4]\n",
        "    "
      ],
      "metadata": {
        "id": "xRY44E5IeAKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Generator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size=100, condition_size=10):\n",
        "        super(Generator, self).__init__()\n",
        "        ##################### ToDo #####################\n",
        "        self.fc = nn.Sequential(\n",
        "\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            # input: 4 by 4, output: 7 by 7\n",
        "\n",
        "            # input: 7 by 7, output: 14 by 14\n",
        "\n",
        "            # input: 14 by 14, output: 28 by 28\n",
        "\n",
        "        )\n",
        "        ##################################################\n",
        "\n",
        "    def forward(self, z, y):\n",
        "        # x: (N, 100), c: (N, 10)\n",
        "        z, y = z.view(z.size(0), -1), y.float() # may not need\n",
        "        x = torch.cat((z, y), 1) # v: (N, 110)\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), 512, 4, 4)\n",
        "        x = self.conv(x) # (N, 28, 28)\n",
        "        return x"
      ],
      "metadata": {
        "id": "U_LCD0fMeI8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "G = Generator().to(DEVICE)"
      ],
      "metadata": {
        "id": "mkekj_toJjGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Discriminator\n",
        "\n",
        "- Discriminator input:\n",
        "  - real/fake image  x: [batch, 28, 28, 1]\n",
        "  - class y: [batch, 10] (one-hot vector)\n",
        "\n",
        "- Discriminator output:\n",
        "  - real probability D(x): [batch, 10] with value range (0, 1)\n",
        "\n",
        "- 기존 DCGAN의 discriminator와 달리, real/fake 이미지 외에 class contition y도 입력으로 받습니다. 이를 CNN에서 추가 정보로 활용하기 위해 이미지에 추가 채널로 concat하여 사용하게 됩니다.\n",
        "이를 위해 class y [batch, 10]을 image shape으로 만들어주는 layer가 추가로 필요하게됩니다.\n",
        "  1. **FC_y**: [batch, 10] → [batch, 28x28=784]\n",
        "  2. **y reshape**: [batch, 28x28=784] → [batch, 1, 28, 28]\n",
        "  3. **concat**: (x, y) [batch, 1+1, 28, 28]\n"
      ],
      "metadata": {
        "id": "r6njw3NHfuUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"\n",
        "        Convolutional Discriminator for MNIST\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channel=1, input_size=784, condition_size=10, num_classes=1):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        ##################### ToDo #####################\n",
        "        self.transform = nn.Sequential(\n",
        "\n",
        "        )\n",
        "        self.conv = nn.Sequential(\n",
        "            # 28 -> 14\n",
        "\n",
        "            # 14 -> 7\n",
        "\n",
        "            # 7 -> 4\n",
        "\n",
        "        )\n",
        "        self.fc = nn.Sequential(\n",
        "\n",
        "        )\n",
        "        ###################################################\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        # x: (N, 1, 28, 28), c: (N, 10)\n",
        "        x, y = x.float(), y.float() # may not need\n",
        "\n",
        "        y = self.transform(y)\n",
        "        y = y.view(y.size(0), 1, 28, 28)\n",
        "        h = torch.cat((x, y), 1) # v: (N, 2, 28, 28)\n",
        "\n",
        "        h = self.conv(h)\n",
        "        h = h.view(h.size(0), -1)\n",
        "        h = self.fc(h)\n",
        "        return h"
      ],
      "metadata": {
        "id": "1IJilr8yfyOa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator().to(DEVICE)"
      ],
      "metadata": {
        "id": "anraH21tLyqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss와 Optimizer 정의\n",
        "\n",
        "모델 학습을 위해 loss와 optimizer를 선언해주도록 하겠습니다."
      ],
      "metadata": {
        "id": "0h9_33j_MWK1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Discriminator loss\n",
        "\n",
        "아래 코드는 Discriminator를 위한 loss 구현 코드입니다.  \n",
        "Discriminator의 학습 목표는, real image에 대해서는 1(or 높은 확률값)을 반환하고, fake image에 대해서는 0(or 낮은 확률값)을 반환하는 것입니다."
      ],
      "metadata": {
        "id": "khd1dKFeM9Ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(real_output, fake_output):\n",
        "    ################ ToDo ##################\n",
        "    D_real_labels = torch.ones_like(real_output)\n",
        "    D_fake_labels = torch.zeros_like(fake_output)\n",
        "\n",
        "    real_loss =\n",
        "    fake_loss =\n",
        "    total_loss = real_loss + fake_loss\n",
        "    ########################################\n",
        "    return total_loss"
      ],
      "metadata": {
        "id": "w9-piqlaL7Jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generator loss\n",
        "아래 코드는 Generator를 위한 loss 구현 코드입니다.  \n",
        "Generator의 학습 목표는, discriminator를 속이는 것이며, 이는 fake output에 대해 1(or 높은 확률값)을 반환하도록 하는 것입니다."
      ],
      "metadata": {
        "id": "MllC_jWYNAUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generator_loss(fake_output):\n",
        "    ################ ToDo ##################\n",
        "    G_fake_labels =\n",
        "    loss =\n",
        "    ########################################\n",
        "    return loss"
      ],
      "metadata": {
        "id": "ySYHryMgM5mB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드는 각각의 model에 대한 optimizer를 선언해주는 코드입니다."
      ],
      "metadata": {
        "id": "Gi1N_oDXNO7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D_opt = torch.optim.Adam(D.parameters(), lr=0.0005, betas=(0.5, 0.999))\n",
        "G_opt = torch.optim.Adam(G.parameters(), lr=0.0005, betas=(0.5, 0.999))"
      ],
      "metadata": {
        "id": "La7FGvkZNQhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the training loop"
      ],
      "metadata": {
        "id": "IQXfFrViNTXl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "noise_dim = 100\n",
        "num_examples_to_generate = 16\n",
        "global_step = 0\n",
        "n_critic = 1"
      ],
      "metadata": {
        "id": "bKIVRBl8Ne1-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래 코드는 DCGAN 학습을 위한 train_step 코드입니다.  \n",
        "1. 각 train_step마다 Generator는 **BATCH_SIZE**개 만큼의 이미지를 생성합니다.  \n",
        "2. Discriminator는 Generator가 만든 **BATCH_SIZE**개의 이미지와, training set에서 가져온 **BATCH_SIZE**개의 이미지, 총 **2xBATCH_SIZE**개의 이미지에 대해 real/fake 판별을 진행합니다.\n",
        "3. 이후 Generator, Discriminator에 대한 loss를 계산하고, Gradient를 계산한 뒤\n",
        "4. Model의 Parameter를 업데이트해주게 됩니다."
      ],
      "metadata": {
        "id": "hV-Ulb2PNcoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G.train()\n",
        "D.train()\n",
        "\n",
        "G_train_loss_list = []\n",
        "D_train_loss_list = []\n",
        "\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    for idx, (images, labels) in enumerate(data_loader):\n",
        "        # Training Discriminator\n",
        "        x = images.to(DEVICE)\n",
        "        y = labels.view(labels.shape[0], 1)\n",
        "        y_onehot = to_onehot(y).to(DEVICE)\n",
        "\n",
        "        D_real_preds = D(x, y_onehot)\n",
        "\n",
        "        z = torch.randn(batch_size, noise_dim).to(DEVICE)\n",
        "        D_fake_preds = D(G(z, y_onehot), y_onehot)\n",
        "\n",
        "        D_loss = discriminator_loss(D_real_preds, D_fake_preds)\n",
        "\n",
        "        D.zero_grad()\n",
        "        D_loss.backward()\n",
        "        D_opt.step()\n",
        "\n",
        "        if global_step % n_critic == 0:\n",
        "            # Training Generator\n",
        "            z = torch.randn(batch_size, noise_dim).to(DEVICE)\n",
        "            D_fake_preds = D(G(z, y_onehot), y_onehot)\n",
        "            G_loss = generator_loss(D_fake_preds)\n",
        "\n",
        "            D.zero_grad()\n",
        "            G.zero_grad()\n",
        "            G_loss.backward()\n",
        "            G_opt.step()\n",
        "\n",
        "            G_train_loss_list.append(G_loss.data.item())\n",
        "            D_train_loss_list.append(D_loss.data.item())\n",
        "\n",
        "        if global_step % 500 == 0:\n",
        "            print('Epoch: {}/{}, Step: {}, D Loss: {}, G Loss: {}'.format(epoch, EPOCHS, global_step, D_loss.item(), G_loss.item()))\n",
        "\n",
        "        global_step += 1"
      ],
      "metadata": {
        "id": "Dnl88_dYNYWN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.ion()\n",
        "\n",
        "fig = plt.figure()\n",
        "plt.plot(G_train_loss_list)\n",
        "plt.plot(D_train_loss_list)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kcRbsiyVOl_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate and save images\n",
        "아래 코드는 모델로부터 이미지를 생성하고 이를 확인하는 코드입니다."
      ],
      "metadata": {
        "id": "ETPAUtvUPNFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.utils import make_grid\n",
        "\n",
        "G.eval()\n",
        "\n",
        "n_samples = 100\n",
        "\n",
        "with torch.no_grad():\n",
        "  z = torch.randn(n_samples, 100).to(DEVICE)\n",
        "  y = torch.arange(10).view(10, 1).repeat(1, 10).view(100, 1)\n",
        "  y_onehot = to_onehot(y).to(DEVICE)\n",
        "  x_hat = G(z, y_onehot)\n",
        "\n",
        "img = make_grid(x_hat, nrow=10, normalize=True, value_range=(-1., 1.)).permute(1, 2, 0).cpu().data.numpy()\n",
        "\n",
        "imshow(img, cmap='gray')"
      ],
      "metadata": {
        "id": "h0RuWsa2PeIm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}