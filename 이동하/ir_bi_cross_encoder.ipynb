{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/%EC%9D%B4%EB%8F%99%ED%95%98/ir_bi_cross_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MUpHHPdfHxZ"
      },
      "source": [
        "# Document Retrieval with Bi-Encoder and Cross-Encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2qGxGuOfHxb"
      },
      "source": [
        "In this course, we will cover the process of utilizing bi-encoder and cross encoder to retrieve documents relevant to our query"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctmm7MwefHxb"
      },
      "source": [
        "<div style=\"text-align : center;\">\n",
        "    <img width=\"800\" alt=\"bi_encoder\" src=\"https://github.com/augustinLib/All-of-NLP/assets/74291999/4c196702-aee7-48b8-8ea9-d655a18bae71\">\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6sakYlEfHxb"
      },
      "source": [
        "## Ready to start"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLpbMT8kfHxb"
      },
      "source": [
        "We will use the `sentence-transformers` library to implement the bi-encoder and cross-encoder models. The library provides encoder models that can be used to encode text into embeddings.  \n",
        "\n",
        "`faiss` is a library that is used to perform similarity search on the embeddings. We will use it to retrieve the most relevant documents to our query.  \n",
        "\n",
        "For Dataset, we will use the `MS-MARCO` dataset. `MS-MARCO` is a collection of queries and web pages from Bing search, and contains queries and documents that are relevant to the queries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiDl0gBNfHxc"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPBOTXYQfHxc"
      },
      "outputs": [],
      "source": [
        "!pip install faiss-gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ji8nzvkfHxd"
      },
      "outputs": [],
      "source": [
        "!pip install pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1i2Sv9ddy3eWZGNN5_oARmPaCEJJfyCE1' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1i2Sv9ddy3eWZGNN5_oARmPaCEJJfyCE1\" -O valid_document.tsv && rm -rf ~/cookies.txt"
      ],
      "metadata": {
        "id": "n6vE704QfJz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --load-cookies ~/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies ~/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1FCEaL3ajZiUWHBbxpR76GVtn7Leladye' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1FCEaL3ajZiUWHBbxpR76GVtn7Leladye\" -O document_embedding.pkl && rm -rf ~/cookies.txt"
      ],
      "metadata": {
        "id": "AomUA6LniYQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### About Sentence-transformers\n",
        "- https://sbert.net/\n",
        "- https://huggingface.co/sentence-transformers\n"
      ],
      "metadata": {
        "id": "liPpVieZ9STK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diXiO7tVfHxd"
      },
      "outputs": [],
      "source": [
        "# import the necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
        "import faiss\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "def visualize_embeddings(query_embeddings, document_embeddings, rank_df, document_df):\n",
        "    retrieved_docid = rank_df.loc[:, 'retrieved_doc']\n",
        "    # concat\n",
        "    retrieved_doc = []\n",
        "    for doc in retrieved_docid:\n",
        "        retrieved_doc.extend(doc)\n",
        "\n",
        "    retrieved_doc_index = []\n",
        "    for doc in retrieved_doc:\n",
        "        retrieved_doc_index.append(np.where(document_df['docid'].values == doc)[0][0])\n",
        "\n",
        "    document_embeddings = document_embeddings[retrieved_doc_index]\n",
        "\n",
        "    # reduce the dimensionality of the embeddings\n",
        "    tsne = TSNE(n_components=2, metric='cosine', random_state=42, perplexity=10)  # Adjust the perplexity value here\n",
        "\n",
        "    embeddings = np.concatenate([query_embeddings, document_embeddings])\n",
        "    # fit the tsne on the embeddings\n",
        "    Y = tsne.fit_transform(embeddings)\n",
        "\n",
        "    # separate the query and document embeddings\n",
        "    query_embedding = Y[:len(query_embeddings)]\n",
        "    document_embedding = Y[len(query_embeddings):]\n",
        "\n",
        "    # build dataframe for visualization\n",
        "    query_df = pd.DataFrame(query_embedding, columns=['x', 'y'])\n",
        "    query_df['index'] = [i for i in range(len(query_embedding))]\n",
        "\n",
        "    document_df = pd.DataFrame(document_embedding, columns=['x', 'y'])\n",
        "    document_df['index'] = np.repeat(np.arange(len(query_embeddings)), 5)\n",
        "\n",
        "    # plot the embeddings\n",
        "    plt.figure(figsize=(5, 5))\n",
        "    # scatter plot for query embeddings and document embeddings\n",
        "    # colors are based on the index\n",
        "    # each color represents a query and its relevant documents\n",
        "    plt.scatter(query_df['x'], query_df['y'], c=query_df['index'], cmap='tab20', label='Query')\n",
        "    plt.scatter(document_df['x'], document_df['y'], c=document_df['index'], cmap='tab20', marker='x', label='Document')\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p1KC59NfHxd"
      },
      "outputs": [],
      "source": [
        "# get document data\n",
        "document = pd.read_csv('valid_document.tsv', sep='\\t', dtype=str)\n",
        "document[\"docid\"] = [int(document.loc[i, \"docid\"][1:]) for i in range(len(document))]\n",
        "document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E02XOzo2fHxd"
      },
      "outputs": [],
      "source": [
        "# docid -> content function\n",
        "def get_content(docid):\n",
        "    return document[document['docid'] == docid]['doc_tac'].values[0]\n",
        "\n",
        "def print_document(content):\n",
        "    content = content.split('.')\n",
        "    for line in content:\n",
        "        print(line)\n",
        "\n",
        "def print_query_document(query, docid):\n",
        "    print(\"Query: \", query)\n",
        "    print()\n",
        "    print(\"Document Content: \")\n",
        "    print(get_content(docid))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S47eHvlfHxd"
      },
      "source": [
        "# Retrieve document with Bi-encoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rSWq3E6fHxd"
      },
      "source": [
        "### We will first utilize the bi-encoder structure to retrieve 5 documents.  \n",
        "The 10 documents are the top-5 most relevant documents to the query,  \n",
        "and the criterion for relevant is the higher the `inner product` between the query embedding and the document embedding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtMHYMVKfHxe"
      },
      "source": [
        "### The bi-encoder structure is composed of two parts:\n",
        "- `Document encoder`: encodes the document into an embedding\n",
        "- `Query encoder`: encodes the query into an embedding\n",
        "\n",
        "But in this case, we will use the same encoder for both the document and the query.(`parameter sharing`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRSulkhgfHxe"
      },
      "outputs": [],
      "source": [
        "# load the pre-trained model\n",
        "bi_encoder = SentenceTransformer('sentence-transformers/msmarco-MiniLM-L6-cos-v5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTlIZd5mfHxe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# generate embeddings for the document\n",
        "def generate_embeddings(text):\n",
        "    return bi_encoder.encode(text)\n",
        "\n",
        "def get_document_embeddings(document):\n",
        "    embeddings = []\n",
        "    for text in tqdm(document):\n",
        "        embeddings.append(generate_embeddings(text))\n",
        "\n",
        "    embeddings = np.array(embeddings)\n",
        "    return embeddings\n",
        "\n",
        "# document embeddings\n",
        "# document_embeddings = get_document_embeddings(document['doc_tac'])\n",
        "\n",
        "with open('document_embedding.pkl', 'rb') as f:\n",
        "    document_embeddings = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeDTsvygfHxe"
      },
      "outputs": [],
      "source": [
        "# document embeddings shape will be (number of documents, embedding size)\n",
        "document_embeddings.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPhMT2ehfHxe"
      },
      "outputs": [],
      "source": [
        "# use faiss to index the embeddings\n",
        "# when we initialize the index, we need to specify the dimension of the embeddings -> document_embeddings.shape[1]\n",
        "faiss_index = faiss.IndexFlatIP(document_embeddings.shape[1])\n",
        "\n",
        "# add the document embeddings to the index\n",
        "faiss_index = faiss.IndexIDMap2(faiss_index)\n",
        "faiss_index.add_with_ids(document_embeddings, document['docid'].values)\n",
        "\n",
        "# check the total number of documents in the index -> it will be equal to the number of documents in the document_embeddings\n",
        "print(faiss_index.ntotal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kg3c6zdkfHxe"
      },
      "source": [
        "## Queries which we will use to retrieve documents\n",
        "In this example, we will use the following queries to retrieve documents:\n",
        "- why do people buy cars\n",
        "\n",
        "- how many square kilometers is scotland's\n",
        "\n",
        "- what does terrorism mean and example\n",
        "\n",
        "- what does the term alien mean\n",
        "\n",
        "- what part of the eye allows light to enter\n",
        "\n",
        "Ground truth of these queries are:\n",
        "- 2921145  \n",
        "\n",
        "- 8041\n",
        "\n",
        "- 634663\n",
        "\n",
        "- 1354086\n",
        "\n",
        "- 24337\n",
        "\n",
        "\n",
        "Before we perform the document retrieval process for a query, let's look at each query and its corresponding ground truth document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6FA04HNfHxe"
      },
      "outputs": [],
      "source": [
        "query = [\n",
        "\"why do people buy cars\",\n",
        "\"how many square kilometers is scotland's\",\n",
        "\"what does terrorism mean and example\",\n",
        "\"what does the term alien mean\",\n",
        "\"what part of the eye allows light to enter\"\n",
        "]\n",
        "\n",
        "gt_docid = [\n",
        "    2921145,\n",
        "    8041,\n",
        "    634663,\n",
        "    1354086,\n",
        "    24337\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmHoUiWgfHxe"
      },
      "outputs": [],
      "source": [
        "print_query_document(query[0], gt_docid[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsEXAhelfHxe"
      },
      "outputs": [],
      "source": [
        "print_query_document(query[1], gt_docid[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foe9d0kdfHxe"
      },
      "outputs": [],
      "source": [
        "print_query_document(query[2], gt_docid[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MoRAgDgrfHxe"
      },
      "outputs": [],
      "source": [
        "print_query_document(query[3], gt_docid[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_KelDUI1fHxe"
      },
      "outputs": [],
      "source": [
        "print_query_document(query[4], gt_docid[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLWrPmIhfHxe"
      },
      "outputs": [],
      "source": [
        "# generate embeddings for queries\n",
        "query_embedding = generate_embeddings(query)\n",
        "query_embedding = np.array(query_embedding).reshape(len(query), -1)\n",
        "\n",
        "# query embeddings shape will be (number of query, embedding size)\n",
        "print(query_embedding.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma8paYCHfHxe"
      },
      "outputs": [],
      "source": [
        "# we use faiss index for document search\n",
        "# Enter the query embedding as a parameter to the \"search\" method and the top k counts you want to retrieve\n",
        "distances, indices = faiss_index.search(query_embedding, 5)\n",
        "print(\"distance\")\n",
        "print(distances)\n",
        "print()\n",
        "\n",
        "print(\"top-5 index\")\n",
        "print(indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4Av0Yp4fHxe"
      },
      "outputs": [],
      "source": [
        "def get_rank(query, indices, gt_docid):\n",
        "    rank_list = []\n",
        "    for i in range(len(query)):\n",
        "        rank = np.where(indices[i] == gt_docid[i])[0][0] + 1\n",
        "        rank_list.append(rank)\n",
        "\n",
        "    rank_df = pd.DataFrame({\n",
        "        \"query\" : query,\n",
        "        \"retrieved_doc\" : list(indices),\n",
        "        \"rank\" : rank_list,\n",
        "    })\n",
        "\n",
        "    return rank_df\n",
        "\n",
        "rank_df = get_rank(query=query, indices=indices, gt_docid=gt_docid)\n",
        "rank_df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_embeddings(query_embedding, document_embeddings, rank_df, document)"
      ],
      "metadata": {
        "id": "ZypLjws_ox-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2VvniwqfHxe"
      },
      "source": [
        "You can see that most of the queries retrieved the ground truth document well with rank 1.  \n",
        "\n",
        "However, for the last query, the rank is low.  \n",
        "\n",
        "How can we increase the rank for the last query as well?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUq7scCrfHxe"
      },
      "source": [
        "# Rerank with Cross-encoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO8eNJE8fHxe"
      },
      "source": [
        "### Let's rerank the query that didn't achieve rank 1.  \n",
        "\n",
        "We retrieved the top-5 candidate documents with a bi-encoder structure.  \n",
        "\n",
        "This time, we will use a slightly more powerful structure, the cross-encoder structure, to rerank the candidate documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbQQatdjfHxf"
      },
      "outputs": [],
      "source": [
        "# cross encoder model\n",
        "cross_encoder = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQX-vDdXfHxf"
      },
      "outputs": [],
      "source": [
        "# select row whose rank is not 1\n",
        "not_rank1 = rank_df[rank_df[\"rank\"] != 1].reset_index(drop=True)\n",
        "not_rank1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgqpUc96fHxf"
      },
      "outputs": [],
      "source": [
        "# get top-5 document content\n",
        "content_list = []\n",
        "top5_docid = not_rank1[\"retrieved_doc\"].values[0]\n",
        "for docid in top5_docid:\n",
        "    content_list.append(get_content(docid))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACnjTVORfHxf"
      },
      "outputs": [],
      "source": [
        "# for cross encoder convert input to list of tuples (query, document)\n",
        "cross_input = []\n",
        "for query in not_rank1[\"query\"]:\n",
        "    for content in content_list:\n",
        "        cross_input.append((query, content))\n",
        "\n",
        "cross_input[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IWxhjkqcfHxf"
      },
      "outputs": [],
      "source": [
        "cross_scores = cross_encoder.predict(cross_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XtZYW7xrfHxf"
      },
      "outputs": [],
      "source": [
        "docid_score = pd.DataFrame({\n",
        "    \"docid\" : top5_docid,\n",
        "    \"score\" : cross_scores\n",
        "})\n",
        "docid_score = docid_score.sort_values(by=\"score\", ascending=False).reset_index(drop=True)\n",
        "docid_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGnn9LMHfHxf"
      },
      "source": [
        "You can see that the ground truth docid has successfully moved up to rank 1"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}