{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm59QWo5gwxl"
      },
      "source": [
        "# [실습 3] T5 모델을 이용한 뉴스요약 프로젝트"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUHIbgxsg4Na"
      },
      "source": [
        "## 실습 목표\n",
        "\n",
        "---\n",
        "\n",
        "1. Hugging Face 프레임워크의 기능을 알아보고, 기초적인 사용법을 익힙니다.\n",
        "\n",
        "2. T5 모델을 이용하여 뉴스 내용을 요약해보고, 이를 헤드라인과 비교해보는 실습을 진행합니다.\n",
        "\n",
        "3. Rouge 평가지표를 이용하여 모델의 성능을 확인해봅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLAa9sYkgWCP"
      },
      "source": [
        "# Hugging Face 프레임워크 기초 실습\n",
        "\n",
        "이번 실습 시간에는 Hugging Face의 다양한 라이브러리와 API를 사용하는 방법을 익혀보겠습니다.  \n",
        "\n",
        "![](https://huggingface.co/datasets/huggingface/brand-assets/resolve/main/hf-logo-with-title.svg)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K71SuQP2YHwB"
      },
      "source": [
        "Hugging Face는 자연어 처리(NLP) 분야에서 가장 인기 있는 딥러닝 모델 및 도구를 제공하는 플랫폼입니다.  \n",
        "\n",
        "주로 `transformers` 라이브러리를 통해 다양한 사전 훈련된 모델을 제공하며, 연구자와 개발자들 사이에서 널리 사용됩니다.\n",
        "\n",
        "저번 시간에 구현해본 BERT 모델이 기억나시나요? 모델을 구현하는 데에 꽤 많은 시간과 노력이 소요되었지만, `transformers`라이브러리를 이용한다면 아래처럼 쉽게 모델을 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6i6yr6mY0jK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification   # transformers 라이브러리에서 문장 분류용 BERT 모델과 토크나이저 불러오기\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9B61n53IZDbG"
      },
      "source": [
        "사용하려는 모델에 맞게 토크나이저도 제공하므로, 텍스트에 손쉽게 적용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KS9hjPqtZKYT"
      },
      "outputs": [],
      "source": [
        "text = \"안녕하세요, transformers를 사용합니다! \"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')    # 토크나이저에 텍스트를 입력하고, 모델을 가동할 프레임워크(pt = Pytorch)를 인자로 제공\n",
        "encoded_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wirToyr8ZYjJ"
      },
      "source": [
        "토큰화된 텍스트는 다음과 같이 사전학습된 모델을 이용하여 추론에 사용됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm2ZJhcGabak"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    output = model(**encoded_input)\n",
        "logits = output.logits\n",
        "\n",
        "logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U53CfPyPaci_"
      },
      "source": [
        "모델의 출력값은 Softmax 함수를 통해 확률로 표현할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAefq_liapWr"
      },
      "outputs": [],
      "source": [
        "probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
        "print(probabilities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifnp1hc0aqHH"
      },
      "source": [
        "지금부터 간단한 예제들을 통해 텍스트 전처리, 토크나이저 사용 및 모델 사용법을 알려드리도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_MtMKgIPRKA"
      },
      "source": [
        "## 1. 토크나이저\n",
        "\n",
        "토크나이저를 사용하는 주요 이유는 자연어 처리 작업에서 텍스트 데이터를 모델이 이해할 수 있는 형식으로 변환하기 위함입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXVooSD-iWO_"
      },
      "source": [
        "### 1.1 공백 기반 토크나이저\n",
        "\n",
        "가장 기본적인 형태의 토크나이저는 공백을 기반으로 단어를 나누어 토큰을 생성합니다. Python의 문자열 함수 중 `split()`을 통해 아래와 같이 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6fvoyjJiTh_"
      },
      "outputs": [],
      "source": [
        "tokenized_text = \"Transformer architectures have become a cornerstone in modern NLP solutions.\".split()\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHiNUNcijV9B"
      },
      "source": [
        "그러나 공백 단위로 단어를 나누게 되면 완벽하게 나뉘지 않을 뿐더러, 한국어 등 교착어에서는 더욱이나 성능이 떨어지게 됩니다.  \n",
        "\n",
        "고로 대부분의 대규모 언어모델에서는 하위 단어 토큰화(Subword Tokenization) 등 단어의 의미를 더 잘게 나눠 해석할 수 있는 토크나이저를 선호합니다.  \n",
        "\n",
        "모든 모델마다 저마다 최적의 효율을 내는 토크나이저가 따로 있으며, `transformers`라이브러리에서는 사전학습된 토크나이저를 손쉽게 불러올 수 있도록 여러 기능을 지원합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nybgv06j_0u"
      },
      "source": [
        "### 1.2 토크나이저 불러오기\n",
        "\n",
        "BERT 모델에 사용되는 토크나이저를 불러와보겠습니다.\n",
        "\n",
        "`from_pretrained()`메서드를 사용한다면, 사전학습된 토크나이저를 불러올 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVr44TBdiWCD"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvaa291CkPXs"
      },
      "source": [
        "토크나이저에 텍스트를 입력하여 결과를 한 번 보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7brFBEliYwU"
      },
      "outputs": [],
      "source": [
        "tokenizer(\"Deep learning has revolutionized the field of natural language processing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5zdCLx36kUOe"
      },
      "source": [
        "이뿐만 아니라, 특정 모델을 불러올 경우 그에 맞는 토크나이저를 자동으로 불러오는 기능도 AutoTokenizer을 통해 구현할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i5KQet4iaCK"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY3-dAqJkb5l"
      },
      "source": [
        "위의 BERT 토크나이저와 결과를 비교해볼까요?\n",
        "\n",
        "### [TODO] 토크나이저에 문장을 넣고 위의 결과와 비교해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNBit3LSibHv"
      },
      "outputs": [],
      "source": [
        "tokenizer(\"Deep learning has revolutionized the field of natural language processing.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">예시코드\n",
        "```\n",
        "tokenizer(\"Deep learning has revolutionized the field of natural language processing.\")\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIccEivjkjHt"
      },
      "source": [
        "두 토크나이저가 모두 같은 결과를 반환하고 있습니다.  \n",
        "\n",
        "BERT의 토크나이저는 딕셔너리 형태로 세 가지 항목을 반환합니다.\n",
        "\n",
        "- `input_ids`는 문장의 각 토큰에 해당하는 인덱스입니다.\n",
        "- `attention_mask`는 토큰이 Attention을 받아야 하는지 여부를 나타냅니다.\n",
        "- `token_type_ids`는 두 개 이상의 시퀀스가 있을 때 토큰이 어떤 시퀀스에 속하는지를 식별합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-XjRA4NqYYQ"
      },
      "source": [
        "토크나이저는 배치 단위로 문장을 받을 수도 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv2Z3kLvqcqV"
      },
      "outputs": [],
      "source": [
        "batch_sentences = [\n",
        "    \"To be, or not to be: that is the question.\",\n",
        "    \"There is nothing either good or bad, but thinking makes it so.\",\n",
        "    \"This above all: to thine own self be true.\",\n",
        "]\n",
        "encoded_inputs = tokenizer(batch_sentences)\n",
        "print(encoded_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZdPVeZhndel"
      },
      "source": [
        "토크나이저를 저장하는 방법은 아래와 같이 간단하게 진행할 수 있습니다.  \n",
        "\n",
        "단 주의할 점은, 아래 경로에 파일의 이름을 적는 것이 아니라, 경로만 적어야 한다는 것입니다. 그 결과로 생성된 경로 안에\n",
        "```\n",
        "('./tokenizer/tokenizer_config.json',\n",
        " './tokenizer/special_tokens_map.json',\n",
        " './tokenizer/vocab.txt',\n",
        " './tokenizer/added_tokens.json',\n",
        " './tokenizer/tokenizer.json')\n",
        "\n",
        " ```\n",
        " 와 같은 파일이 생성된 것을 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73PYxrzVidhQ"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained(\"./tokenizer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvcnx8pglCS9"
      },
      "source": [
        "### 1.3 인코딩과 디코딩\n",
        "토크나이저를 이용하여 위와 다른 방법으로 인코딩을 진행해보겠습니다.  \n",
        "\n",
        "우선 토크나이저의 `tokenize()`메서드를 통해 텍스트를 분할할 수 있습니다.\n",
        "\n",
        "`add_special_tokens=True`로 입력할 경우, 모델에 맞는 특별한 토큰이 추가됩니다.\n",
        "\n",
        "BERT 모델의 경우 [CLS] 토큰을 통해 분류 작업을, [SEP] 토큰을 활용하여 복수의 문장을 구분하는 작업을 주 태스크와 동시에 진행합니다. 그러므로 BERT 토크나이저를 사용할 때, 해당 모델이 요구하는 특수 토큰을 함께 추가해주는 것이죠.  \n",
        "\n",
        "만약 BERT가 아닌 다른 모델이라면, 그에 맞는 특별 토큰이 존재할 경우 자동적으로 추가해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiguShjyieek"
      },
      "outputs": [],
      "source": [
        "sequence = \"Deep learning has revolutionized the field of natural language processing.\"\n",
        "\n",
        "tokens = tokenizer.tokenize(sequence, add_special_tokens=True)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiJkSiYolSQH"
      },
      "source": [
        "`convert_tokens_to_ids()`메서드는 분리된 단어들을 인덱스에 매칭시켜줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppmulrmzifMj"
      },
      "outputs": [],
      "source": [
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBQawWTfltgy"
      },
      "source": [
        "만일 모델 학습이 종료되었다면, 출력 결과는 숫자 형태입니다. `decode`메서드를 통해 토큰을 원본 단어로 복원할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NoTcXfbif21"
      },
      "outputs": [],
      "source": [
        "decoded_string = tokenizer.decode(ids)\n",
        "print(decoded_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saeK8JeOa1Xa"
      },
      "source": [
        "## 2. 텍스트 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T2bJUCDqRDH"
      },
      "source": [
        "### 2.1 패딩\n",
        "\n",
        "문장의 길이가 동일하지 않을 경우, 언어 모델의 입력으로 사용할 수 없습니다.  \n",
        "\n",
        "이러한 경우를 방지하기 위하여 패딩을 토크나이저에 적용할 수 있습니다.\n",
        "\n",
        "아래와 같이 `padding=True`인자를 넣어주게 되면 자동적으로 배치 내 가장 긴 문장을 기준으로 패딩이 적용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 예시 문장에 패딩을 첨가하여 토큰화해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9TLJnp2rJtU"
      },
      "outputs": [],
      "source": [
        "batch_sentences = [\n",
        "    \"To be, or not to be: that is the question.\",\n",
        "    \"There is nothing either good or bad, but thinking makes it so.\",\n",
        "    \"This above all: to thine own self be true.\",\n",
        "]\n",
        "encoded_inputs = tokenizer(batch_sentences, padding=True)\n",
        "print(encoded_inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "batch_sentences = [\n",
        "    \"To be, or not to be: that is the question.\",\n",
        "    \"There is nothing either good or bad, but thinking makes it so.\",\n",
        "    \"This above all: to thine own self be true.\",\n",
        "]\n",
        "encoded_inputs = tokenizer(batch_sentences, padding=True)\n",
        "print(encoded_inputs)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30n6-WgHrJ_C"
      },
      "source": [
        "### 2.2 길이 제한(Truncation)\n",
        "짧은 문장은 패딩을 통해 긴 문장과 길이를 맞춰줄 수 있지만, 문장의 길이가 너무 길 경우 데이터에 패딩이 지나치게 많이 포함되어 연산에 영향을 줄 수 있습니다.  \n",
        "\n",
        "이 경우 `truncation=True`인자를 이용하면, 길이 제한을 통해 길이가 긴 문자열들의 일부분을 절삭할 수 있습니다.\n",
        "\n",
        "최대 길이는 모델에서 허용한 하이퍼파라미터를 따릅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 예시 문장에 패딩과 길이제한을 첨가하여 토큰화해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JOAuTJmrtXg"
      },
      "outputs": [],
      "source": [
        "batch_sentences = [\n",
        "    \"To be, or not to be: that is the question.\",\n",
        "    \"There is nothing either good or bad, but thinking makes it so.\",\n",
        "    \"This above all: to thine own self be true.\",\n",
        "]\n",
        "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n",
        "print(encoded_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "batch_sentences = [\n",
        "    \"To be, or not to be: that is the question.\",\n",
        "    \"There is nothing either good or bad, but thinking makes it so.\",\n",
        "    \"This above all: to thine own self be true.\",\n",
        "]\n",
        "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True)\n",
        "print(encoded_input)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjyR44gyry_K"
      },
      "source": [
        "### 2.3 텐서 변환\n",
        "\n",
        "`transformers`의 모델 중 일부분은 Pytorch 환경에서 구현되었고, 또 다른 일부는 Tensorflow에서 만들어졌습니다.\n",
        "\n",
        "이 두 환경은 서로 텐서의 형태를 공유하지 않으므로, 토큰화된 문장을 Pytorch(`pt`) 텐서나 Tensorflow(`tf`) 텐서로 변환할 수 있습니다.\n",
        "\n",
        "`return_tensors` 인자를 다음과 같이 조작할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 예시 문장에 패딩, 길이제한과 텐서 변환을 첨가하여 토큰화해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FmOCpDJsXDP"
      },
      "outputs": [],
      "source": [
        "batch_sentences = [\n",
        "    \"To be, or not to be: that is the question.\",\n",
        "    \"There is nothing either good or bad, but thinking makes it so.\",\n",
        "    \"This above all: to thine own self be true.\",\n",
        "]\n",
        "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(encoded_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "batch_sentences = [\n",
        "    \"To be, or not to be: that is the question.\",\n",
        "    \"There is nothing either good or bad, but thinking makes it so.\",\n",
        "    \"This above all: to thine own self be true.\",\n",
        "]\n",
        "encoded_input = tokenizer(batch_sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "print(encoded_input)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leHTRNqwPNGW"
      },
      "source": [
        "## 3. 모델\n",
        "\n",
        "모델을 불러오는 과정도 토크나이저를 사용하는 방법과 크게 다르지 않습니다.  \n",
        "\n",
        "우선 이미 사전학습된 BERT 모델을 불러와보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XqPdUGDHsmxM"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbihzLcnsrNf"
      },
      "source": [
        "### 3.1 커스텀 모델 생성\n",
        "\n",
        "그러나 경우에 따라 사전학습되지 않은 초기화된 모델을 사용하여 처음부터 훈련시켜야 할 수도 있습니다.\n",
        "\n",
        "`transformers`에 있는 모델은 `configuration`객체를 통해 초기화할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quJ7Hu_etB0N"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertModel\n",
        "\n",
        "# config(설정)을 만듭니다.\n",
        "config = BertConfig()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_b_Sc-3tHcf"
      },
      "source": [
        "config는 다음과 같은 딕셔너리 형태로 구성되어 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FAcJllCetGJh"
      },
      "outputs": [],
      "source": [
        "print(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EtjdO4ePS-e"
      },
      "source": [
        "아래 모델의 인자로 `config`를 입력할 경우 모델이 초기화됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aJNdpVbqtef6"
      },
      "outputs": [],
      "source": [
        "model = BertModel(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1vTPT2utnnu"
      },
      "source": [
        "### 3.2 모델 저장\n",
        "\n",
        "모델 저장기능은 토크나이저 저장과 동일합니다. 인자 내에 문자열로 디렉토리를 입력하면 해당 위치에 모델 파일이 생성됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YlK855PtvwO"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"saving_folder\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWzbXAsHtw1S"
      },
      "source": [
        "이렇게 간단하게 `transformers`라이브러리 사용법을 익혀보았습니다.  \n",
        "\n",
        "이제 이를 바탕으로 뉴스 요약 프로젝트를 진행해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFqaza7MgElT"
      },
      "source": [
        "# T5 모델을 이용한 뉴스 요약 프로젝트\n",
        "\n",
        "요약 생성 메커니즘에는 2가지 유형이 있습니다:\n",
        "\n",
        "추출적 요약 (Extractive Summary)\n",
        "\n",
        "- 정의:  \n",
        "원문에서 가장 중요하다고 판단되는 문장이나 구절을 직접 추출하여 요약을 만드는 방식입니다.\n",
        "\n",
        "- 특징:\n",
        "    - 원문에서 직접적으로 문장을 가져오기 때문에, 요약의 문장들은 원문에 모두 존재합니다.\n",
        "\n",
        "    - 원문의 문맥과 구조를 그대로 유지하기 때문에, 원문의 의미 전달에는 효과적일 수 있습니다.\n",
        "\n",
        "    - 그러나, 요약의 길이나 구조를 조절하기 어려울 수 있습니다.\n",
        "\n",
        "추상적 요약 (Abstractive Summary)\n",
        "\n",
        "- 정의:  \n",
        "원문의 내용을 이해하고, 그 의미를 기반으로 새로운 문장을 생성하여 요약을 만드는 방식입니다.\n",
        "\n",
        "- 특징:\n",
        "\n",
        "    - 원문에 없는 새로운 문장이나 표현을 사용하여 요약을 생성할 수 있습니다.\n",
        "\n",
        "    - 원문의 주요 내용을 더 간결하고 자연스럽게 전달할 수 있습니다.\n",
        "\n",
        "    - 딥러닝 기반의 모델, 특히 시퀀스 투 시퀀스(Seq2Seq) 모델을 활용하여 추상적 요약을 구현하는 경우가 많습니다.\n",
        "\n",
        "    - 원문의 의미를 왜곡할 위험이 있을 수 있으므로, 정확한 요약을 위한 학습이 중요합니다.\n",
        "\n",
        "이번 실습에서는 **문장 생성**을 통한 **추상적 요약** 태스크를 진행해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "URZVuEamf92N"
      },
      "source": [
        "## 1. 모듈 불러오기 및 환경 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txOL9ZCii4jg"
      },
      "source": [
        "### 1.1 모듈 불러오기\n",
        "\n",
        "딥러닝 모델을 구현하고 학습하기 위한 필수 라이브러리들을 불러오겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mtoA9PoQl4Y"
      },
      "outputs": [],
      "source": [
        "# 기본 라이브러리 불러오기\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm   # 반복문의 진행 상태를 표시하는 라이브러리\n",
        "\n",
        "# 파이토치 관련 라이브러리 불러오기\n",
        "import torch\n",
        "import torch.nn.functional as F # 파이토치 함수: 다양한 활성화 함수 및 유틸리티 제공\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler  # 데이터 관련 유틸리티\n",
        "\n",
        "# huggingface/transformers에서 T5 모듈 불러오기\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration    # T5 토크나이저와 조건부 생성 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea1EDJs8f7Cd"
      },
      "source": [
        "이 코드를 통해 필요한 모든 라이브러리와 모듈을 불러왔으므로, 이제 딥러닝 모델의 구성 및 학습을 시작할 준비가 되었습니다.\n",
        "\n",
        "이어서 딥러닝 모델 학습 시 사용할 하드웨어를 설정하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kh4sDaKi80J"
      },
      "source": [
        "### 1.2 하드웨어 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jK6ywKcDQ419",
        "outputId": "0c2c5856-96f6-4c91-a531-f7f5462bf1a2"
      },
      "outputs": [],
      "source": [
        "# GPU 사용 설정\n",
        "from torch import cuda\n",
        "\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'   # cuda(GPU)가 사용 가능하면 'cuda'를, 아니면 'cpu'를 device 변수에 할당\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nv6MFA8aiGvQ"
      },
      "source": [
        "딥러닝 모델의 연산이 GPU에서 수행될 수 있게 되면 학습 속도가 크게 향상됩니다. 만약 GPU가 없거나 사용할 수 없는 경우, CPU에서 연산이 수행됩니다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcR6BVbdizhr"
      },
      "source": [
        "### 1.3 하이퍼 파라미터 설정\n",
        "\n",
        "이번엔 데이터 전처리와 모델 구성에 앞서 하이퍼 파라미터들을 설정하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8BDfhoVTV0c"
      },
      "outputs": [],
      "source": [
        "TRAIN_BATCH_SIZE = 2    # 학습 데이터의 배치 크기 설정 (기본값: 64)\n",
        "VALID_BATCH_SIZE = 2    # 검증 데이터의 배치 크기 설정 (기본값: 1000)\n",
        "TRAIN_EPOCHS = 2        # 학습을 위한 에포크 수 설정 (기본값: 10)\n",
        "VAL_EPOCHS = 1          # 검증을 위한 에포크 수 설정\n",
        "LEARNING_RATE = 1e-4    # 학습률 설정 (기본값: 0.01)\n",
        "\n",
        "MAX_LEN = 512           # 입력 텍스트의 최대 길이 설정\n",
        "SUMMARY_LEN = 150       # 요약 텍스트의 최대 길이 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj2Y44e5idfy"
      },
      "source": [
        "- `TRAIN_BATCH_SIZE`와 `VALID_BATCH_SIZE`: 학습 및 검증 데이터의 배치 크기를 설정합니다. 배치 크기는 한 번에 처리되는 데이터의 양을 의미하며, GPU 메모리 용량에 따라 조절될 수 있습니다.\n",
        "\n",
        "- `TRAIN_EPOCHS`와 `VAL_EPOCHS`: 전체 데이터셋에 대해 학습 및 검증을 수행할 횟수를 설정합니다. 에포크가 많을수록 모델은 데이터를 더 많이 볼 수 있지만, 과적합의 위험이 있습니다.\n",
        "\n",
        "- `LEARNING_RATE`: 모델의 가중치를 업데이트할 때 사용되는 학습률을 설정합니다. 너무 큰 학습률은 학습이 불안정해질 수 있고, 너무 작은 학습률은 학습 속도가 느려질 수 있습니다.\n",
        "\n",
        "- `MAX_LEN`와 `SUMMARY_LEN`: 입력 텍스트와 요약 텍스트의 최대 길이를 설정합니다. 텍스트 데이터를 처리할 때, 너무 긴 텍스트는 잘라내거나, 너무 짧은 텍스트는 패딩을 추가하여 이 길이에 맞춰 처리합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bR3KTsKliwMJ"
      },
      "source": [
        "### 1.4 시드 설정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bX5WEb-MWUE-"
      },
      "outputs": [],
      "source": [
        "# 재현성을 위한 설정\n",
        "SEED = 42               # 난수 시드 값 설정 (기본값: 42)\n",
        "\n",
        "torch.manual_seed(SEED) # 파이토치의 난수 시드 값 설정\n",
        "np.random.seed(SEED)    # 넘파이의 난수 시드 값 설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qseNgBAzjHXE"
      },
      "source": [
        "이 코드는 딥러닝 실험의 재현성을 보장하기 위해 난수 생성에 사용되는 시드 값을 설정하는 부분입니다.\n",
        "\n",
        "- `SEED = 42`: 난수 생성을 위한 시드 값을 42로 설정합니다. 이 값은 실험의 재현성을 보장하기 위해 사용되며, 동일한 시드 값으로 여러 번 실험을 실행하면 동일한 결과를 얻을 수 있습니다.\n",
        "\n",
        "- `torch.manual_seed(SEED)`: 파이토치에서 난수를 생성할 때 사용되는 시드 값을 설정합니다. 이를 통해 파이토치 내부에서 발생하는 모든 무작위 연산의 결과가 동일하게 유지됩니다.\n",
        "\n",
        "- `np.random.seed(SEED)`: 넘파이에서 난수를 생성할 때 사용되는 시드 값을 설정합니다. 이를 통해 넘파이 연산에서 발생하는 무작위성이 일정하게 유지됩니다.\n",
        "\n",
        "이러한 설정은 모델 초기화, 데이터 셔플링, 드롭아웃 등의 무작위 연산에서 동일한 결과를 얻기 위해 중요합니다. 실험의 재현성은 연구 결과의 신뢰성을 높이는 데 중요한 요소입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt-7ElFqjVfr"
      },
      "source": [
        "## 2. 데이터 불러오기 및 전처리\n",
        "\n",
        "이번 시간에는 텍스트 요약(Text summarization)을 위해 뉴스 데이터를 이용하겠습니다.   \n",
        "\n",
        "데이터셋의 출처는 [캐글](https://www.kaggle.com/datasets/sunnysai12345/news-summary?select=news_summary_more.csv)로, Inshorts에서 요약된 뉴스로 구성되어 있습니다. 스크랩된 기사의 출처는 Hindu, Indian times, Guardian이며 수집 기간은 2017년 2월부터 8월까지입니다.  \n",
        "\n",
        "총 4514행의 샘플로 구성되어 있으며, 각 샘플에 대하여 6가지 정보가 열 단위로 저장되어 있습니다.  \n",
        "\n",
        "- author : 기사의 저자\n",
        "- date : 기사가 발행된 날짜\n",
        "- headline : 발행된 기사의 헤드라인\n",
        "- read_more : 온라인으로 기사를 따라가기 위한 URL\n",
        "- text : 기사의 요약문\n",
        "- ctext : 전체 기사\n",
        "\n",
        "우리는 `ctext`의 내용을 요약하여 `text`와 같은 형태로 출력하는 모델을 만들어 보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zFqxJjxoZ85"
      },
      "source": [
        "### 2.1 데이터 불러오기\n",
        "\n",
        "아래 경로에서 데이터를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fWhOgg6RDLf"
      },
      "outputs": [],
      "source": [
        "data_path = './news_summary.csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M36MT0_Qoesi"
      },
      "source": [
        "데이터를 Pandas dataframe으로 저장합니다. 일부 문자가 `latin-1` 인코딩으로 저장되어 있으므로 해당 인자를 입력해줍니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "1vI5rY9ORIVF",
        "outputId": "21efea20-2b8d-4a56-e9d6-3dba0e22b984"
      },
      "outputs": [],
      "source": [
        "raw_news = pd.read_csv(data_path, encoding='latin-1')\n",
        "raw_news.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P59mkHyypLf4"
      },
      "source": [
        "상당히 많은 정보가 존재하지만, 우리에겐 기사의 원문과 요약된 텍스트 두 가지만 필요합니다.  \n",
        "\n",
        "해당 정보만 따로 추출하여 `df` 데이터프레임에 할당해봅시다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 데이터프레임에서 요약된`text`와 `ctext`열만 선택하여 슬라이싱합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6BKJ1dupxpt"
      },
      "outputs": [],
      "source": [
        "# 'text'와 'ctext' 열만 선택하여 새로운 데이터프레임 생성\n",
        "df = raw_news[['text','ctext']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "# 'text'와 'ctext' 열만 선택하여 새로운 데이터프레임 생성\n",
        "df = raw_news[['text','ctext']]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfhMBqdnpy1T"
      },
      "source": [
        "### 2.2 요약용 텍스트 태깅\n",
        "\n",
        "텍스트를 분할했다면, 요약할 대상 문장의 앞에 `'summarize: '`태그를 달아주어야 합니다.\n",
        "\n",
        "이번 실습에 사용할 `T5(Text-to-Text Transfer Transformer)` 모델은 텍스트를 입력받아 텍스트를 출력하는 구조로 설계되었습니다. 이 모델의 특징 중 하나는 다양한 자연어 처리 작업을 \"텍스트 변환\" 문제로 간주하고, 특정 작업을 수행하기 위한 명령어를 입력 텍스트의 일부로 제공하는 것입니다.  \n",
        "\n",
        "예를 들어, 문장 분류 작업을 수행하려면 `\"classify: {문장}\"`과 같은 형식으로 입력을 제공하고, 번역 작업을 수행하려면 `\"translate English to French: {문장}\"`과 같은 형식으로 입력을 제공합니다.  \n",
        "\n",
        "이러한 방식을 사용하는 이유는 T5 모델 뿐만 아니라 대부분의 대형 언어모델을 하나의 일관된 구조로 다양한 작업에 적용할 수 있게 하기 위함입니다. 모델은 입력 텍스트에 포함된 명령어를 통해 어떤 작업을 수행해야 하는지 판단하게 됩니다.  \n",
        "\n",
        "따라서 `\"summarize: \"` 문자열을 추가하는 것은 T5 모델에게 텍스트 요약 작업을 수행하도록 지시하는 것과 같습니다. 이와 같은 형식으로 입력을 제공하면, 모델은 주어진 원문을 요약한 결과를 출력하게 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 데이터프레임의 `ctext`열 중 모든 데이터에 대해 태그를 달고. 데이터프레임의 `raw_news` 컬럼에 내용을 추가해주세요.\n",
        "\n",
        "예로, 텍스트가 `\"To be, or not to be: that is the question.\"`일 경우, 이를\n",
        "\n",
        "`\"summarize: To be, or not to be: that is the question.\"`형태로 바뀌어야 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66cT2fpgToL1",
        "outputId": "4f03c02c-76ad-45fd-b166-f80564c48954"
      },
      "outputs": [],
      "source": [
        "# 'ctext' 열 앞에 'summarize: ' 문자열 추가\n",
        "df['raw_news'] = 'summarize: ' + df['ctext']\n",
        "\n",
        "# 데이터프레임의 처음 5줄 출력\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">예시코드\n",
        "```\n",
        "# 'ctext' 열 앞에 'summarize: ' 문자열 추가\n",
        "df['raw_news'] = 'summarize: ' + df['ctext']\n",
        "\n",
        "# 데이터프레임의 처음 5줄 출력\n",
        "print(df.head())\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kt4c1df6qp_E"
      },
      "source": [
        "### 2.3 데이터 분할\n",
        "\n",
        "`df` 데이터프레임에서 데이터를 나누어 학습용 데이터와 테스트용 데이터로 분할해봅시다.  \n",
        "\n",
        "전체 데이터의 80%를 학습용으로 사용하도록 하겠습니다. 그러나 학습의 균일함을 위해 데이터프레임의 행들을 섞어 무작위로 분배하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bh59TGEYTzDv"
      },
      "outputs": [],
      "source": [
        "# 학습 데이터의 크기 설정 (전체 데이터의 80%)\n",
        "train_size = 0.8\n",
        "\n",
        "# 전체 데이터에서 학습 데이터를 무작위로 선택\n",
        "train_data = df.sample(frac=train_size,\n",
        "                          random_state=SEED).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoMwyT27rG3S"
      },
      "source": [
        "`df.sample(frac=train_size, random_state=SEED)`: `sample` 함수는 데이터프레임에서 무작위로 행을 선택하는 함수입니다. `frac` 인자는 선택할 행의 비율을 나타내며, 여기서는 `train_size`로 설정하여 80%의 행을 선택하도록 합니다. `random_state` 인자는 무작위 선택의 재현성을 보장하기 위해 사용되며, 이전에 설정한 SEED 값을 사용합니다.\n",
        "\n",
        "`.reset_index(drop=True)`: 선택된 행의 인덱스를 재설정합니다. `drop=True`는 기존 인덱스를 새로운 열로 추가하지 않고 삭제하도록 합니다.\n",
        "\n",
        "완료가 되었다면 일부분을 보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GVxYrMsuVX1w",
        "outputId": "6545a402-b349-4119-a998-36305864d08b"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T19YJQYZsbA8"
      },
      "source": [
        "데이터가 잘 섞여 분배되었습니다. 마찬가지 방법으로 테스트용 데이터셋도 나눠보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] `val_data` 변수에 나머지 데이터를 할당해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VhQUCz8sWkOi"
      },
      "outputs": [],
      "source": [
        "# 학습 데이터셋에 포함되지 않은 나머지 데이터를 검증 데이터셋으로 설정\n",
        "val_data = df.drop(train_data.index).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">예시코드\n",
        "```\n",
        "# 학습 데이터셋에 포함되지 않은 나머지 데이터를 검증 데이터셋으로 설정\n",
        "val_data = df.drop(train_data.index).reset_index(drop=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dl7CAFdFsyIQ"
      },
      "source": [
        "`df.drop(train_dataset.index)`: `drop` 함수는 데이터프레임에서 특정 행을 제거하는 함수입니다. 여기서는 `train_dataset.index`를 사용하여 학습 데이터셋에 이미 포함된 행들을 전체 데이터셋(`df`)에서 제거합니다.\n",
        "\n",
        "`.reset_index(drop=True)`: 제거된 행의 인덱스를 재설정합니다. `drop=True`는 기존 인덱스를 새로운 열로 추가하지 않고 삭제하도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n86Je87ZWr4X",
        "outputId": "70ec7979-4ad5-45a6-e16d-a09f67fe8123"
      },
      "outputs": [],
      "source": [
        "val_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5qu0ohnsm4V"
      },
      "source": [
        "전체 데이터셋과 분할된 데이터셋들의 형태를 확인해볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4VYyEKCbwnP",
        "outputId": "5566dd7a-e1eb-4fd6-a297-1b87534471ba"
      },
      "outputs": [],
      "source": [
        "print(\"FULL Dataset: {}\".format(df.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(val_data.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJgOlRo1s7rZ"
      },
      "source": [
        "### 2.4 토큰화\n",
        "\n",
        "이제 준비된 데이터를 바탕으로 토큰화를 진행해보겠습니다. 앞서 설명한 토큰화 방식과 마찬가지로, T5 모델에 대한 토크나이저를 불러오겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "c3491186fe004bdd92ad405c10d0289a",
            "84937492a3bf447a935f02377b1d939f",
            "873dc72eb3fa4413a198ae0faa94cd35",
            "5e4c09ad91d44655abed571fc519a41d",
            "9b70bbd8fd514196ba20fa483b938d73",
            "86092b5adbb746448b59a3c07e744964",
            "6d4954310dcf432ca4ba3821839166c0",
            "dbf8d19f3a13433382348d2f8afc3dcf",
            "fcb56f5e112e4b46bfbf2d1e959f2c1d",
            "fe9bff27cadf4e2ca0f51e792968a53e",
            "5df8e7c094ca4fa3a29c49270097dc9b",
            "4358c67e0eca48e2a7446a2a4e1edac9",
            "ea0abf14599945c8a8f4db98d7c1cbf5",
            "15d1aefada884a5c9a274db5fad3d11b",
            "1dc5f31497f94d598dd94d9031cebbaf",
            "cbda7388e6d345b7973cd0236d65de41",
            "6ffd87f676c64131bd9b68551c85cc67",
            "6a90953fd8ef4d46b8848ef6947c1417",
            "9f1ef27066504d048dd3f4f93ef821d8",
            "facb646c3b81421aafb518fd307d613d",
            "a0c0ecf3838a40e0b3958daa6b61a463",
            "21ade4e020014be7affc919e8cb7daad"
          ]
        },
        "id": "vrwMlxm_T6W2",
        "outputId": "a475fb75-61e6-4425-f63f-67be303aa1c8"
      },
      "outputs": [],
      "source": [
        "# T5 토크나이저를 \"t5-base\" 모델을 기반으로 불러오기\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmEfyYWZts0-"
      },
      "source": [
        " `T5Tokenizer`는 T5 모델의 텍스트를 토큰화하기 위한 토크나이저입니다. `from_pretrained` 메서드를 사용하여 사전 학습된 `\"t5-base\"` 모델에 대한 토크나이저를 불러옵니다.  \n",
        "\n",
        "`\"t5-base\"`는 T5 모델의 기본 버전을 나타냅니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ3U25e-t7Y6"
      },
      "source": [
        "### 2.5 데이터셋 클래스 선언\n",
        "\n",
        "데이터셋 클래스를 선언하도록 하겠습니다.  \n",
        "\n",
        "아래 데이터셋은 PyTorch의 Dataset 클래스를 상속받아 정의하며, 이를 통해 데이터 로딩 및 전처리를 효율적으로 수행할 수 있습니다.\n",
        "\n",
        "또한 `DataLoader`와 함께 사용하면 배치 단위로 데이터를 불러와 모델 학습에 사용할 수 있습니다.  \n",
        "\n",
        "`CustomDataset` 클래스는 T5 모델과 텍스트 요약 작업의 특성을 반영하여 설계되었습니다. 이를 바탕으로, 일반적인 데이터셋과는 다르게 `CustomDataset`이 가져야 하는 특이한 기능들은 다음과 같습니다.\n",
        "\n",
        "1. 토큰화 및 패딩:\n",
        "\n",
        "T5 모델은 특정한 토크나이저를 사용하여 텍스트를 토큰화합니다. `CustomDataset` 클래스는 이 토크나이저를 사용하여 원문과 요약문을 토큰화합니다.\n",
        "\n",
        "또한, 모델에 입력되는 텍스트의 길이는 일정해야 하므로, 주어진 최대 길이에 따라 텍스트를 잘라내거나 패딩을 추가하는 작업이 필요합니다.\n",
        "\n",
        "2. 반환 형식:\n",
        "\n",
        "T5 모델 학습을 위해서는 원문(`source_ids`, `source_mask`)과 요약문(`target_ids`)에 해당하는 토큰 ID와 attention mask가 필요합니다.\n",
        "\n",
        "CustomDataset 클래스는 `__getitem__` 메서드에서 이 정보를 딕셔너리 형태로 반환합니다. 이 딕셔너리는 모델 학습 시 바로 사용될 수 있도록 구성되어 있습니다.\n",
        "\n",
        "3. 텍스트 정규화:\n",
        "\n",
        "텍스트 데이터에는 불필요한 공백이나 특수 문자 등이 포함될 수 있습니다. 이 클래스에서는 각 텍스트를 공백을 기준으로 분할한 후 다시 합쳐서 불필요한 공백을 제거하는 작업을 수행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hw9oud3BQ598"
      },
      "outputs": [],
      "source": [
        "# 사용자 정의 데이터셋 클래스\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, source_len, summ_len,\n",
        "                 source_col, highlight_col):\n",
        "        # 초기화 메서드\n",
        "        self.tokenizer = tokenizer  # 토크나이저 설정\n",
        "        self.data = dataframe  # 데이터프레임 설정\n",
        "        self.source_len = source_len  # 원문의 최대 길이 설정\n",
        "        self.summ_len = summ_len  # 요약문의 최대 길이 설정\n",
        "        self.highlight = self.data[highlight_col]  # 요약문 데이터 설정\n",
        "        self.source = self.data[source_col]  # 원문 데이터 설정\n",
        "\n",
        "    def __len__(self):\n",
        "        # 데이터셋의 길이 반환\n",
        "        return len(self.highlight)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # 주어진 인덱스에 해당하는 데이터 반환\n",
        "        source_text = str(self.source[index])  # 원문 텍스트 추출\n",
        "        source_text = ' '.join(source_text.split())  # 불필요한 공백 제거\n",
        "\n",
        "        highlight_text = str(self.highlight[index])  # 요약문 텍스트 추출\n",
        "        highlight_text = ' '.join(highlight_text.split())  # 불필요한 공백 제거\n",
        "\n",
        "        # 원문 텍스트를 토큰화\n",
        "        source_encoded = self.tokenizer.batch_encode_plus(\n",
        "            [source_text],\n",
        "            max_length=self.source_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        # 요약문 텍스트를 토큰화\n",
        "        target_encoded = self.tokenizer.batch_encode_plus(\n",
        "            [highlight_text],\n",
        "            max_length=self.summ_len,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        # 토큰화된 결과에서 필요한 정보 추출\n",
        "        source_ids = source_encoded['input_ids'].squeeze()  # squeeze 메서드는 텐서에서 크기가 1인 차원을 제거\n",
        "        source_mask = source_encoded['attention_mask'].squeeze()\n",
        "        target_ids = target_encoded['input_ids'].squeeze()\n",
        "        target_mask = target_encoded['attention_mask'].squeeze()\n",
        "\n",
        "        # 결과 반환\n",
        "        return {\n",
        "            'source_ids': source_ids.to(dtype=torch.long),\n",
        "            'source_mask': source_mask.to(dtype=torch.long),\n",
        "            'target_ids': target_ids.to(dtype=torch.long),\n",
        "            'target_ids_y': target_ids.to(dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfWyDoa7wVo7"
      },
      "source": [
        "위 클래스를 뜯어 살펴보겠습니다.\n",
        "\n",
        "1. 초기화 (`__init__`):\n",
        "\n",
        "    - 입력으로 주어진 데이터프레임, 토크나이저, 원문과 요약문의 최대 길이, 그리고 원문과 요약문의 열 이름을 기반으로 클래스를 초기화합니다.\n",
        "\n",
        "    - 원문(source)과 요약문(highlight) 데이터를 멤버 변수로 저장합니다.\n",
        "\n",
        "2. 데이터셋의 길이 반환 (`__len__`):\n",
        "\n",
        "    - 데이터셋에 포함된 샘플의 총 개수를 반환합니다.\n",
        "\n",
        "3. 인덱스에 해당하는 데이터 반환 (`__getitem__`):\n",
        "\n",
        "    - 주어진 인덱스에 해당하는 원문과 요약문을 추출합니다.\n",
        "\n",
        "    - 추출된 원문과 요약문을 토크나이저를 사용하여 토큰화합니다. 이때, 주어진 최대 길이에 맞게 텍스트를 잘라내거나 패딩을 추가합니다.\n",
        "\n",
        "    - 토큰화된 결과에서 필요한 정보 (예: input_ids, attention_mask 등)를 추출합니다.\n",
        "\n",
        "    - 추출된 정보를 딕셔너리 형태로 반환합니다. 이 딕셔너리는 모델 학습 시 입력 데이터로 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtRmGIeX2jrL"
      },
      "source": [
        "데이터셋 클래스가 선언되었으므로, 이를 바탕으로 학습용 데이터셋을 만들어보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 학습용 데이터셋 인스턴스를 생성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L8AIdXx1SqlR"
      },
      "outputs": [],
      "source": [
        "training_set = CustomDataset(dataframe=train_data,\n",
        "                        tokenizer=tokenizer,\n",
        "                        source_len=MAX_LEN,\n",
        "                        summ_len=SUMMARY_LEN,\n",
        "                        source_col='text',\n",
        "                        highlight_col='ctext',\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ">예시코드\n",
        "```\n",
        "training_set = CustomDataset(dataframe=train_data,\n",
        "                        tokenizer=tokenizer,\n",
        "                        source_len=MAX_LEN,\n",
        "                        summ_len=SUMMARY_LEN,\n",
        "                        source_col='text',\n",
        "                        highlight_col='ctext',\n",
        "                        )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkc-7gRi5rxU"
      },
      "source": [
        "`tokenizer=tokenizer`: T5 모델의 토크나이저를 사용하여 텍스트를 토큰화합니다.\n",
        "\n",
        "`source_len=MAX_LEN`: 원문의 최대 길이를 `MAX_LEN`으로 설정합니다. 이 길이를 초과하는 원문은 잘리게 되며, 이 길이보다 짧은 원문은 패딩됩니다.\n",
        "\n",
        "`summ_len=SUMMARY_LEN`: 요약문의 최대 길이를 `SUMMARY_LEN`으로 설정합니다. 이 길이를 초과하는 요약문은 잘리게 되며, 이 길이보다 짧은 요약문은 패딩됩니다.\n",
        "\n",
        "`source_col='text'`: 원문 데이터가 포함된 열의 이름을 `'text'`로 설정합니다.\n",
        "\n",
        "`highlight_col='ctext'`: 요약문 데이터가 포함된 열의 이름을 `'ctext'`로 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvfPv-k057we"
      },
      "source": [
        "CustomDataset 클래스의 `__getitem__`메서드를 호출하여 인덱스 1에 해당하는 샘플을 가져옵니다. 이 메서드는 주어진 인덱스에 해당하는 원문과 요약문을 토큰화하고, 필요한 정보를 딕셔너리 형태로 반환합니다.  \n",
        "\n",
        "한 번 내부를 살펴볼까요?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 데이터셋 클래스의 1번 인덱스에 해당하는 데이터를 불러와주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7AX6zrpW1xm",
        "outputId": "1403784e-14c9-47cb-e825-90a9614f45cf"
      },
      "outputs": [],
      "source": [
        "sample = training_set.__getitem__(1)\n",
        "sample"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "sample = training_set.__getitem__(1)\n",
        "sample\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UCC7EYQ6Hym"
      },
      "source": [
        "각 키와 값에 대한 설명은 다음과 같습니다:\n",
        "\n",
        "- `source_ids`: 원문(`text`)의 토큰화된 결과입니다. 이는 T5 모델에 입력으로 제공될 원문의 토큰 ID들을 나타냅니다. 값 중 0은 패딩 토큰을 나타냅니다.\n",
        "\n",
        "- `source_mask`: 원문의 attention mask입니다. 이는 모델이 원문의 어떤 부분에 주의를 기울여야 하는지를 나타냅니다. 1은 해당 위치의 토큰이 실제 데이터를 나타내며, 0은 패딩 토큰을 나타냅니다.\n",
        "\n",
        "- `target_ids`: 요약문(`ctext`)의 토큰화된 결과입니다. 이는 T5 모델의 출력과 비교될 대상입니다. 값 중 0은 패딩 토큰을 나타냅니다.\n",
        "\n",
        "- `target_ids_y`: 요약문의 토큰화된 결과입니다. 이는 학습 시 정답 라벨로 사용됩니다. `target_ids`와 동일한 값을 가집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP-J8p2M6Ot_"
      },
      "source": [
        "CustomDataset 클래스의 `__getitem__`메서드를 호출하면, 데이터셋 전체 길이를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35UyvL4AZxSS",
        "outputId": "17bb95c9-fa63-403a-87f0-06134a37c104"
      },
      "outputs": [],
      "source": [
        "training_set.__len__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BER8XC7c6Ueb"
      },
      "source": [
        "### [TODO] 테스트 데이터셋 인스턴스를 생성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjpO1tIjWgYn"
      },
      "outputs": [],
      "source": [
        "val_set = CustomDataset(dataframe=val_data,\n",
        "                        tokenizer=tokenizer,\n",
        "                        source_len=MAX_LEN,\n",
        "                        summ_len=SUMMARY_LEN,\n",
        "                        source_col='text',\n",
        "                        highlight_col='ctext',\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "val_set = CustomDataset(dataframe=val_data,\n",
        "                        tokenizer=tokenizer,\n",
        "                        source_len=MAX_LEN,\n",
        "                        summ_len=SUMMARY_LEN,\n",
        "                        source_col='text',\n",
        "                        highlight_col='ctext',\n",
        "                        )\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMtIX4vYWh-L",
        "outputId": "b82193d3-ddd8-4b3c-c103-4e5385a52327"
      },
      "outputs": [],
      "source": [
        "val_set.__len__()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs41unMF6Y9i"
      },
      "source": [
        "### 2.6 Dataloader\n",
        "\n",
        "Pytorch DataLoader는 데이터셋과 샘플러를 입력으로 받아, 데이터셋에서 데이터를 가져와 배치로 묶어주는 반복 가능한 객체(iterable)를 생성합니다.  \n",
        "\n",
        "이는 미니배치 학습, 데이터 셔플, 병렬 데이터 로딩 등을 쉽게 수행할 수 있게 해줍니다.\n",
        "\n",
        "DataLoader을 생성하기에 앞서 파라미터를 설정해주겠습니다.  \n",
        "\n",
        "파라미터에는 배치 크기, 셔플 여부, 사용할 프로세스 수를 기입해줍시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z54o-AtJbSlL"
      },
      "outputs": [],
      "source": [
        "# 학습 및 검증 데이터 로더를 생성하기 위한 매개변수 설정\n",
        "train_params = {\n",
        "    'batch_size': TRAIN_BATCH_SIZE,  # 학습 데이터의 배치 크기 설정\n",
        "    'shuffle': True,                 # 학습 데이터를 섞어서 학습의 안정성 향상\n",
        "    'num_workers': 0                # 데이터 로딩에 사용할 프로세스 수 (0은 메인 프로세스에서 로드)\n",
        "}\n",
        "\n",
        "val_params = {\n",
        "    'batch_size': VALID_BATCH_SIZE,  # 검증 데이터의 배치 크기 설정\n",
        "    'shuffle': False,                # 검증 데이터는 순서에 영향을 받지 않으므로 섞지 않음\n",
        "    'num_workers': 0                # 데이터 로딩에 사용할 프로세스 수 (0은 메인 프로세스에서 로드)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsYlFtub79dZ"
      },
      "source": [
        "`batch_size`: 한 번에 처리할 데이터의 양을 설정합니다. 배치 크기는 GPU 메모리와 관련이 있으며, 너무 크게 설정하면 메모리 오류가 발생할 수 있습니다.\n",
        "\n",
        "`shuffle`: 학습 데이터의 경우, 각 에폭마다 데이터를 섞어서 모델이 데이터의 순서에 익숙해지지 않게 합니다. 이를 통해 모델의 일반화 성능을 향상시킬 수 있습니다. 반면, 테스트 데이터는 모델의 성능을 평가하는 데만 사용되므로 데이터를 섞을 필요가 없습니다.\n",
        "\n",
        "`num_workers`: 데이터 로딩 속도를 높이기 위해 여러 프로세스를 사용할 수 있습니다. 여기서는 단순화를 위해 메인 프로세스에서만 데이터를 로드하도록 설정되었습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4u7oOYP8Q02"
      },
      "source": [
        "딕셔너리 언패킹을 통해 위에서 선언한 파라미터 변수를 데이터로더 생성에 적용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 데이터로더를 생성해주세요.\n",
        "\n",
        "위에서 선언한 딕셔너리를 이용하여 데이터로더를 생성해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUqD0TYlb2eL"
      },
      "outputs": [],
      "source": [
        "# 학습 및 검증을 위한 데이터 로더 생성\n",
        "training_loader = DataLoader(training_set, **train_params)  # 학습 데이터셋을 위한 데이터 로더\n",
        "val_loader = DataLoader(val_set, **val_params)              # 테스트 데이터셋을 위한 데이터 로더"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "# 학습 및 검증을 위한 데이터 로더 생성\n",
        "training_loader = DataLoader(training_set, **train_params)  # 학습 데이터셋을 위한 데이터 로더\n",
        "val_loader = DataLoader(val_set, **val_params)              # 테스트 데이터셋을 위한 데이터 로더\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VQbi8X_8pOS"
      },
      "source": [
        "훌륭합니다. 이제 데이터 준비를 마쳤으니, 모델을 불러와 학습시키기만 하면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlzdvqVj8Cq1"
      },
      "source": [
        "## 3. 모델 인스턴스 생성 및 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2he5nKa8u10"
      },
      "source": [
        "이번 실습에 사용할 모델은 [T5](https://arxiv.org/abs/1910.10683)입니다.  \n",
        "\n",
        "![T5](https://miro.medium.com/max/4006/1*D0J1gNQf8vrrUpKeyD8wPA.png)\n",
        "\n",
        "T5(Text-to-Text Transfer Transformer)는 Google Research에서 개발된 트랜스포머 기반의 모델로, 모든 자연어 처리 작업을 \"텍스트를 텍스트로 변환하는 작업\"으로 간주합니다.  \n",
        "\n",
        "이 독특한 접근 방식은 다양한 NLP 작업을 동일한 모델 아키텍처와 훈련 방법으로 처리할 수 있게 해주고 이는 사용되는 문장 앞에 독특한 태그를 붙이는 방식으로 진행됩니다.\n",
        "\n",
        "예를 들어 번역 작업에서는 \"translate English to Korean: Hello\"와 같은 입력을 받아 \"안녕하세요\"라는 출력을 생성합니다.\n",
        "\n",
        "Hugging Face에서 배포되는 다른 LLM과 마찬가지로, 큰 텍스트 데이터셋에서 미리 훈련된 후 특정 작업에 미세 조정되어 다양한 크기(small, base, large, 3B, 11B 등)로 제공됩니다.\n",
        "\n",
        "우리는 이 모델이 제공하는 다양한 기능 중 요약기능(\"summarize: \")을 통해 위에서 처리한 뉴스 데이터를 요약해보도록 하겠습니다.\n",
        "\n",
        "우선 Hugging Face Transformers 라이브러리에서 T5 모델을 불러오도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTidr3pKBJWo"
      },
      "source": [
        "### 3.1 모델 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "c4e8d9aef1254ac6a10290e1cd49da8f",
            "d63904ff36a441f6a2ca88aa9f2dbd26",
            "2bb23c9ca00e4a089ab774f96cf996d7",
            "4f6d8ec73b3c4b3f8df67e3255ee7e37",
            "1f482ed31ff84ffa89a31e097399aa65",
            "73bf01e44b3443c891a14f49c8040dd4",
            "5936d85cea684684a48cb0be89128da9",
            "8c3d9ef0d9cd4ca984fc79caad5e59f3",
            "e0fdeacc456944d28c8678c9d32dd4e2",
            "273c12737de640b1bf9eaed14834acc0",
            "8b00c9559c5f4b978278c778aa199536",
            "9798e6d64a894c509bbada170530b215",
            "fe2333cf28d3485fa59412d9e5d0fda8",
            "bb99f2baa59246b7b0f85655b2d9f01b",
            "5811520d1d384361a65a8e2d313571fd",
            "cbba07ac78064826914fd0901f4054c5",
            "fb7857cba4254d58a0d0169b74b4ed36",
            "d0135b05b40c42e1947ec5096e869ccf",
            "0bb03d2c478a4ab38c48aa25b3148e84",
            "d6a3f30bc0ee4057a5ec6ccf2535b369",
            "e9750a5f121045fdb7d33512ce3bb3b4",
            "1e47a04d3b834c6d80cb75170cdc218d"
          ]
        },
        "id": "N7Clhg4jb6A-",
        "outputId": "0e8926e0-3ea8-4f60-d510-81323eb83cc9"
      },
      "outputs": [],
      "source": [
        "# T5-base 모델을 정의하고 요약 생성을 위한 언어 모델 계층을 추가합니다.\n",
        "# 이후, 이 모델은 하드웨어(GPU/TPU)를 사용하기 위해 해당 장치로 전송됩니다.\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")  # T5-base 모델을 불러옵니다.\n",
        "model = model.to(device)  # 모델을 GPU나 TPU로 전송합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sInyaZK_ysU"
      },
      "source": [
        "- `T5ForConditionalGeneration`: T5 모델의 변형으로, 조건부 생성 작업(예: 텍스트 요약)을 수행하기 위해 설계되었습니다. 이 모델은 주어진 입력 텍스트에 대한 요약을 생성하는 데 사용됩니다.\n",
        "\n",
        "- `.from_pretrained(\"t5-base\")`: 사전 학습된 't5-base' 모델을 불러옵니다. 't5-base'는 T5 모델의 중간 크기 버전으로, 광범위한 텍스트 데이터에서 사전 학습되었습니다.\n",
        "\n",
        "- `.to(device)`: 모델을 현재 사용 가능한 하드웨어 장치(GPU 또는 CPU)로 전송합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qzoX3f_7A57D"
      },
      "source": [
        "### 3.2 Optimizer\n",
        "모델에 사용할 옵티마이저를 불러오고, 이에 적용할 학습률을 설정합니다.\n",
        "\n",
        "`params=model.parameters()`인자는 모델의 모든 파라미터(가중치 및 편향)를 옵티마이저에 전달하여 학습 중에 업데이트될 수 있도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv7f3Mlsd-jj"
      },
      "outputs": [],
      "source": [
        "# 네트워크의 가중치를 조정하기 위해 학습 세션에서 사용될 옵티마이저를 정의합니다.\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)  # Adam 옵티마이저를 사용하며, 학습률은 LEARNING_RATE로 설정합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KyIx6_VOBOzt"
      },
      "source": [
        "### 3.3 학습 함수 선언\n",
        "\n",
        "학습에 필요한 함수를 선언합니다.  \n",
        "\n",
        "모델을 학습모드로 설정하여 `순전파`, `손실계산`, `역전파`, `가중치 업데이트` 총 네 가지 과정을 for 문을 통해 반복적으로 진행합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ul6NTCAemHh"
      },
      "outputs": [],
      "source": [
        "def train(epoch, tokenizer, model, device, loader, optimizer):\n",
        "    # 모델을 학습 모드로 설정합니다.\n",
        "    model.train()\n",
        "\n",
        "    # 데이터 로더에서 배치 단위로 데이터를 가져와 학습을 진행합니다.\n",
        "    for _, data in tqdm(enumerate(loader, 0)):\n",
        "        # 타겟 데이터를 GPU로 이동시키고, 입력 및 레이블로 사용될 데이터를 준비합니다.\n",
        "        y = data['target_ids'].to(device, dtype=torch.long)\n",
        "        y_ids = y[:, :-1].contiguous()\n",
        "        lm_labels = y[:, 1:].clone().detach()\n",
        "        lm_labels[y[:, 1:] == tokenizer.pad_token_id] = -100\n",
        "        ids = data['source_ids'].to(device, dtype=torch.long)\n",
        "        mask = data['source_mask'].to(device, dtype=torch.long)\n",
        "\n",
        "        # 모델에 데이터를 전달하여 출력을 얻습니다.\n",
        "        outputs = model(input_ids=ids, attention_mask=mask, decoder_input_ids=y_ids, labels=lm_labels)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        # 500번째 스텝마다 학습 손실을 출력합니다.\n",
        "        if _ % 500 == 0:\n",
        "            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "\n",
        "        # 옵티마이저의 기울기를 초기화하고, 손실을 기반으로 역전파를 수행한 후, 가중치를 업데이트합니다.\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5XBwQm5BiRF"
      },
      "source": [
        "- 모델 학습 모드 설정: `model.train()`을 사용하여 모델을 학습 모드로 설정합니다. 이렇게 하면 모델 내의 드롭아웃과 같은 특정 레이어가 학습 중에만 활성화됩니다.\n",
        "\n",
        "- 데이터 로딩: loader를 통해 학습 데이터를 배치 단위로 가져옵니다.\n",
        "\n",
        "- 데이터 전처리: 타겟 데이터(`y`)를 GPU로 이동시키고, 입력(`ids, mask`) 및 레이블(`lm_labels`)로 사용될 데이터를 준비합니다. `lm_labels`는 손실 계산에 사용되며, 패딩 토큰 위치에 -100 값을 가집니다.\n",
        "\n",
        "    - PyTorch의 크로스 엔트로피 손실 함수는 -100 값을 가진 레이블을 자동으로 무시하도록 설계되어 있습니다.\n",
        "\n",
        "    - 패딩 토큰들은 시퀀스의 길이를 동일하게 맞추기 위해 사용되지만, 실제 데이터가 아니므로 손실 계산에서 무시되어야 합니다.\n",
        "\n",
        "- 모델 전달: 입력 데이터를 모델에 전달하여 출력을 얻습니다. 이 때, 손실도 함께 반환됩니다.\n",
        "\n",
        "- 손실 출력: 500번째 스텝마다 현재의 손실을 출력하여 학습 진행 상황을 모니터링합니다.\n",
        "\n",
        "- 역전파 및 가중치 업데이트: 손실을 기반으로 역전파를 수행하고, 옵티마이저를 사용하여 모델의 가중치를 업데이트합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kp9PyOq5B6xA"
      },
      "source": [
        "### 3.4 평가 함수 선언\n",
        "\n",
        "이번엔 평가에 사용할 함수를 선언하겠습니다.  \n",
        "\n",
        "학습 함수와 유사하지만, `순전파`와 `손실계산`까지만 진행된다는 점이 다릅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mm49ArZeqv7"
      },
      "outputs": [],
      "source": [
        "def validate(epoch, tokenizer, model, device, loader):\n",
        "    # 모델을 평가 모드로 설정. 이렇게 하면 학습 중에만 활성화되는 특정 레이어들 (예: Dropout)이 비활성화됩니다.\n",
        "    model.eval()\n",
        "\n",
        "    # 예측된 요약과 실제 요약을 저장하기 위한 리스트를 초기화합니다.\n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    # 모델의 파라미터가 업데이트되지 않도록 gradient 계산을 중지합니다.\n",
        "    # 이는 검증 중에는 모델을 업데이트하지 않기 때문입니다.\n",
        "    with torch.no_grad():\n",
        "        # 검증 데이터셋의 각 배치에 대해 반복합니다.\n",
        "        for _, data in tqdm(enumerate(loader, 0)):\n",
        "            # 현재 배치의 데이터를 GPU로 전송합니다.\n",
        "            y = data['target_ids'].to(device, dtype = torch.long)\n",
        "            ids = data['source_ids'].to(device, dtype = torch.long)\n",
        "            mask = data['source_mask'].to(device, dtype = torch.long)\n",
        "\n",
        "            # 주어진 입력에 대한 요약을 생성합니다.\n",
        "            generated_ids = model.generate(\n",
        "                input_ids = ids,\n",
        "                attention_mask = mask,\n",
        "                max_length=150,\n",
        "                num_beams=2,\n",
        "                repetition_penalty=2.5,\n",
        "                length_penalty=1.0,\n",
        "                early_stopping=True\n",
        "                )\n",
        "\n",
        "            # 토큰 ID를 실제 텍스트로 변환합니다.\n",
        "            preds = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=True) for g in generated_ids]\n",
        "            target = [tokenizer.decode(t, skip_special_tokens=True, clean_up_tokenization_spaces=True)for t in y]\n",
        "\n",
        "            # 예측과 실제 값을 저장합니다.\n",
        "            predictions.extend(preds)\n",
        "            actuals.extend(target)\n",
        "    return predictions, actuals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XII6BYWjEr6F"
      },
      "source": [
        "- 모델 평가 모드 설정: `model.eval()`을 사용하여 모델을 평가 모드로 설정합니다. 이렇게 하면 모델 내의 드롭아웃과 같은 특정 레이어가 비활성화됩니다.\n",
        "\n",
        "- 데이터 로딩: loader를 통해 검증 데이터를 배치 단위로 가져옵니다.\n",
        "\n",
        "- 데이터 전처리: 타겟 데이터(`y`)와 입력 데이터(`ids, mask`)를 GPU로 이동시킵니다.\n",
        "\n",
        "- 모델 전달 및 요약 생성: 입력 데이터(`ids, mask`)를 모델에 전달하여 요약을 생성합니다. 이 때, `model.generate` 메서드를 사용하여 주어진 입력에 대한 요약을 생성합니다. 여기에는 빔 서치, 반복 패널티, 길이 패널티 등의 다양한 설정이 포함됩니다.\n",
        "\n",
        "    - 빔 서치와 두 페널티에 관한 설명은 아래에 자세히 이어서 설명하겠습니다.\n",
        "\n",
        "- 토큰 ID를 텍스트로 변환: 생성된 요약의 토큰 ID와 실제 요약의 토큰 ID를 실제 텍스트로 변환합니다. 이 때, `tokenizer.decode` 메서드를 사용하여 토큰 ID를 텍스트로 변환합니다.\n",
        "\n",
        "- 진행 상황 모니터링: 100번째 스텝마다 현재 진행 상황을 출력하여 검증 진행 상황을 모니터링합니다.\n",
        "\n",
        "- 결과 반환: 모든 배치에 대한 예측이 완료되면 생성된 요약과 실제 요약을 반환합니다. 이를 통해 후에 성능 지표를 계산할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZToINA7NFVbX"
      },
      "source": [
        "### 3.5 Beam Search\n",
        "\n",
        "빔 서치는 텍스트 생성 작업에서 가장 가능성 있는 시퀀스를 찾기 위한 알고리즘입니다.  \n",
        "\n",
        "그리디 탐색(Greedy Search)은 각 단계에서 가장 확률이 높은 토큰만을 선택하는 반면, 빔 서치는 여러 후보 시퀀스를 동시에 고려하면서 생성 작업을 진행합니다.\n",
        "\n",
        "![Beam search](https://velog.velcdn.com/images%2Fdldydldy75%2Fpost%2F714a88b6-a16a-4477-989b-f5a0782090db%2Fimage.png)\n",
        "\n",
        "빔 서치의 핵심 개념은 '빔 너비(beam width)'입니다. 빔 너비는 알고리즘이 각 단계에서 고려하는 후보 시퀀스의 수를 나타냅니다.  \n",
        "\n",
        "빔 너비가 1이면 그리디 탐색과 동일하게 작동하며, 빔 너비가 높아질수록 더 많은 후보 시퀀스를 고려하게 됩니다. 그러나 빔 너비가 너무 크면 계산 복잡도가 증가하게 됩니다.\n",
        "\n",
        "빔 서치는 여러 후보 시퀀스 중에서 최적의 시퀀스를 선택하는 데 유용하지만, 몇 가지 문제점도 있습니다.\n",
        "\n",
        "이러한 문제를 해결하기 위해 반복 페널티와 길이 페널티가 도입되었습니다.\n",
        "\n",
        "- 반복 페널티 (Repetition Penalty):\n",
        "\n",
        "    - 텍스트 생성 중에 동일한 단어나 구절이 반복적으로 나타나는 것을 방지하기 위한 페널티입니다.\n",
        "\n",
        "    - 반복 페널티 값이 1보다 큰 경우, 모델이 이전에 생성한 토큰을 다시 생성하는 것에 페널티를 부여합니다. 이로 인해 생성된 텍스트에서 반복적인 내용이 줄어듭니다.\n",
        "\n",
        "    - 반복 페널티 값을 조절함으로써 생성 텍스트의 반복성을 조절할 수 있습니다.\n",
        "\n",
        "- 길이 페널티 (Length Penalty):\n",
        "\n",
        "    - 빔 서치에서는 여러 후보 시퀀스 중에서 가장 확률이 높은 시퀀스를 선택합니다.\n",
        "    \n",
        "    - 그러나 짧은 시퀀스는 자연스럽게 높은 확률을 가질 수 있기 때문에, 길이 페널티를 도입하여 긴 시퀀스의 확률이 과도하게 감소되는 것을 방지합니다.\n",
        "\n",
        "    - 길이 페널티 값이 1인 경우, 페널티가 적용되지 않습니다.\n",
        "    \n",
        "    - 값이 1보다 크면 긴 시퀀스에 대한 확률이 상대적으로 증가하게 됩니다.\n",
        "\n",
        "    - 이 페널티는 생성된 텍스트의 길이를 조절하는 데 도움을 줍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAwfofE2I-pF"
      },
      "source": [
        "### 3.6 학습\n",
        "\n",
        "두 함수가 완성되었으므로, 반복문과 이들을 이용하여 학습을 진행하도록 하겠습니다.\n",
        "\n",
        "매 에포크마다 학습과 검증을 수행하고, 모델의 예측값과 정답을 데이터프레임이 저장하도록 하겠습니다.  \n",
        "\n",
        "학습을 완료하는 데에는 T4 GPU(VRAM 16G) 기준 1시간 20분 가량 소요됩니다. 그 동안 커피 한 잔의 여유를 즐기며 앞서 배웠던 내용을 살펴볼까요?  \n",
        "\n",
        "T5 모델에 대해 더 알아보셔도 좋고, Beam search에 대한 내용을 다시 한 번 확인해보셔도 좋습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] 위에서 선언한 학습 함수와 검증 함수를 이용하여 모델을 훈련시킵니다.\n",
        "\n",
        "`for`루프를 통해 매 에포크마다 학습과정과 검증과정을 수행하도록 코드를 완성시켜주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoQJeuLKeBAT",
        "outputId": "0e0d43ae-92f1-47fc-b813-c53ccb291b21"
      },
      "outputs": [],
      "source": [
        "# TRAIN_EPOCHS 동안 모델을 학습시키는 루프\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    train(epoch, tokenizer, model, device, training_loader, optimizer)  # 각 에포크마다 train 함수를 호출하여 모델을 학습\n",
        "\n",
        "# VAL_EPOCHS 동안 모델을 검증하고 결과를 predictions.csv 파일로 저장하는 루프\n",
        "for epoch in range(VAL_EPOCHS):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)    # 각 에포크마다 validate 함수를 호출하여 검증 데이터셋에 대한 모델의 성능을 평가\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})   # 생성된 예측과 실제 값을 포함하는 데이터프레임(final_df)을 생성\n",
        "    final_df.to_csv('predictions.csv')                                              # predictions.csv 파일로 저장\n",
        "    print('Output Files generated for review')                                      # 파일이 생성되었음을 알리는 메시지를 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "# TRAIN_EPOCHS 동안 모델을 학습시키는 루프\n",
        "for epoch in range(TRAIN_EPOCHS):\n",
        "    train(epoch, tokenizer, model, device, training_loader, optimizer)  # 각 에포크마다 train 함수를 호출하여 모델을 학습\n",
        "\n",
        "# VAL_EPOCHS 동안 모델을 검증하고 결과를 predictions.csv 파일로 저장하는 루프\n",
        "for epoch in range(VAL_EPOCHS):\n",
        "    predictions, actuals = validate(epoch, tokenizer, model, device, val_loader)    # 각 에포크마다 validate 함수를 호출하여 검증 데이터셋에 대한 모델의 성능을 평가\n",
        "    final_df = pd.DataFrame({'Generated Text':predictions,'Actual Text':actuals})   # 생성된 예측과 실제 값을 포함하는 데이터프레임(final_df)을 생성\n",
        "    final_df.to_csv('predictions.csv')                                              # predictions.csv 파일로 저장\n",
        "    print('Output Files generated for review')                                      # 파일이 생성되었음을 알리는 메시지를 출력\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7L71mTlQ_1E"
      },
      "source": [
        "학습이 완료되었다면, 모델을 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypSbA-vPQtvA"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"T5_news\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTaN6C9IJ4p8"
      },
      "source": [
        "## 4. Rouge 스코어를 통한 평가\n",
        "\n",
        "학습이 완료되었다면, 결과물을 불러와봅시다.  \n",
        "\n",
        "`predictions.csv`를 불러와 데이터프레임으로 저장해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        },
        "id": "28tL7J7mUAya",
        "outputId": "18a68de2-4d15-45c0-c6be-bfe51c8cddf3"
      },
      "outputs": [],
      "source": [
        "pred = pd.read_csv(\"./predictions.csv\", index_col=0)\n",
        "pred.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1M-Zc9ZKlQu"
      },
      "source": [
        "### 4.1 결과 비교\n",
        "\n",
        "반복문을 통해 데이터프레임의 상위 15개 샘플에 대한 예측값과 실제 결과를 비교해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtGpVWYaY1B9",
        "outputId": "82cc6838-54ce-4379-8563-26fc6acd4cd3"
      },
      "outputs": [],
      "source": [
        "# pred 데이터프레임의 상위 15개 행에 대해 반복\n",
        "for index, row in pred.head(15).iterrows():\n",
        "    # 'Generated Text' 열의 값을 가져옴\n",
        "    generated_text = row['Generated Text']\n",
        "    # 'Actual Text' 열의 값을 가져옴\n",
        "    actual_text = row['Actual Text']\n",
        "    # 생성된 텍스트를 출력\n",
        "    print(f\"Generated: {generated_text}\")\n",
        "    # 실제 텍스트를 출력\n",
        "    print(f\"Actual: {actual_text}\")\n",
        "    # 두 텍스트 사이에 구분을 위한 빈 줄 출력\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1V2dIvScLGuW"
      },
      "source": [
        "다소 차이가 있지만, 비슷한 단어들이 예측 결과와 레이블에서 동시에 발견됩니다.  \n",
        "\n",
        "특정 문장의 경우 레이블이 없음에도 잘 생성된 것을 볼 수 있습니다.\n",
        "\n",
        "다만 아쉬운 점은, 이렇게 육안으로 비교할 경우 정량적인 결과 분석이 어렵습니다. 이러한 경우를 위해 Rouge 스코어로 평가를 해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzk_6EbWKyDh"
      },
      "source": [
        "### 4.2 Rouge score\n",
        "\n",
        "Rouge(R-ecall O-riented U-nderstudy G for E-valuation)는 자동 요약의 성능을 평가하기 위한 메트릭 중 하나입니다. Rouge는 여러 버전이 있으며, 각 버전은 다른 방식으로 요약의 품질을 평가합니다.\n",
        "\n",
        "- ROUGE-N: N-gram 기반의 정밀도와 재현율을 계산합니다. 예를 들어,\n",
        "ROUGE-1은 unigram, ROUGE-2는 bigram에 기반한 스코어를 제공합니다.\n",
        "\n",
        "- ROUGE-L: 가장 긴 공통 부분 문자열(Longest Common Subsequence, LCS)을 기반으로 합니다. LCS는 두 문자열 사이에서 순서를 변경하지 않고 얻을 수 있는 가장 긴 공통 부분 문자열을 찾는 것을 의미합니다.\n",
        "\n",
        "- ROUGE-S: skip-bigram을 기반으로 합니다. Skip-bigram은 문장 내에서 몇 개의 단어를 건너뛰더라도 순서가 유지되는 단어 쌍을 의미합니다.\n",
        "\n",
        "Rouge 스코어는 주로 정밀도(Precision), 재현율(Recall), F1 스코어로 제공됩니다.\n",
        "\n",
        "- 정밀도는 생성된 요약 내에서 실제 요약과 일치하는 단어나 구의 비율을 나타내며,\n",
        "\n",
        "- 재현율은 실제 요약 내에서 생성된 요약과 일치하는 단어나 구의 비율을 나타냅니다.\n",
        "\n",
        "- F1 스코어는 정밀도와 재현율의 조화 평균입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCbuxowwMN5u"
      },
      "source": [
        "### 4.3 결측 문장 확인 및 제거\n",
        "\n",
        "해당 평가지표를 적용하기 위해 결측치를 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehR-NA6Zcgz6",
        "outputId": "17e18c2a-1fa7-4a3b-eaac-7f954d67cc6c"
      },
      "outputs": [],
      "source": [
        "pred.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gDFszzvMWx5"
      },
      "source": [
        "29개의 샘플에 대해 레이블 데이터가 없다고 확인되네요.  \n",
        "\n",
        "해당 샘플을 제거해줍시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dN4VJFXMIj4"
      },
      "outputs": [],
      "source": [
        "# 결측치 제거\n",
        "pred = pred.dropna()\n",
        "\n",
        "# 결측치 제거 후 데이터프레임의 크기 확인\n",
        "print(pred.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI1GggAAMh5E"
      },
      "source": [
        "### 4.4 Rouge 스코어 측정\n",
        "\n",
        "결과 데이터프레임에 대해 Rouge 스코어를 측정해보도록 하겠습니다.\n",
        "\n",
        "각 열의 값을 리스트로 변환 후 스코어를 계산하고, 결과를 출력해보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### [TODO] Rouge 스코어를 계산해주세요.\n",
        "\n",
        "아래 코드의 빈 칸을 채워넣어 실제 문장과 예측 문장 사이의 점수를 측정하도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDZloacrcGya",
        "outputId": "a7ef97f6-9db5-431c-9811-ea5554717f0a"
      },
      "outputs": [],
      "source": [
        "from rouge import Rouge  # Rouge 평가 도구를 가져옴\n",
        "\n",
        "# 'Generated Text' 열의 값을 문자열 리스트로 변환하여 predictions에 저장\n",
        "predictions = [str(text) for text in pred['Generated Text'].tolist()]\n",
        "# 'Actual Text' 열의 값을 문자열 리스트로 변환하여 actuals에 저장\n",
        "actuals = [str(text) for text in pred['Actual Text'].tolist()]\n",
        "\n",
        "rouge = Rouge()  # Rouge 객체 생성\n",
        "# 생성된 요약과 실제 요약 사이의 Rouge 스코어 계산\n",
        "scores = rouge.get_scores(predictions, actuals, avg=True)\n",
        "\n",
        "print(scores)  # Rouge 스코어 출력"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> 예시코드\n",
        "```\n",
        "from rouge import Rouge  # Rouge 평가 도구를 가져옴\n",
        "\n",
        "# 'Generated Text' 열의 값을 문자열 리스트로 변환하여 predictions에 저장\n",
        "predictions = [str(text) for text in pred['Generated Text'].tolist()]\n",
        "# 'Actual Text' 열의 값을 문자열 리스트로 변환하여 actuals에 저장\n",
        "actuals = [str(text) for text in pred['Actual Text'].tolist()]\n",
        "\n",
        "rouge = Rouge()  # Rouge 객체 생성\n",
        "# 생성된 요약과 실제 요약 사이의 Rouge 스코어 계산\n",
        "scores = rouge.get_scores(predictions, actuals, avg=True)\n",
        "\n",
        "print(scores)  # Rouge 스코어 출력\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrYTPWpmc3dB"
      },
      "source": [
        "각 지표는 다음과 같은 의미를 가집니다:\n",
        "\n",
        "- rouge-1: unigram (단일 단어)의 일치도를 나타냅니다.\n",
        "\n",
        "- rouge-2: bigram (두 단어의 조합)의 일치도를 나타냅니다.\n",
        "\n",
        "- rouge-l: 가장 긴 공통 부분 문자열의 일치도를 나타냅니다.\n",
        "각 지표에는 세 가지 값이 있습니다:\n",
        "\n",
        "- r (recall): 실제 요약에서 얼마나 많은 단어/구문이 생성된 요약에 포함되었는지 나타냅니다.\n",
        "\n",
        "- p (precision): 생성된 요약에서 실제 요약과 일치하는 단어/구문의 비율을 나타냅니다.\n",
        "\n",
        "- f (f-score): recall과 precision의 조화 평균입니다. 두 지표의 균형을 나타내는 값으로, 높을수록 좋습니다.\n",
        "\n",
        "다만, 지표가 딕셔너리로 제공되기에 가시성이 떨어집니다.  \n",
        "\n",
        "아래 코드를 통해 딕셔너리의 키와 값을 뽑아내어 정제된 형태로 출력해보겠습니다.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFz3phmKcH2I",
        "outputId": "97f87f04-626a-4a84-a5ba-0f3f01346722"
      },
      "outputs": [],
      "source": [
        "for key, value in scores.items():\n",
        "    print(f\"{key}:\\nRecall: {value['r']*100:.2f}%\\nPrecision: {value['p']*100:.2f}%\\nF-score: {value['f']*100:.2f}%\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVYQxHrsNAno"
      },
      "source": [
        "이렇게 T5 모델을 통해 결과를 측정해보았습니다. 요약에는 T5 이외에도 [Bart](https://huggingface.co/facebook/bart-base), [Pegasus](https://huggingface.co/google/pegasus-large) 등이 자주 사용됩니다.  이러한 모델을 사용하여 요약을 진행해보고, 결과를 비교해보는 것은 어떨까요?\n",
        "\n",
        "또, [Hugging Face Datasets](https://huggingface.co/datasets?task_categories=task_categories:summarization&sort=trending)에는 수많은 요약용 데이터가 준비되어있습니다. 이를 이용하여 여러분들의 실력을 키워보시는 것도 추천드립니다.\n",
        "\n",
        "이번 실습도 수고많으셨습니다!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bb03d2c478a4ab38c48aa25b3148e84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15d1aefada884a5c9a274db5fad3d11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f1ef27066504d048dd3f4f93ef821d8",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_facb646c3b81421aafb518fd307d613d",
            "value": 1208
          }
        },
        "1dc5f31497f94d598dd94d9031cebbaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0c0ecf3838a40e0b3958daa6b61a463",
            "placeholder": "​",
            "style": "IPY_MODEL_21ade4e020014be7affc919e8cb7daad",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 53.9kB/s]"
          }
        },
        "1e47a04d3b834c6d80cb75170cdc218d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f482ed31ff84ffa89a31e097399aa65": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21ade4e020014be7affc919e8cb7daad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "273c12737de640b1bf9eaed14834acc0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb23c9ca00e4a089ab774f96cf996d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c3d9ef0d9cd4ca984fc79caad5e59f3",
            "max": 891646390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e0fdeacc456944d28c8678c9d32dd4e2",
            "value": 891646390
          }
        },
        "4358c67e0eca48e2a7446a2a4e1edac9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea0abf14599945c8a8f4db98d7c1cbf5",
              "IPY_MODEL_15d1aefada884a5c9a274db5fad3d11b",
              "IPY_MODEL_1dc5f31497f94d598dd94d9031cebbaf"
            ],
            "layout": "IPY_MODEL_cbda7388e6d345b7973cd0236d65de41"
          }
        },
        "4f6d8ec73b3c4b3f8df67e3255ee7e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_273c12737de640b1bf9eaed14834acc0",
            "placeholder": "​",
            "style": "IPY_MODEL_8b00c9559c5f4b978278c778aa199536",
            "value": " 892M/892M [00:03&lt;00:00, 239MB/s]"
          }
        },
        "5811520d1d384361a65a8e2d313571fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9750a5f121045fdb7d33512ce3bb3b4",
            "placeholder": "​",
            "style": "IPY_MODEL_1e47a04d3b834c6d80cb75170cdc218d",
            "value": " 147/147 [00:00&lt;00:00, 4.12kB/s]"
          }
        },
        "5936d85cea684684a48cb0be89128da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5df8e7c094ca4fa3a29c49270097dc9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e4c09ad91d44655abed571fc519a41d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe9bff27cadf4e2ca0f51e792968a53e",
            "placeholder": "​",
            "style": "IPY_MODEL_5df8e7c094ca4fa3a29c49270097dc9b",
            "value": " 792k/792k [00:00&lt;00:00, 3.80MB/s]"
          }
        },
        "6a90953fd8ef4d46b8848ef6947c1417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d4954310dcf432ca4ba3821839166c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ffd87f676c64131bd9b68551c85cc67": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73bf01e44b3443c891a14f49c8040dd4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84937492a3bf447a935f02377b1d939f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86092b5adbb746448b59a3c07e744964",
            "placeholder": "​",
            "style": "IPY_MODEL_6d4954310dcf432ca4ba3821839166c0",
            "value": "Downloading (…)ve/main/spiece.model: 100%"
          }
        },
        "86092b5adbb746448b59a3c07e744964": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "873dc72eb3fa4413a198ae0faa94cd35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbf8d19f3a13433382348d2f8afc3dcf",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fcb56f5e112e4b46bfbf2d1e959f2c1d",
            "value": 791656
          }
        },
        "8b00c9559c5f4b978278c778aa199536": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c3d9ef0d9cd4ca984fc79caad5e59f3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9798e6d64a894c509bbada170530b215": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe2333cf28d3485fa59412d9e5d0fda8",
              "IPY_MODEL_bb99f2baa59246b7b0f85655b2d9f01b",
              "IPY_MODEL_5811520d1d384361a65a8e2d313571fd"
            ],
            "layout": "IPY_MODEL_cbba07ac78064826914fd0901f4054c5"
          }
        },
        "9b70bbd8fd514196ba20fa483b938d73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f1ef27066504d048dd3f4f93ef821d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0c0ecf3838a40e0b3958daa6b61a463": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb99f2baa59246b7b0f85655b2d9f01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bb03d2c478a4ab38c48aa25b3148e84",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6a3f30bc0ee4057a5ec6ccf2535b369",
            "value": 147
          }
        },
        "c3491186fe004bdd92ad405c10d0289a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_84937492a3bf447a935f02377b1d939f",
              "IPY_MODEL_873dc72eb3fa4413a198ae0faa94cd35",
              "IPY_MODEL_5e4c09ad91d44655abed571fc519a41d"
            ],
            "layout": "IPY_MODEL_9b70bbd8fd514196ba20fa483b938d73"
          }
        },
        "c4e8d9aef1254ac6a10290e1cd49da8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d63904ff36a441f6a2ca88aa9f2dbd26",
              "IPY_MODEL_2bb23c9ca00e4a089ab774f96cf996d7",
              "IPY_MODEL_4f6d8ec73b3c4b3f8df67e3255ee7e37"
            ],
            "layout": "IPY_MODEL_1f482ed31ff84ffa89a31e097399aa65"
          }
        },
        "cbba07ac78064826914fd0901f4054c5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cbda7388e6d345b7973cd0236d65de41": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0135b05b40c42e1947ec5096e869ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d63904ff36a441f6a2ca88aa9f2dbd26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73bf01e44b3443c891a14f49c8040dd4",
            "placeholder": "​",
            "style": "IPY_MODEL_5936d85cea684684a48cb0be89128da9",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "d6a3f30bc0ee4057a5ec6ccf2535b369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbf8d19f3a13433382348d2f8afc3dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0fdeacc456944d28c8678c9d32dd4e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9750a5f121045fdb7d33512ce3bb3b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea0abf14599945c8a8f4db98d7c1cbf5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ffd87f676c64131bd9b68551c85cc67",
            "placeholder": "​",
            "style": "IPY_MODEL_6a90953fd8ef4d46b8848ef6947c1417",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "facb646c3b81421aafb518fd307d613d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb7857cba4254d58a0d0169b74b4ed36": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcb56f5e112e4b46bfbf2d1e959f2c1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fe2333cf28d3485fa59412d9e5d0fda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb7857cba4254d58a0d0169b74b4ed36",
            "placeholder": "​",
            "style": "IPY_MODEL_d0135b05b40c42e1947ec5096e869ccf",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "fe9bff27cadf4e2ca0f51e792968a53e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
