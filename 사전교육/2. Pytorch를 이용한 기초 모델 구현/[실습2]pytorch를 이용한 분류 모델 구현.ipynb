{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iSpLXXN4qfBM"
   },
   "source": [
    "# [실습] 파이 토치 기본 문법\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLoKuDo5qj2e"
   },
   "source": [
    "## 학습 목표\n",
    "1. 파이토치를 이용한 텐서를 다루는 방법에 대해 익힙니다.\n",
    "2. 파이토치를 이용한 다양한 모델링 방법에 대해 학습합니다.\n",
    "3. 파이토치를 이용한 다양한 데이터셋 빌드 과정에 대해 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zPUw-nIRq53G"
   },
   "source": [
    "## 1. 텐서\n",
    "*   텐서는 파이토치의 가장 기본적인 데이터 구조\n",
    "*   텐서 = 다차원 배열"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "53_0jq70rPr0"
   },
   "source": [
    "### 1-1. 텐서 생성하기\n",
    "\n",
    "파이토치에서는 리스트나 배열 형태의 데이터를 텐서로 변환하여 다양한 연산을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dYt3DxWbnT2D",
    "outputId": "b2ed64f1-6be0-4c1a-f2b4-28cf56752aef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# 2차원 형태 list를 이용하여 텐서를 생성할 수 있습니다.\n",
    "torch.tensor([[1,2],[3,4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIPZR_dZkYvD"
   },
   "source": [
    "device를 지정하면 GPU에 텐서를 만들 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbCTKMdEneoD",
    "outputId": "0bf12c0c-264b-4cf1-f7fe-96b921416cc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2],[3,4.]], device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a88AdJJTkd2c"
   },
   "source": [
    "dtype을 이용하여 텐서의 데이터 형태를 지정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgffdaGRnqt8",
    "outputId": "6e1dfb64-29a1-48cd-b64d-d114d78761c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2],[3,4.]], dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Zx4T1-kzyU"
   },
   "source": [
    "### 1-2. 다양한 종류의 텐서\n",
    "PyTorch는 다양한 자료형의 텐서를 제공합니다. 각 텐서는 특정 데이터 타입의 값을 저장하고, 해당 데이터 타입에 최적화된 연산을 수행할 수 있습니다. 주요 텐서 타입은 다음과 같습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y07pXA4cad-p",
    "outputId": "38d11fef-5f5f-4101-a324-20d175dbbf7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3., 4., 5., 6.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.FloatTensor([0, 1, 2, 3, 4, 5, 6])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "irOmEauKk71H",
    "outputId": "6ca644a2-42cf-40d4-bd8f-249b5221203f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.IntTensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CXb5PxS3k_BM",
    "outputId": "fedb9e1e-67fe-41c2-e0db-ca80e2ac4ff8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.LongTensor([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qJBhfHF0lC-H",
    "outputId": "0dc56a58-0f1b-4b4f-a271-658e6728c264"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ByteTensor([1, 0, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uju7u7GdlZ64"
   },
   "source": [
    "### 1-3. 텐서의 차원 및 크기 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMc4pCH5ljXX"
   },
   "source": [
    "PyTorch에서 텐서의 구조를 파악하는 것은 매우 중요합니다.\n",
    "\n",
    " 특히, 다양한 연산이나 모델링을 할 때 텐서의 차원과 크기를 알아야 합니다.\n",
    "\n",
    "`dim()`: 텐서의 차원을 반환합니다. 예를 들어, 1차원 벡터는 1, 2차원 행렬은 2, 3차원 텐서는 3을 반환합니다.\n",
    "`shape `혹은` size()`: 텐서의 각 차원별 크기를 튜플로 반환합니다. 예를 들어,\n",
    "2×3 크기의 2차원 텐서의 경우 `(2, 3)`을 반환합니다.\n",
    "위의 메서드와 속성을 활용하면, 텐서의 구조를 빠르게 확인하고 원하는 형태로 변환 작업을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_YvE31GapJP",
    "outputId": "bce34077-a941-4082-8d69-78f4a00b1dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([7])\n",
      "torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "print(t.dim())  #  차원\n",
    "print(t.shape)  # shape\n",
    "print(t.size()) # shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[1,2],[3,4]]).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PdediV2Al7Pg"
   },
   "source": [
    "### 1-4. view : 텐서의 모양 변경하기\n",
    "\n",
    "`view`는 주어진 텐서의 크기(혹은 모양)를 변경하는 기능을 합니다.\n",
    "코드는 먼저 3차원의 numpy 배열을 생성하고, 이를 PyTorch의 `FloatTensor`로 변환하는 과정을 보여줍니다.\n",
    "\n",
    "예제 에서 ft 텐서의 크기는 (2, 2, 3)입니다. 이렇게 차원과 크기를 파악한 뒤, view 메서드를 활용하면 원하는 차원과 크기로 텐서를 쉽게 변환할 수 있습니다.\n",
    "\n",
    "\n",
    "텐서의 원래 요소의 총 개수와 변환된 후의 요소의 총 개수는 항상 동일해야 합니다.\n",
    "\n",
    "`[-1, 3]`에서 -1은 특별한 값으로, 해당 차원의 크기는 다른 차원의 크기를 통해 유추되어집니다. 여기서는 `(?, 3)`의 형태로 크기를 변경하라는 의미이며, 실제로 변경된 후의 텐서의 크기는 `(4, 3)`이 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHeEu2C2as_B",
    "outputId": "ca8bc00a-c266-4fe3-bb84-1a4e4a1f165e",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view 매우중요\n",
    "#dim()을 사용하면 현재 텐서의 차원을 보여줍니다. shape나 size()를 사용하면 크기를 확인할 수 있습니다.\n",
    "import numpy as np\n",
    "t = np.array([[[0, 1, 2],\n",
    "               [3, 4, 5]],\n",
    "              [[6, 7, 8],\n",
    "               [9, 10, 11]]])\n",
    "ft = torch.FloatTensor(t)\n",
    "ft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0,  1,  2],\n",
       "        [ 3,  4,  5]],\n",
       "\n",
       "       [[ 6,  7,  8],\n",
       "        [ 9, 10, 11]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# t = np.arange(12).reshape(2,2,3) # same\n",
    "t = np.arange(12).reshape(-1,2,3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8cMl_LhDa5K4",
    "outputId": "f24f8e3c-f7b6-497c-c44e-ec6cde5a8d17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.],\n",
      "        [ 3.,  4.,  5.],\n",
      "        [ 6.,  7.,  8.],\n",
      "        [ 9., 10., 11.]])\n",
      "torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.view([-1, 3])) # ft라는 텐서를 (?, 3)의 크기로 변경\n",
    "print(ft.view([-1, 3]).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kmWXEFK5fCL"
   },
   "source": [
    "### 1-5. squeeze: 차원의 크기가 1인 경우 해당 차원을 제거하기\n",
    "squeeze 메서드는 텐서의 차원 중 크기가 1인 차원을 제거하는 기능을 합니다. 이 메서드는 딥 러닝 모델링 시, 결과의 차원을 조정해야 할 때나 특정 연산을 적용하기 전 차원을 줄여야 할 때 유용하게 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CadN5HCqa_Un",
    "outputId": "531a88b3-7b04-4cbc-b81e-788f8d2a6e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "#squeeze\n",
    "ft = torch.FloatTensor([[0], [1], [2]])\n",
    "print(ft)\n",
    "print(ft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PSpC6uGMbKLW",
    "outputId": "40542ad9-e22e-49c3-deeb-8df373435723"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(ft.squeeze())\n",
    "print(ft.squeeze().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qafJ7nJ55pjI"
   },
   "source": [
    "squeeze 메서드는 텐서의 차원 중 크기가 1인 차원을 제거하는 기능을 합니다. 이 메서드는 딥 러닝 모델링 시, 결과의 차원을 조정해야 할 때나 특정 연산을 적용하기 전 차원을 줄여야 할 때 유용하게 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YfqnlLvr5qkR",
    "outputId": "25a27ec0-45b0-4650-9abc-82133c8f4de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2.])\n",
      "torch.Size([3])\n",
      "tensor([[0., 1., 2.]])\n",
      "torch.Size([1, 3])\n",
      "tensor([[0.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "ft = torch.Tensor([0, 1, 2])\n",
    "print(ft)\n",
    "print(ft.shape)\n",
    "\n",
    "ft_unsqueeze = ft.unsqueeze(0)  # 0번째 차원에 1을 추가\n",
    "print(ft_unsqueeze)\n",
    "print(ft_unsqueeze.shape)\n",
    "\n",
    "ft_unsqueeze2 = ft.unsqueeze(1)  # 1번째 차원에 1을 추가\n",
    "print(ft_unsqueeze2)\n",
    "print(ft_unsqueeze2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28HxeCWc6Ic_"
   },
   "source": [
    "이렇게, unsqueeze 메서드를 사용하여 텐서의 차원을 적절하게 조절함으로써 딥 러닝 모델의 연산을 원활하게 진행할 수 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "57r4UVta6JfG"
   },
   "source": [
    "### 1-6. topk: 텐서에서 상위 k개의 값과 그 위치 반환하기\n",
    "\n",
    "PyTorch의 topk 함수는 텐서에서 가장 큰 k개의 값을 반환하며, 해당 값들의 위치(index)도 함께 반환합니다. 이 함수는 모델 예측의 결과 중 상위 k개의 예측값을 뽑아낼 때나, 특정 조건을 만족하는 상위 k개의 값을 찾을 때 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kTC_60x4aFKG",
    "outputId": "b256be34-e9e8-4824-abf7-2f5e7d81798d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 4., 3.])\n",
      "tensor([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "#topk\n",
    "x = torch.arange(1., 6.)\n",
    "# tensor([ 1.,  2.,  3.,  4.,  5.])\n",
    "values, indices = torch.topk(x, 3)\n",
    "print(values)\n",
    "# tensor([5., 4., 3.])\n",
    "print(indices)\n",
    "# tensor([4, 3, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZ5MWZai7G1h"
   },
   "source": [
    "## 2. 파이 토치 관련 유용한 모듈 및 옵션"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cOdu9w568GKG"
   },
   "source": [
    "\n",
    "1. **torchvision**\n",
    "\n",
    "    torchvision는 이미지 처리에 특화된 도구 및 라이브러리를 제공하는 모듈입니다. 사전 학습된 모델, 일반적인 이미지 데이터셋 등에 대한 액세스를 제공합니다.\n",
    "\n",
    "2. **nn**\n",
    "\n",
    "    nn 모듈은 딥러닝 모델 구축에 필요한 다양한 구성 요소와 레이어, 활성화 함수, 손실 함수 등을 포함하고 있습니다.\n",
    "\n",
    "3. **optim**\n",
    "\n",
    "    optim 모듈은 다양한 최적화 알고리즘 (예: SGD, Adam)을 제공하여 네트워크의 가중치를 업데이트합니다.\n",
    "\n",
    "4. **nn.functional (F)**\n",
    "\n",
    "    torch.nn.functional에는 파라미터가 필요 없는 함수들(예: 활성화 함수, dropout)이 포함되어 있습니다.\n",
    "\n",
    "5. **DataLoader**\n",
    "\n",
    "    DataLoader는 배치 학습을 위한 데이터 로딩, 미니 배치 생성 등의 기능을 제공합니다.\n",
    "\n",
    "6. **datasets**\n",
    "\n",
    "    datasets는 일반적인 표준 데이터셋에 대한 액세스를 제공합니다 (예: MNIST, CIFAR-10).\n",
    "\n",
    "7. **transforms**\n",
    "\n",
    "    transforms는 이미지 및 텐서에 적용할 수 있는 데이터 전처리 및 변환 기능을 제공합니다.\n",
    "\n",
    "8. **SummaryWriter**\n",
    "\n",
    "    SummaryWriter는 TensorBoard에 로깅 및 시각화를 위한 인터페이스를 제공합니다.\n",
    "\n",
    "9. **cudnn**\n",
    "\n",
    "    cudnn은 NVIDIA cuDNN 라이브러리에 대한 설정 및 인터페이스를 제공합니다. 이 라이브러리는 딥 러닝 연산을 위한 GPU 가속화 기능을 제공합니다.\n",
    "\n",
    "10. **torchsummary**\n",
    "\n",
    "    torchsummary의 summary 함수는 모델의 구조와 파라미터 개수를 쉽게 확인할 수 있게 도와줍니다.\n",
    "\n",
    "11. **torch.onnx**\n",
    "\n",
    "    torch.onnx는 PyTorch 모델을 ONNX(Open Neural Network Exchange) 형식으로 변환하는 기능을 제공합니다. 이를 통해 다른 딥 러닝 프레임워크와 호환성을 갖게 됩니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3s0Jx8l8wuD"
   },
   "source": [
    "### 2-1. 다양한 모듈들 임포트 및 축약 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "7H0jxrnynsFr"
   },
   "outputs": [],
   "source": [
    "# torch 의 유용한 함수들\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn  # neural network 모음. (e.g. nn.Linear, nn.Conv2d, BatchNorm, Loss functions 등등)\n",
    "import torch.optim as optim  # Optimization algorithm 모음, (e.g. SGD, Adam, 등등)\n",
    "import torch.nn.functional as F  # 파라미터가 필요없는 Function 모음\n",
    "from torch.utils.data import DataLoader  # 데이터 세트 관리 및 미니 배치 생성을 위한 함수 모음\n",
    "import torchvision.datasets as datasets  # 표준 데이터 세트 모음\n",
    "import torchvision.transforms as transforms  # 데이터 세트에 적용 할 수있는 변환 관련 함수 모음\n",
    "from torch.utils.tensorboard import SummaryWriter  # tensorboard에 출력하기 위한 함수 모음\n",
    "import torch.backends.cudnn as cudnn  # cudnn을 다루기 위한 값 모음\n",
    "from torchsummary import summary  # summary를 통한 model의 현황을 확인 하기 위함\n",
    "import torch.onnx  # model을 onnx 로 변환하기 위함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r4mCtTh383xw"
   },
   "source": [
    "### 2-2. Seed\n",
    "Seed는 난수 생성 알고리즘의 시작 숫자입니다. 동일한 Seed 값을 사용하면 동일한 난수 시퀀스가 생성됩니다. 이를 통해 확률적 요소가 포함된 코드의 실행 결과를 예측 가능하게 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "c64Mucx1sYjx"
   },
   "outputs": [],
   "source": [
    "seed = 100\n",
    "# pytorch 내부적으로 사용하는 seed 값 설정\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# cuda를 사용할 경우 pytorch 내부적으로 사용하는 seed 값 설정\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kl150NEc88Il"
   },
   "source": [
    "`torch.manual_seed(seed)`\n",
    "\n",
    "PyTorch의 CPU 연산을 위한 Seed 값을 설정합니다. 모든 연산에서 사용되는 난수의 기본 Seed를 설정하여 CPU 연산의 일관성을 보장합니다.\n",
    "\n",
    "`torch.cuda.manual_seed(seed)`\n",
    "\n",
    " PyTorch의 GPU 연산을 위한 Seed 값을 설정합니다. GPU 연산에서 사용되는 난수의 기본 Seed를 설정하여 GPU 연산의 일관성을 보장합니다. 만약 여러개의 GPU를 사용한다면, torch.cuda.manual_seed_all(seed)를 사용하여 모든 GPU의 Seed 값을 설정해야 할 수도 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fsn0nE1C9IP4"
   },
   "source": [
    "### 2-3. GPU 사용 관련 설정\n",
    "GPU를 효과적으로 사용하는 것은 딥러닝 연산에 큰 도움이 됩니다. GPU 설정과 관련된 기본적인 내용들을 보여주고 있으며, 실제 환경에 맞게 조정하여 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "xP8xP34_tcyK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# cuda가 사용 가능한 지 확인\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# cuda가 사용 가능하면 device에 \"cuda\"를 저장하고 사용 가능하지 않으면 \"cpu\"를 저장한다.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 멀티 GPU 사용 시 사용 가능한 GPU 셋팅 관련\n",
    "# 아래 코드의 \"0,1,2\"는 GPU가 3개 있고 그 번호가 0, 1, 2 인 상황의 예제입니다.\n",
    "# 만약 GPU가 5개이고 사용 가능한 것이 0, 3, 4 라면 \"0,3,4\" 라고 적으면 됩니다.\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"\n",
    "\n",
    "# 현재 PC의 사용가능한 GPU 사용 갯수 확인\n",
    "print(torch.cuda.device_count())\n",
    "# 사용 가능한 device 갯수에 맞춰서 0번 부터 GPU 할당\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(\n",
    "    list(map(str, list(range(torch.cuda.device_count()))))\n",
    ")\n",
    "\n",
    "# 실제 사용할 GPU만 선택하려면 아래와 같이 입력하면 됩니다. (예시)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1, 4, 6\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Taz0KmN9aqV"
   },
   "source": [
    "### 2-4 CuDNN 관련 설정\n",
    "CuDNN 설정은 딥러닝 연산의 효율성과 속도에 큰 영향을 줍니다. 아래 설정은 딥러닝 연산을 최적화하고, 연산 속도를 향상시키기 위한 몇 가지 기본적인 설정 예시입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "FawxLD-Cts3t"
   },
   "outputs": [],
   "source": [
    "# cudnn을 사용하도록 설정. GPU를 사용하고 있으면 기본값은 True 입니다.\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.enabled = True\n",
    "\n",
    "# inbuilt cudnn auto-tuner가 사용 중인 hardware에 가장 적합한 알고리즘을 선택하도록 허용합니다.\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udqBTVRG6lJq"
   },
   "source": [
    "## 3. DataLoader\n",
    "\n",
    "*   PyTorch에서는 모델 학습 시 데이터의 배치 관리를 쉽게 도와주는 DataLoader를 제공합니다.\n",
    "*   DataLoader는 데이터셋과 샘플러를 결합하여 주어진 데이터셋에서 배치만큼 데이터를 뽑아오는 반복 가능한 객체(iterable)를 생성합니다.\n",
    "\n",
    "*  이를 통해 데이터를 쉽게 셔플하거나 병렬 처리를 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "TTyK-fAkaHP8"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
    "                               [93,  88,  93],\n",
    "                               [89,  91,  90],\n",
    "                               [96,  98,  100],\n",
    "                               [73,  66,  70]])\n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1c302mlUaJlN"
   },
   "outputs": [],
   "source": [
    "#dataset 만들\n",
    "dataset = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "iLenZBa4aMZm"
   },
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FRgp3MGaRAt",
    "outputId": "ff8346b1-d780-4050-cb28-d6423e4a0368"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 93.,  88.,  93.],\n",
      "        [ 96.,  98., 100.]]) tensor([[185.],\n",
      "        [196.]])\n",
      "tensor([[73., 80., 75.],\n",
      "        [73., 66., 70.]]) tensor([[152.],\n",
      "        [142.]])\n",
      "tensor([[89., 91., 90.]]) tensor([[180.]])\n"
     ]
    }
   ],
   "source": [
    "for x , y in dataloader:\n",
    "    print(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3lIGQg4F9ryW"
   },
   "source": [
    "## 4. 파이토치를 활용한 선형회귀 연습\n",
    "선형회귀(Linear Regression)는 머신러닝과 통계에서 기본적으로 사용하는 예측 방법 중 하나입니다. 선형회귀는 데이터 포인트 사이의 선형 관계를 찾는 것을 목표로 합니다. 즉, 주어진 독립 변수(X)에 대한 종속 변수(Y)의 응답을 예측하려고 합니다.\n",
    "\n",
    "본 챕터를 통해 다음과 같은 내용을 학습하게 됩니다\n",
    "\n",
    "\n",
    "\n",
    "*   파이토치의 기본 개념들 도구들 연습\n",
    "*   선형회귀 모델의 구조와 작동 원리 이해\n",
    "*   파이토치를 사용한 선형회귀 모델의 구현 및 학습\n",
    "*   다양한 방식의 모델링 방법\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q7g4pcR6_7iB"
   },
   "source": [
    "### 4-1 데이터 준비\n",
    "먼저, 선형회귀를 위한 학습 데이터를 준비합니다. 우리가 사용할 데이터는\n",
    "\n",
    "x와 y 사이에 간단한 선형 관계를 가진다고 가정합니다. 여기서\n",
    "y=2x 라는 관계를 가진 데이터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "910eHF8lvP1w"
   },
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1], [2], [3]])\n",
    "y_train = torch.FloatTensor([[2], [4], [6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PoUqKOF9_1vg",
    "outputId": "30b56716-4b3e-4b50-c398-36d10c0a408c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.],\n",
      "        [2.],\n",
      "        [3.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(x_train)\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJdrCVLLAzEA",
    "outputId": "4e468550-faec-4cfb-f237-92b839a6f96d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.],\n",
      "        [4.],\n",
      "        [6.]])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "print(y_train)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l73GLMSXAJpO"
   },
   "source": [
    "### 4-2 가중치와 편향 초기화\n",
    "\n",
    "선형회귀의 목표는 주어진 데이터에 대해 가장 잘 맞는 직선을 찾는 것입니다. 이 직선은 y = Wx + b로 표현될 수 있으며, 여기서\n",
    "\n",
    "\n",
    "**W는 가중치(weight)이고,**\n",
    "\n",
    "\n",
    "**b는 편향(bias)입니다.**\n",
    "\n",
    "\n",
    "데이터 학습을 시작하기 전에, 초기의\n",
    "W와 b 값을 정해줄 필요가 있습니다. 일반적으로는 랜덤 값으로 시작하나, 이 예제에서는 간단히\n",
    "W를 0으로 시작하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrXMxD88TDpX",
    "outputId": "4ac063d6-6d12-4d71-d634-559c4eecfc17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# 가중치와 편향 초기화\n",
    "# 가중치 W를 0으로 초기화하고 학습을 통해 값이 변경되는 변수임을 명시함.\n",
    "W = torch.zeros(1, requires_grad=True)\n",
    "# 가중치 W를 출력\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y3onZ5tbTKqN",
    "outputId": "a3222320-3748-4806-fda6-62bbc0e43f39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "b = torch.zeros(1, requires_grad=True)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZLYTe5HWAgWA"
   },
   "source": [
    "### 4-2. 가설(hypothesis) 설정하기\n",
    "선형 회귀의 핵심은 주어진 x값에 대한 예측값 y를 찾는것 입니다. 이 예측값을 구하기 위해 가설 이라는 함수를 정의합니다 여기서는 간단한 선형 가설을 사용합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MloeVBiaTPgm",
    "outputId": "483b3f36-9d36-4a1b-cdc0-303001938ea9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * W + b\n",
    "print(hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWesHQ8jAy-N"
   },
   "source": [
    "### 4-3. 비용함수 및 최적화\n",
    "우리의 목표는 주어진 데이터에 가장 잘 맞는 직선을 찾는 것입니다. 이를 위해 실제값과 예측값 사이의 차이를 계산하는 비용 함수를 정의하게 됩니다. 선형 회귀에서는 주로 평균 제곱 오차(Mean Squared Error, MSE)를 비용 함수로 사용합니다.\n",
    "\n",
    "**평균 제곱 오차(MSE)**\n",
    "\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    "\n",
    "\n",
    "**최적화(optimization)**\n",
    "\n",
    "\n",
    "선형 회귀의 학습 과정은 결국 이 비용을 최소화하는 가중치 W와 편향 b를 찾는 것입니다. 이를 위해 경사 하강법(Gradient Descent)와 같은 최적화 알고리즘이 사용됩니다. 파이토치에서는 다양한 최적화 알고리즘을 제공하며, 여기서는 SGD(Stochastic Gradient Descent)를 사용하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4QcqNrJTmU1",
    "outputId": "5e603115-8025-475f-947c-1612f0cc2494"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# mse 선언 뒤에서 더 간편하게 만들 수 있는 방법 소개 예정\n",
    "cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "FsjYddgPbtqq"
   },
   "outputs": [],
   "source": [
    "# optimizer 선언\n",
    "optimizer = optim.SGD([W, b], lr=0.01)\n",
    "# gradient를 0으로 초기화\n",
    "optimizer.zero_grad()\n",
    "# 비용 함수를 미분하여 gradient 계산\n",
    "cost.backward()\n",
    "# W와 b를 업데이트\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Th24XQ6qbzf0",
    "outputId": "0cea1a40-58df-48a8-ead2-7b3642620562"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1999 W: 0.353, b: 0.151 Cost: 14.770963\n",
      "Epoch  100/1999 W: 1.746, b: 0.577 Cost: 0.047939\n",
      "Epoch  200/1999 W: 1.801, b: 0.453 Cost: 0.029624\n",
      "Epoch  300/1999 W: 1.843, b: 0.356 Cost: 0.018306\n",
      "Epoch  400/1999 W: 1.877, b: 0.280 Cost: 0.011312\n",
      "Epoch  500/1999 W: 1.903, b: 0.220 Cost: 0.006990\n",
      "Epoch  600/1999 W: 1.924, b: 0.173 Cost: 0.004319\n",
      "Epoch  700/1999 W: 1.940, b: 0.136 Cost: 0.002669\n",
      "Epoch  800/1999 W: 1.953, b: 0.107 Cost: 0.001649\n",
      "Epoch  900/1999 W: 1.963, b: 0.084 Cost: 0.001019\n",
      "Epoch 1000/1999 W: 1.971, b: 0.066 Cost: 0.000630\n",
      "Epoch 1100/1999 W: 1.977, b: 0.052 Cost: 0.000389\n",
      "Epoch 1200/1999 W: 1.982, b: 0.041 Cost: 0.000240\n",
      "Epoch 1300/1999 W: 1.986, b: 0.032 Cost: 0.000149\n",
      "Epoch 1400/1999 W: 1.989, b: 0.025 Cost: 0.000092\n",
      "Epoch 1500/1999 W: 1.991, b: 0.020 Cost: 0.000057\n",
      "Epoch 1600/1999 W: 1.993, b: 0.016 Cost: 0.000035\n",
      "Epoch 1700/1999 W: 1.995, b: 0.012 Cost: 0.000022\n",
      "Epoch 1800/1999 W: 1.996, b: 0.010 Cost: 0.000013\n",
      "Epoch 1900/1999 W: 1.997, b: 0.008 Cost: 0.000008\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "nb_epochs = 1999 # 원하는만큼 경사 하강법을 반복\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    hypothesis = x_train * W + b\n",
    "\n",
    "    # cost 계산\n",
    "    cost = torch.mean((hypothesis - y_train) ** 2)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} W: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, W.item(), b.item(), cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "orwBAACDb7Y5"
   },
   "outputs": [],
   "source": [
    "# nn module로 선형회귀\n",
    "# 모델을 선언 및 초기화. 단순 선형 회귀이므로 input_dim=1, output_dim=1.\n",
    "model = nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CO1PfkgtlGBt",
    "outputId": "c100a728-5efb-4311-aee5-a467ec0b04af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.3530]], requires_grad=True), Parameter containing:\n",
      "tensor([0.5078], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "2skJJScolGaJ"
   },
   "outputs": [],
   "source": [
    "# optimizer 설정. 경사 하강법 SGD를 사용하고 learning rate를 의미하는 lr은 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c1ka2aKBtq9"
   },
   "source": [
    "### 4-4. 모델학습\n",
    "이제 학습 과정을 살펴 보겠습니다.\n",
    "\n",
    "\n",
    "\n",
    "1.   에포크(Epoch):\n",
    "에포크란 전체 훈련 데이터가 학습에 한 번 사용된 주기를 말합니다. 여기서는 총 2000번의 에포크(0 ~ 1999) 동안 학습을 수행하도록 설정했습니다.\n",
    "2.   예측(Hypothesis):우리의 모델은 입력 x에 가중치 W를 곱하고 편향 b를 더하여 예측값을 계산합니다. 이 예측값은 hypothesis에 저장됩니다.\n",
    "3.  비용 함수(Cost Function):\n",
    "이후, 예측된 값 hypothesis와 실제값 y_train 사이의 오차를 평균 제곱 오차로 계산하여 cost에 저장합니다.\n",
    "4. 최적화(Gradient Descent): 계산된 cost를 사용하여 경사 하강법을 통해 모델의 가중치 W와 편향 b를 업데이트합니다.\n",
    "5. 로깅(Logging): 마지막으로, 학습 진행 상황을 확인하기 위해 100 에포크마다 W, b 및 cost 값을 출력합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMymdiJzlJjU",
    "outputId": "37c42ec9-c05d-4180-ebbe-bc228be5ac96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 9.571098\n",
      "Epoch  100/2000 Cost: 0.094508\n",
      "Epoch  200/2000 Cost: 0.058400\n",
      "Epoch  300/2000 Cost: 0.036088\n",
      "Epoch  400/2000 Cost: 0.022300\n",
      "Epoch  500/2000 Cost: 0.013780\n",
      "Epoch  600/2000 Cost: 0.008515\n",
      "Epoch  700/2000 Cost: 0.005262\n",
      "Epoch  800/2000 Cost: 0.003252\n",
      "Epoch  900/2000 Cost: 0.002009\n",
      "Epoch 1000/2000 Cost: 0.001242\n",
      "Epoch 1100/2000 Cost: 0.000767\n",
      "Epoch 1200/2000 Cost: 0.000474\n",
      "Epoch 1300/2000 Cost: 0.000293\n",
      "Epoch 1400/2000 Cost: 0.000181\n",
      "Epoch 1500/2000 Cost: 0.000112\n",
      "Epoch 1600/2000 Cost: 0.000069\n",
      "Epoch 1700/2000 Cost: 0.000043\n",
      "Epoch 1800/2000 Cost: 0.000026\n",
      "Epoch 1900/2000 Cost: 0.000016\n",
      "Epoch 2000/2000 Cost: 0.000010\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train) # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward() # backward 연산\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, nb_epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XST1j6wCPHU"
   },
   "source": [
    "### 4-5 모델 예측\n",
    "학습된 모델을 사용하여 새로운 데이터에 대한 예측을 수행해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oAQ4AcR6lNft",
    "outputId": "ed6e4620-f979-40bd-b42d-ca8964dd3868"
   },
   "outputs": [],
   "source": [
    "# 임의의 입력 4를 선언\n",
    "new_var =  torch.FloatTensor([[4.0]])\n",
    "# 입력한 값 4에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) # forward 연산\n",
    "# y = 2x 이므로 입력이 4라면 y가 8에 가까운 값이 나와야 제대로 학습이 된 것\n",
    "print(\"훈련 후 입력이 4일 때의 예측값 :\", pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pf_u4tQtCYrF"
   },
   "source": [
    "이 예제에서는 y = 2x 관계를 가지는 데이터로 모델을 학습시켰기 때문에, 입력값이 4일 때 예측값은 8에 가까운 값이 출력되어야 합니다. 이를 통해 모델이 정상적으로 학습되었음을 알 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1rjfo-UE3Jq"
   },
   "source": [
    "### 4-6. 모델 파라메터 확인\n",
    "PyTorch의 model.parameters() 메서드를 사용하면, 해당 모델의 모든 파라미터(가중치와 편향)를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s9MtZbPJlOH1",
    "outputId": "a6cc8001-1474-4659-acaa-ef73ebc01183"
   },
   "outputs": [],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "smNupTpeFECm"
   },
   "source": [
    "## 5. 파이토치를 활용한 다중 선형회귀 연습\n",
    "\n",
    "선형 회귀는 종속 변수와 하나 이상의 독립 변수 사이의 관계를 모델링하는 것을 목표로 합니다. 우리는 이미 독립 변수가 하나인 선형 회귀를 살펴보았습니다. 이번 챕터에서는 독립 변수가 두 개 이상인 다중 선형 회귀(multiple linear regression)에 대해 알아보겠습니다.\n",
    "\n",
    "\n",
    "다중 선형 회귀는 여러 개의 입력 특성을 사용하여 출력을 예측하며, 각 특성에는 그에 해당하는 가중치가 있습니다. 이를 표현할 때는 다음과 같은 수식을 생각할 수 있습니다\n",
    "\n",
    "y = w1x1 + w2x2+ .. wnxn+b\n",
    "\n",
    "여기서 x1,x2,xn , w은 각각 독립 변수이며 w 는 가중치 입니다\n",
    "\n",
    "이 챕터에서는 다중 선형 회귀를 파이토치를 활용하여 구현하고 학습하는 방법을 알아보겠습니다. 특히, 여러 독립 변수들로부터 하나의 출력을 예측하는 방법에 초점을 맞춰 설명하게 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okYBVHcoGjad"
   },
   "source": [
    "### 5-1. 다중 선형회귀 데이터셋 구성\n",
    "\n",
    "다중 선형 회귀를 구현하기 위해 샘플 데이터를 구성해봅시다.\n",
    "\n",
    "x_train은 독립 변수 텐서로, 각 행은 하나의 데이터 샘플을 나타내며 각 샘플은 3개의 독립 변수 값을 가지고 있습니다.\n",
    "\n",
    "반면 y_train은 종속 변수 텐서로 각 샘플의 정답 값을 담고 있습니다.\n",
    "\n",
    "이 데이터를 활용하여 다중 선형 회귀 모델을 학습시키는 과정을 진행할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "i0_GGgmWlPck"
   },
   "outputs": [],
   "source": [
    "# 다중 선형 회귀 구현\n",
    "x_train = torch.FloatTensor(\n",
    "    [[73, 80, 75], [93, 88, 93], [89, 91, 90], [96, 98, 100], [73, 66, 70]]\n",
    ")\n",
    "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Km3ZUA7RiA-"
   },
   "source": [
    "### 5-2 모델 정의 및 초기\n",
    "다중 선형 회귀를 구현하기 위해 모델을 정의합니다.\n",
    "\n",
    "PyTorch의 `nn.Linear`는 선형 계층을 나타내며, 이 경우 다중 선형 회귀를 위해 `input_dim=3`와 `output_dim=1`을 인자로 전달하였습니다.\n",
    "\n",
    " 여기서 `input_dim=3`은 세 개의 독립 변수를 나타내며,\n",
    "\n",
    "`output_dim=1`은 하나의 출력 값을 의미합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O_28S-0VlT_S",
    "outputId": "7a8ab4e4-c596-49b5-ae2e-cafc35b4e38b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.2740, -0.5279, -0.3371]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.4411], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "yi_GQtC3lU-6"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAs85K8hR3a4"
   },
   "source": [
    "### 5-3. 학습 시작\n",
    "\n",
    "주어진 데이터에 대해서 경사 하강법을 사용하여 선형 회귀 모델을 학습합니다.\n",
    "*  ` prediction = model(x_train)`\n",
    "모델에 학습 데이터를 전달하여 예측값을 계산합니다. 이 때, model(x_train)은 model.forward(x_train)과 동일한 표현입니다.\n",
    "*    `cost = F.mse_loss(prediction, y_train)` 예측값과 실제값 간의 차이를 계산하기 위해 평균 제곱 오차(MSE)를 사용합니다. PyTorch는 평균 제곱 오차를 계산하는 함수인 F.mse_loss를 제공합니다.\n",
    "*   ` optimizer.zero_grad(), cost.backward()` 경사 하강법을 수행하기 전에 미분 값을 0으로 초기화합니다. 그 후, `cost.backward()`를 통해 역전파를 수행하며 가중치와 편향에 대한 미분 값을 계산합니다.\n",
    "*   `optimizer.step() `계산된 미분 값을 이용하여 파라미터(가중치와 편향)를 업데이트 합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2XWS_yB-lZG_",
    "outputId": "5134a351-5164-46ef-a6e2-5a054665249a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 72985.664062\n",
      "Epoch  100/2000 Cost: 0.601515\n",
      "Epoch  200/2000 Cost: 0.589830\n",
      "Epoch  300/2000 Cost: 0.578705\n",
      "Epoch  400/2000 Cost: 0.568106\n",
      "Epoch  500/2000 Cost: 0.558023\n",
      "Epoch  600/2000 Cost: 0.548425\n",
      "Epoch  700/2000 Cost: 0.539282\n",
      "Epoch  800/2000 Cost: 0.530560\n",
      "Epoch  900/2000 Cost: 0.522257\n",
      "Epoch 1000/2000 Cost: 0.514343\n",
      "Epoch 1100/2000 Cost: 0.506793\n",
      "Epoch 1200/2000 Cost: 0.499597\n",
      "Epoch 1300/2000 Cost: 0.492724\n",
      "Epoch 1400/2000 Cost: 0.486171\n",
      "Epoch 1500/2000 Cost: 0.479909\n",
      "Epoch 1600/2000 Cost: 0.473943\n",
      "Epoch 1700/2000 Cost: 0.468238\n",
      "Epoch 1800/2000 Cost: 0.462775\n",
      "Epoch 1900/2000 Cost: 0.457555\n",
      "Epoch 2000/2000 Cost: 0.452571\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)  # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        # 100번마다 로그 출력\n",
    "        print(\"Epoch {:4d}/{} Cost: {:.6f}\".format(epoch, nb_epochs, cost.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFcqcGWClaIi",
    "outputId": "088ee063-80be-45a9-fd73-89580785aa8f"
   },
   "outputs": [],
   "source": [
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-zaLWLITbU-"
   },
   "source": [
    "### 5-4. 클래스 기반 모델 구현\n",
    "PyTorch를 활용해 모델을 클래스 형태로 구현하는 것이 일반적인입니다.\n",
    "\n",
    " 이는 모델의 구조와 연산을 묶어 표현하기 쉽게 하기 위함입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "6oCMRDWylfi_"
   },
   "outputs": [],
   "source": [
    "# 클래스 형태로 구현\n",
    "class MultivariateLinearRegressionModel(nn.Module): # nn.module을 상속받아서 클래스 정의를 해야 한다\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3, 1)  # 다중 선형 회귀이므로 input_dim=3, output_dim=1.\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "DHUUiJ68lv4z"
   },
   "outputs": [],
   "source": [
    "model = MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "o9ZhYEkzlwuA"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qh7BZl0glxnK",
    "outputId": "561eb5c6-ada7-4420-e894-0f6b0b9dbcd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost: 27189.396484\n",
      "Epoch  100/2000 Cost: 7.947201\n",
      "Epoch  200/2000 Cost: 7.563591\n",
      "Epoch  300/2000 Cost: 7.200102\n",
      "Epoch  400/2000 Cost: 6.855614\n",
      "Epoch  500/2000 Cost: 6.529204\n",
      "Epoch  600/2000 Cost: 6.219892\n",
      "Epoch  700/2000 Cost: 5.926751\n",
      "Epoch  800/2000 Cost: 5.648952\n",
      "Epoch  900/2000 Cost: 5.385696\n",
      "Epoch 1000/2000 Cost: 5.136173\n",
      "Epoch 1100/2000 Cost: 4.899686\n",
      "Epoch 1200/2000 Cost: 4.675560\n",
      "Epoch 1300/2000 Cost: 4.463129\n",
      "Epoch 1400/2000 Cost: 4.261769\n",
      "Epoch 1500/2000 Cost: 4.070914\n",
      "Epoch 1600/2000 Cost: 3.890007\n",
      "Epoch 1700/2000 Cost: 3.718528\n",
      "Epoch 1800/2000 Cost: 3.555942\n",
      "Epoch 1900/2000 Cost: 3.401854\n",
      "Epoch 2000/2000 Cost: 3.255734\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 2000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "    # model(x_train)은 model.forward(x_train)와 동일함.\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)  # <== 파이토치에서 제공하는 평균 제곱 오차 함수\n",
    "\n",
    "    # cost로 H(x) 개선하는 부분\n",
    "    # gradient를 0으로 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 비용 함수를 미분하여 gradient 계산\n",
    "    cost.backward()\n",
    "    # W와 b를 업데이트\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        # 100번마다 로그 출력\n",
    "        print(\"Epoch {:4d}/{} Cost: {:.6f}\".format(epoch, nb_epochs, cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HQ5YTf6Txin"
   },
   "source": [
    "### 5-5. 텐서 데이터셋, 데이터 로더로 구현\n",
    "\n",
    " 큰 데이터를 다룰 때, 전체 데이터를 한번에 처리하기는 힘듭니다. 따라서 데이터를 작은 배치로 나누어 처리하는 것이 일반적입니다. PyTorch는 이를 쉽게 구현할 수 있는 도구를 제공합니다\n",
    "\n",
    "\n",
    "*   ` TensorDataset : dataset = TensorDataset(x_train, y_train)`\n",
    "    TensorDataset은 텐서를 입력으로 받아서 데이터셋의 형태로 반환해줍니다. 이 데이터셋은 DataLoader에서 데이터를 배치만큼씩 가져오는 작업을 수행합니\n",
    "\n",
    "*   `DataLoader`는 TensorDataset에서 정의한 데이터셋을 입력받아 배치 크기에 따라 데이터를 반환하는 반복자(iterator)를 제공합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EN7v_ri3ly3Y"
   },
   "outputs": [],
   "source": [
    "# 텐서 데이터셋, 데이터 로더로 구현\n",
    "\n",
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "\n",
    "x_train  =  torch.FloatTensor([[73,  80,  75],\n",
    "                               [93,  88,  93],\n",
    "                               [89,  91,  90],\n",
    "                               [96,  98,  100],\n",
    "                               [73,  66,  70]])\n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])\n",
    "\n",
    "dataset = TensorDataset(x_train, y_train)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qcxdMRrmBC5"
   },
   "outputs": [],
   "source": [
    "model = nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a2EGKhAgmCNg",
    "outputId": "8195be32-440b-43ba-b526-514329ebceb4"
   },
   "outputs": [],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        # print(batch_idx)\n",
    "        # print(samples)\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}\".format(\n",
    "                epoch, nb_epochs, batch_idx + 1, len(dataloader), cost.item()\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0iAKxmwmJhd"
   },
   "source": [
    "### 5-5. 텐서 데이터셋이 아닌 커스텀 데이터 셋\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self):\n",
    "  데이터셋의 전처리를 해주는 부분\n",
    "\n",
    "  def __len__(self):\n",
    "  데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "  데이터셋에서 특정 1개의 샘플을 가져오는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_JMLr3aimDL4"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "# Dataset 상속\n",
    "class CustomDataset(Dataset):\n",
    "  def __init__(self):\n",
    "    self.x_data = [[73, 80, 75],\n",
    "                   [93, 88, 93],\n",
    "                   [89, 91, 90],\n",
    "                   [96, 98, 100],\n",
    "                   [73, 66, 70]]\n",
    "    self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "  # 총 데이터의 개수를 리턴\n",
    "  def __len__(self):\n",
    "    return len(self.x_data)\n",
    "\n",
    "  # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "  def __getitem__(self, idx):\n",
    "    x = torch.FloatTensor(self.x_data[idx])\n",
    "    y = torch.FloatTensor(self.y_data[idx])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZhliXFTmLnl"
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhlK9rXmmPnf"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Linear(3, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GoJpyTZymQZE",
    "outputId": "507c27e1-6506-489d-e2ac-ce115ad5fe43"
   },
   "outputs": [],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "    for batch_idx, samples in enumerate(dataloader):\n",
    "        # print(batch_idx)\n",
    "        # print(samples)\n",
    "        x_train, y_train = samples\n",
    "        # H(x) 계산\n",
    "        prediction = model(x_train)\n",
    "\n",
    "        # cost 계산\n",
    "        cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "        # cost로 H(x) 계산\n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(\n",
    "            \"Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}\".format(\n",
    "                epoch, nb_epochs, batch_idx + 1, len(dataloader), cost.item()\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JD2IkJ19mRhy",
    "outputId": "bba48f54-3288-4eed-f8a4-ef91805e173d"
   },
   "outputs": [],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]])\n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var)\n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
