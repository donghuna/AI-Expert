{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/%ED%95%98%EC%88%9C%ED%9A%8C/Lab4_Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "DOv_qK3oXomk"
      },
      "outputs": [],
      "source": [
        "from typing import List\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "keras.utils.set_random_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model\n",
        "IMAGE_SIZE = 224\n",
        "PATCH_SIZE = 16\n",
        "NUM_PATCHES = (IMAGE_SIZE // PATCH_SIZE) ** 2\n",
        "LAYER_NORM_EPS = 1e-6\n",
        "PROJECTION_DIM = 192\n",
        "NUM_HEADS = 3\n",
        "NUM_LAYERS = 12\n",
        "MLP_UNITS = [\n",
        "    PROJECTION_DIM * 4,\n",
        "    PROJECTION_DIM,\n",
        "]\n",
        "DROPOUT_RATE = 0.0\n",
        "\n",
        "# Training\n",
        "NUM_EPOCHS = 20\n",
        "BASE_LR = 0.001\n",
        "WEIGHT_DECAY = 0.0001\n",
        "\n",
        "# Data\n",
        "BATCH_SIZE = 16\n",
        "AUTO = tf.data.AUTOTUNE\n",
        "NUM_CLASSES = 5"
      ],
      "metadata": {
        "id": "8nd6dC8FXqhZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(is_training=True):\n",
        "    def fn(image, label):\n",
        "        if is_training:\n",
        "            # Resize to a bigger spatial resolution and take the random crops.\n",
        "            image = float(image) / 255.0\n",
        "            image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "            image = tf.image.random_crop(image, (IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "            image = tf.image.random_flip_left_right(image)\n",
        "        else:\n",
        "            image = float(image) / 255.0\n",
        "            image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n",
        "        label = tf.one_hot(label, depth=NUM_CLASSES)\n",
        "        return image, label\n",
        "\n",
        "    return fn\n",
        "\n",
        "\n",
        "def prepare_dataset(dataset, is_training=True):\n",
        "    if is_training:\n",
        "        dataset = dataset.shuffle(BATCH_SIZE * 10)\n",
        "    dataset = dataset.map(preprocess_dataset(is_training), num_parallel_calls=AUTO)\n",
        "    return dataset.batch(BATCH_SIZE).prefetch(AUTO)\n",
        "\n",
        "\n",
        "train_dataset, val_dataset = tfds.load(\n",
        "    \"tf_flowers\", split=[\"train[:90%]\", \"train[90%:]\",], as_supervised=True\n",
        ")\n",
        "num_train = train_dataset.cardinality()\n",
        "num_val = val_dataset.cardinality()\n",
        "\n",
        "print(f\"Number of training examples: {num_train}\")\n",
        "print(f\"Number of validation examples: {num_val}\")\n",
        "\n",
        "\n",
        "train_dataset = prepare_dataset(train_dataset, is_training=True)\n",
        "val_dataset = prepare_dataset(val_dataset, is_training=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvZLZf8wXqZZ",
        "outputId": "348368a9-bfd4-44c5-b833-aa19c7b98e7e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training examples: 3303\n",
            "Number of validation examples: 367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "YTMKcuKdg9zK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, dropout_rate: float, hidden_units: List):\n",
        "    \"\"\"FFN for a Transformer block.\"\"\"\n",
        "    # Iterate over the hidden units and add Dropout.\n",
        "    for (idx, units) in enumerate(hidden_units):\n",
        "        x = layers.Dense(\n",
        "            units,\n",
        "            activation=tf.nn.gelu if idx == 0 else None,\n",
        "        )(x)\n",
        "        x = layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def transformer(name: str) -> keras.Model:\n",
        "    \"\"\"Transformer block with pre-norm.\"\"\"\n",
        "    num_patches = NUM_PATCHES + 2 if \"deit\" in MODEL_TYPE else NUM_PATCHES + 1\n",
        "    encoded_patches = layers.Input((num_patches, PROJECTION_DIM))\n",
        "\n",
        "    # Implement here\n",
        "    # Layer normalization 1 - layers.LayerNormalization(epsilon)\n",
        "    x1 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(encoded_patches)\n",
        "\n",
        "    # Multi Head Self Attention layer - layers.MultiHeadAttention(num_heads, key_dim, dropout)\n",
        "    x2 = layers.MultiHeadAttention(\n",
        "        num_heads=NUM_HEADS,\n",
        "        key_dim=PROJECTION_DIM,\n",
        "        dropout=DROPOUT_RATE,\n",
        "    )(x1, x1)\n",
        "\n",
        "    # Skip connection\n",
        "    # layers.add()\n",
        "    x3 = layers.add([x2, encoded_patches])\n",
        "\n",
        "    # Layer normalization 2\n",
        "    x4 = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)(x3)\n",
        "\n",
        "    # MLP layer 1.\n",
        "    x5 = mlp(\n",
        "        x4,\n",
        "        dropout_rate=DROPOUT_RATE,\n",
        "        hidden_units=MLP_UNITS,\n",
        "    )\n",
        "\n",
        "    # Skip connection 2.\n",
        "    outputs = layers.add([x5, x2])\n",
        "\n",
        "    return keras.Model(encoded_patches, outputs, name=name)\n"
      ],
      "metadata": {
        "id": "8y52yB4jXvpT"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTClassifier(keras.Model):\n",
        "    \"\"\"Vision Transformer base class.\"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        # Patchify + linear projection + reshaping.\n",
        "        self.projection = keras.Sequential(\n",
        "            [\n",
        "                layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
        "                # Implement here\n",
        "                # Hint: Use convolution - What happens if kernel size is equal to stride?\n",
        "                layers.Conv2D(\n",
        "                    filters=PROJECTION_DIM,\n",
        "                    kernel_size=16,\n",
        "                    strides=16,\n",
        "                    padding='valid',\n",
        "                    name='patch_conv'\n",
        "                ),\n",
        "                layers.Reshape((NUM_PATCHES, PROJECTION_DIM)),\n",
        "\n",
        "            ],\n",
        "            name=\"projection\",\n",
        "        )\n",
        "\n",
        "        # Positional embedding.\n",
        "        init_shape = (\n",
        "            1,\n",
        "            NUM_PATCHES + 1,\n",
        "            PROJECTION_DIM,\n",
        "        )\n",
        "        self.positional_embedding = tf.Variable(\n",
        "            tf.zeros(init_shape), name=\"pos_embedding\"\n",
        "        )\n",
        "\n",
        "        # Transformer blocks.\n",
        "        self.transformer_blocks = [\n",
        "            transformer(name=f\"transformer_block_{i}\")\n",
        "            for i in range(NUM_LAYERS)\n",
        "        ]\n",
        "\n",
        "        # CLS token.\n",
        "        initial_value = tf.zeros((1, 1, PROJECTION_DIM))\n",
        "        self.cls_token = tf.Variable(\n",
        "            initial_value=initial_value, trainable=True, name=\"cls\"\n",
        "        )\n",
        "\n",
        "        # Other layers.\n",
        "        self.dropout = layers.Dropout(DROPOUT_RATE)\n",
        "        self.layer_norm = layers.LayerNormalization(epsilon=LAYER_NORM_EPS)\n",
        "        self.head = layers.Dense(\n",
        "            NUM_CLASSES,\n",
        "            name=\"classification_head\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        n = tf.shape(inputs)[0]\n",
        "\n",
        "        # Create patches and project the patches.\n",
        "        projected_patches = self.projection(inputs)\n",
        "\n",
        "        # Append class token if needed.\n",
        "        cls_token = tf.tile(self.cls_token, (n, 1, 1))\n",
        "        cls_token = tf.cast(cls_token, projected_patches.dtype)\n",
        "        projected_patches = tf.concat([cls_token, projected_patches], axis=1)\n",
        "\n",
        "        # Add positional embeddings to the projected patches.\n",
        "\n",
        "        encoded_patches = (\n",
        "            self.positional_embedding + projected_patches\n",
        "        )\n",
        "        encoded_patches = self.dropout(encoded_patches)\n",
        "\n",
        "        # Iterate over the number of layers and stack up blocks of Transformer.\n",
        "        for transformer_module in self.transformer_blocks:\n",
        "            # Add a Transformer block.\n",
        "            encoded_patches = transformer_module(encoded_patches)\n",
        "\n",
        "        # Final layer normalization.\n",
        "        representation = self.layer_norm(encoded_patches)\n",
        "\n",
        "        # Pool representation.\n",
        "        encoded_patches = representation[:, 0]\n",
        "\n",
        "        # Classification head.\n",
        "        output = self.head(encoded_patches)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "zoERTVrcXzGS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_TYPE = \"vit\"\n",
        "vit_model = ViTClassifier()\n",
        "\n",
        "lr_scaled = (BASE_LR / 51200) * BATCH_SIZE\n",
        "vit_model.compile(\n",
        "    optimizer=keras.optimizers.AdamW(lr_scaled, weight_decay=WEIGHT_DECAY),\n",
        "    metrics=[\"accuracy\"],\n",
        "    loss='categorical_crossentropy',\n",
        ")\n",
        "\n",
        "_ = vit_model.fit(train_dataset, validation_data=val_dataset, epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "53xPyD1AX0WC",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d1435d-fc5b-4e89-8ee7-c1f73c4c8914"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "207/207 [==============================] - 100s 168ms/step - loss: 8.4462 - accuracy: 0.2389 - val_loss: 7.9493 - val_accuracy: 0.1962\n",
            "Epoch 2/20\n",
            "207/207 [==============================] - 33s 159ms/step - loss: 7.6303 - accuracy: 0.2455 - val_loss: 9.6256 - val_accuracy: 0.1853\n",
            "Epoch 3/20\n",
            "207/207 [==============================] - 32s 153ms/step - loss: 8.6807 - accuracy: 0.2386 - val_loss: 9.9728 - val_accuracy: 0.1853\n",
            "Epoch 4/20\n",
            "207/207 [==============================] - 32s 152ms/step - loss: 8.8982 - accuracy: 0.2371 - val_loss: 10.1891 - val_accuracy: 0.1853\n",
            "Epoch 5/20\n",
            "207/207 [==============================] - 32s 153ms/step - loss: 9.0407 - accuracy: 0.2371 - val_loss: 10.1363 - val_accuracy: 0.1880\n",
            "Epoch 6/20\n",
            "207/207 [==============================] - 32s 155ms/step - loss: 6.3743 - accuracy: 0.2050 - val_loss: 6.8957 - val_accuracy: 0.2044\n",
            "Epoch 7/20\n",
            "207/207 [==============================] - 32s 152ms/step - loss: 6.0419 - accuracy: 0.2031 - val_loss: 6.7637 - val_accuracy: 0.2016\n",
            "Epoch 8/20\n",
            "207/207 [==============================] - 33s 162ms/step - loss: 6.1051 - accuracy: 0.2044 - val_loss: 6.7636 - val_accuracy: 0.2016\n",
            "Epoch 9/20\n",
            "207/207 [==============================] - 33s 160ms/step - loss: 6.0609 - accuracy: 0.1995 - val_loss: 6.8074 - val_accuracy: 0.2016\n",
            "Epoch 10/20\n",
            "207/207 [==============================] - 33s 160ms/step - loss: 6.0853 - accuracy: 0.2016 - val_loss: 6.7195 - val_accuracy: 0.2098\n",
            "Epoch 11/20\n",
            "207/207 [==============================] - 31s 152ms/step - loss: 6.1438 - accuracy: 0.2059 - val_loss: 6.7195 - val_accuracy: 0.2098\n",
            "Epoch 12/20\n",
            "207/207 [==============================] - 32s 153ms/step - loss: 6.1437 - accuracy: 0.2044 - val_loss: 6.6756 - val_accuracy: 0.2071\n",
            "Epoch 13/20\n",
            "207/207 [==============================] - 32s 152ms/step - loss: 6.1340 - accuracy: 0.2050 - val_loss: 6.6756 - val_accuracy: 0.2098\n",
            "Epoch 14/20\n",
            "207/207 [==============================] - 32s 153ms/step - loss: 6.1291 - accuracy: 0.2047 - val_loss: 6.6756 - val_accuracy: 0.2098\n",
            "Epoch 15/20\n",
            "207/207 [==============================] - 32s 153ms/step - loss: 6.1535 - accuracy: 0.2035 - val_loss: 6.6317 - val_accuracy: 0.2098\n",
            "Epoch 16/20\n",
            "207/207 [==============================] - 33s 159ms/step - loss: 6.1535 - accuracy: 0.2047 - val_loss: 6.6317 - val_accuracy: 0.2098\n",
            "Epoch 17/20\n",
            "207/207 [==============================] - 33s 160ms/step - loss: 6.1486 - accuracy: 0.2047 - val_loss: 6.6317 - val_accuracy: 0.2098\n",
            "Epoch 18/20\n",
            "207/207 [==============================] - 32s 152ms/step - loss: 6.1584 - accuracy: 0.2038 - val_loss: 6.6317 - val_accuracy: 0.2098\n",
            "Epoch 19/20\n",
            "207/207 [==============================] - 32s 153ms/step - loss: 6.1535 - accuracy: 0.2044 - val_loss: 6.6317 - val_accuracy: 0.2098\n",
            "Epoch 20/20\n",
            "207/207 [==============================] - 33s 160ms/step - loss: 6.1779 - accuracy: 0.2050 - val_loss: 6.6317 - val_accuracy: 0.2098\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = vit_model.evaluate(val_dataset)"
      ],
      "metadata": {
        "id": "bsIafBK84dC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8af383d-0550-45b7-ea4a-39606b2b0b3a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23/23 [==============================] - 1s 59ms/step - loss: 8.6689 - accuracy: 0.1417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ViTDistilled(ViTClassifier):\n",
        "    def __init__(self, regular_training=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.num_tokens = 2\n",
        "        self.regular_training = regular_training\n",
        "\n",
        "        # CLS and distillation tokens, positional embedding.\n",
        "        init_value = tf.zeros((1, 1, PROJECTION_DIM))\n",
        "        self.dist_token = tf.Variable(init_value, name=\"dist_token\")\n",
        "        self.positional_embedding = tf.Variable(\n",
        "            tf.zeros(\n",
        "                (\n",
        "                    1,\n",
        "                    NUM_PATCHES + self.num_tokens,\n",
        "                    PROJECTION_DIM,\n",
        "                )\n",
        "            ),\n",
        "            name=\"pos_embedding\",\n",
        "        )\n",
        "\n",
        "        # Head layers.\n",
        "        self.head = layers.Dense(\n",
        "            NUM_CLASSES,\n",
        "            name=\"classification_head\",\n",
        "        )\n",
        "        self.head_dist = layers.Dense(\n",
        "            NUM_CLASSES,\n",
        "            name=\"distillation_head\",\n",
        "        )\n",
        "\n",
        "    def call(self, inputs, training=True):\n",
        "        n = tf.shape(inputs)[0]\n",
        "\n",
        "        # Create patches and project the patches.\n",
        "        projected_patches = self.projection(inputs)\n",
        "\n",
        "        # Append the tokens.\n",
        "        cls_token = tf.tile(self.cls_token, (n, 1, 1))\n",
        "        dist_token = tf.tile(self.dist_token, (n, 1, 1))\n",
        "        cls_token = tf.cast(cls_token, projected_patches.dtype)\n",
        "        dist_token = tf.cast(dist_token, projected_patches.dtype)\n",
        "        projected_patches = tf.concat(\n",
        "            [cls_token, dist_token, projected_patches], axis=1\n",
        "        )\n",
        "\n",
        "        # Add positional embeddings to the projected patches.\n",
        "        encoded_patches = (\n",
        "            self.positional_embedding + projected_patches\n",
        "        )\n",
        "        encoded_patches = self.dropout(encoded_patches)\n",
        "\n",
        "        # Iterate over the number of layers and stack up blocks of Transformer.\n",
        "        for transformer_module in self.transformer_blocks:\n",
        "            # Add a Transformer block.\n",
        "            encoded_patches = transformer_module(encoded_patches)\n",
        "\n",
        "        # Final layer normalization.\n",
        "        representation = self.layer_norm(encoded_patches)\n",
        "\n",
        "        # Classification heads.\n",
        "        x, x_dist = (\n",
        "            self.head(representation[:, 0]),\n",
        "            self.head_dist(representation[:, 1]),\n",
        "        )\n",
        "\n",
        "        if not training or self.regular_training:\n",
        "            # During standard train / finetune, inference average the classifier predictions.\n",
        "            return (x + x_dist) / 2\n",
        "\n",
        "        elif training:\n",
        "            # Only return separate classification predictions when training in distilled mode.\n",
        "            return x, x_dist\n"
      ],
      "metadata": {
        "id": "jEuMXc_diEg7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DeiT(keras.Model):\n",
        "    # References:\n",
        "    # https://keras.io/examples/vision/knowledge_distillation/\n",
        "    # https://keras.io/examples/keras_recipes/trainer_pattern/\n",
        "    def __init__(self, student, teacher, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.student = student\n",
        "        self.teacher = teacher\n",
        "\n",
        "        self.student_loss_tracker = keras.metrics.Mean(name=\"student_loss\")\n",
        "        self.dist_loss_tracker = keras.metrics.Mean(name=\"distillation_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        metrics = super().metrics\n",
        "        metrics.append(self.student_loss_tracker)\n",
        "        metrics.append(self.dist_loss_tracker)\n",
        "        return metrics\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "    ):\n",
        "        super().compile(optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack data.\n",
        "        x, y = data\n",
        "\n",
        "        # Implement here\n",
        "        # Forward pass of teacher\n",
        "        # tf.nn.softmax()\n",
        "        # tf.argmax() - Hard label\n",
        "        teacher_predictions = tf.nn.softmax(self.teacher(x, training=False), axis=-1)\n",
        "        teacher_predictions = tf.argmax(teacher_predictions, axis=-1)\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass of student.\n",
        "            cls_predictions, dist_predictions = self.student(x, training=True)\n",
        "\n",
        "            # Compute losses - Mean of student loss and distillation loss(Hard label distillation)\n",
        "            student_loss = self.student_loss_fn(y, cls_predictions)\n",
        "            distillation_loss = self.distillation_loss_fn(teacher_predictions, dist_predictions)\n",
        "            loss = (student_loss + distillation_loss) / 2\n",
        "\n",
        "        # Compute gradients.\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights.\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`.\n",
        "        student_predictions = (cls_predictions + dist_predictions) / 2\n",
        "        self.compiled_metrics.update_state(y, student_predictions)\n",
        "        self.dist_loss_tracker.update_state(distillation_loss)\n",
        "        self.student_loss_tracker.update_state(student_loss)\n",
        "\n",
        "        # Return a dict of performance.\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        return results\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data.\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions.\n",
        "        y_prediction = self.student(x, training=False)\n",
        "\n",
        "        # Calculate the loss.\n",
        "        student_loss = self.student_loss_fn(y, y_prediction)\n",
        "\n",
        "        # Update the metrics.\n",
        "        self.compiled_metrics.update_state(y, y_prediction)\n",
        "        self.student_loss_tracker.update_state(student_loss)\n",
        "\n",
        "        # Return a dict of performance.\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "        return results\n",
        "\n",
        "    def call(self, inputs):\n",
        "        return self.student(inputs, training=False)\n"
      ],
      "metadata": {
        "id": "02LZ7HS2iFxH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://github.com/sayakpaul/deit-tf/releases/download/v0.1.0/bit_teacher_flowers.zip\n",
        "!unzip -q bit_teacher_flowers.zip\n"
      ],
      "metadata": {
        "id": "bO5LTq2SiafY"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_TYPE = \"deit\"\n",
        "bit_teacher_flowers = keras.models.load_model(\"bit_teacher_flowers\")\n",
        "\n",
        "deit_tiny = ViTDistilled()\n",
        "deit_distiller = DeiT(student=deit_tiny, teacher=bit_teacher_flowers)\n",
        "\n",
        "BASE_LR = 0.1\n",
        "\n",
        "lr_scaled = (BASE_LR / 512) * BATCH_SIZE\n",
        "deit_distiller.compile(\n",
        "    optimizer=keras.optimizers.AdamW(weight_decay=WEIGHT_DECAY, learning_rate=lr_scaled),\n",
        "    metrics=[\"accuracy\"],\n",
        "    student_loss_fn=keras.losses.CategoricalCrossentropy(\n",
        "        from_logits=True, label_smoothing=0.1\n",
        "    ),\n",
        "    distillation_loss_fn=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "_ = deit_distiller.fit(train_dataset, validation_data=val_dataset, epochs=NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "ZYw0SNbGieYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7372eb28-78f5-4c9a-8aff-b0ddaaad4f30"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "207/207 [==============================] - 184s 664ms/step - accuracy: 0.2486 - student_loss: 1.7799 - distillation_loss: 0.6960 - val_accuracy: 0.1907 - val_student_loss: 2.6807 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 2/20\n",
            "207/207 [==============================] - 134s 650ms/step - accuracy: 0.2507 - student_loss: 1.6677 - distillation_loss: 0.5245 - val_accuracy: 0.1907 - val_student_loss: 2.6955 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 3/20\n",
            "207/207 [==============================] - 133s 645ms/step - accuracy: 0.2507 - student_loss: 1.6613 - distillation_loss: 0.5074 - val_accuracy: 0.1907 - val_student_loss: 2.8114 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 4/20\n",
            "207/207 [==============================] - 134s 650ms/step - accuracy: 0.2507 - student_loss: 1.6451 - distillation_loss: 0.4955 - val_accuracy: 0.1907 - val_student_loss: 2.8981 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 5/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6363 - distillation_loss: 0.5027 - val_accuracy: 0.1907 - val_student_loss: 2.6908 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 6/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6290 - distillation_loss: 0.4821 - val_accuracy: 0.1907 - val_student_loss: 2.8218 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 7/20\n",
            "207/207 [==============================] - 134s 645ms/step - accuracy: 0.2507 - student_loss: 1.6282 - distillation_loss: 0.5002 - val_accuracy: 0.1907 - val_student_loss: 2.7267 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 8/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6227 - distillation_loss: 0.4896 - val_accuracy: 0.1907 - val_student_loss: 2.7731 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 9/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6153 - distillation_loss: 0.4833 - val_accuracy: 0.1907 - val_student_loss: 2.8195 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 10/20\n",
            "207/207 [==============================] - 133s 645ms/step - accuracy: 0.2507 - student_loss: 1.6193 - distillation_loss: 0.4864 - val_accuracy: 0.1907 - val_student_loss: 2.7342 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 11/20\n",
            "207/207 [==============================] - 133s 645ms/step - accuracy: 0.2507 - student_loss: 1.6106 - distillation_loss: 0.4997 - val_accuracy: 0.1907 - val_student_loss: 2.6459 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 12/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6106 - distillation_loss: 0.4939 - val_accuracy: 0.1907 - val_student_loss: 2.5713 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 13/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6105 - distillation_loss: 0.4925 - val_accuracy: 0.1907 - val_student_loss: 2.7377 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 14/20\n",
            "207/207 [==============================] - 135s 650ms/step - accuracy: 0.2507 - student_loss: 1.6081 - distillation_loss: 0.4812 - val_accuracy: 0.1907 - val_student_loss: 2.7520 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 15/20\n",
            "207/207 [==============================] - 133s 645ms/step - accuracy: 0.2507 - student_loss: 1.6075 - distillation_loss: 0.4815 - val_accuracy: 0.1907 - val_student_loss: 2.8536 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 16/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6094 - distillation_loss: 0.4859 - val_accuracy: 0.1907 - val_student_loss: 2.8018 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 17/20\n",
            "207/207 [==============================] - 134s 645ms/step - accuracy: 0.2507 - student_loss: 1.6071 - distillation_loss: 0.4951 - val_accuracy: 0.1907 - val_student_loss: 2.7935 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 18/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6059 - distillation_loss: 0.4679 - val_accuracy: 0.1907 - val_student_loss: 2.7801 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 19/20\n",
            "207/207 [==============================] - 133s 644ms/step - accuracy: 0.2507 - student_loss: 1.6047 - distillation_loss: 0.4889 - val_accuracy: 0.1907 - val_student_loss: 2.7474 - val_distillation_loss: 0.0000e+00\n",
            "Epoch 20/20\n",
            "207/207 [==============================] - 135s 650ms/step - accuracy: 0.2507 - student_loss: 1.6056 - distillation_loss: 0.4886 - val_accuracy: 0.1907 - val_student_loss: 2.9421 - val_distillation_loss: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_ = deit_distiller.evaluate(val_dataset)"
      ],
      "metadata": {
        "id": "eE1nEzqU4d_7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}