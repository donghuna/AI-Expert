{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/donghuna/AI-Expert/blob/main/%ED%99%A9%EC%98%81%EC%88%99/%5B%EA%B3%BC%EC%A0%9C%5D%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90_AI_Expert_LangChainAgents_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.1.0\n",
        "!pip install langchain-openai==0.0.2\n",
        "!pip install langchainhub==0.1.14 # langchain python라이브러리로 프롬프트, 에이전트, 체인 관련 패키지 모음\n",
        "!pip install langserve[all]==0.0.39\n",
        "\n",
        "!pip install faiss-cpu==1.7.4  # Facebook에서 개발 및 배포한 밀집 벡터의 유사도 측정, 클러스터링에 효율적인 라이브러리\n",
        "!pip install tavily-python==0.1.9 # 언어 모델에 중립적인 디자인으로, 모든 LLM과 통합이 가능하도록 설계된 검색 API\n",
        "!pip install beautifulsoup4==4.12.2  #파이썬에서 사용할 수 있는 웹데이터 크롤링 라이브러리\n",
        "!pip install wikipedia\n",
        "\n",
        "!pip install fastapi==0.109.0 #  Python의 API를 빌드하기 위한 웹 프레임워크\n",
        "!pip install uvicorn==0.23.2 # ASGI(Asynchronous Server Gateway Interface) 서버\n",
        "!pip install urllib3==2.1.0 # 파이썬에서 HTTP 요청을 보내고 받는 데 사용되는 강력하고 유연한 라이브러리\n",
        "\n",
        "!pip install python-dotenv\n",
        "!pip install pypdf\n",
        "!pip install transformers nltk\n",
        "!pip install langchain transformers"
      ],
      "metadata": {
        "id": "F_vgpBVH3g06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG4jKxckH1_c"
      },
      "outputs": [],
      "source": [
        "# !pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tavily Search 를 사용하기 위해서는 API KEY를 발급 받아 등록해야 함.\n",
        "\n",
        "[Tavily Search API 발급받기](https://app.tavily.com/sign-in)\n",
        "\n",
        "발급 받은 API KEY 를 다음과 같이 환경변수에 등록"
      ],
      "metadata": {
        "id": "jXEvb3WyJMcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "# TAVILY API KEY를 기입합니다.\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "\n",
        "# 디버깅을 위한 프로젝트명을 기입합니다.\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"AGENT TUTORIAL\""
      ],
      "metadata": {
        "id": "RIxxUDEZI6ZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPEN-AI_KEY')"
      ],
      "metadata": {
        "id": "ys24Z3bfJHUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# API KEY를 환경변수로 관리하기 위한 설정 파일\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# API KEY 정보로드\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "sEii2SHNJbAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "search.invoke 함수는 주어진 문자열에 대한 검색을 실행\n",
        "\n",
        "invoke() 함수에 검색하고 싶은 검색어를 넣어 검색을 수행"
      ],
      "metadata": {
        "id": "sWR_5-ANKJt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TavilySearchResults 클래스를 langchain_community.tools.tavily_search 모듈에서 가져옵니다.\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
        "# k=5은 검색 결과를 5개까지 가져오겠다는 의미입니다\n",
        "search = TavilySearchResults(k=5)"
      ],
      "metadata": {
        "id": "1hKlxX7cJ8tP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색 결과를 가져옵니다.\n",
        "search.invoke(\"판교 카카오 프렌즈샵 아지트점의 전화번호는 무엇인가요?\")"
      ],
      "metadata": {
        "id": "2KnGx9mSKQ8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#PDF 기반 문서 검색 도구: Retriever\n",
        "\n",
        "내부 데이터에 대해 조회를 수행할 retriever 생성.\n",
        "\n",
        "*   웹 기반 문서 로더, 문서 분할기, 벡터 저장소, 그리고 OpenAI 임베딩을 사용하여 문서 검색 시스템을 구축\n",
        "*   PDF 문서를 FAISS DB 에 저장하고 조회하는 retriever 를 생성\n",
        "\n"
      ],
      "metadata": {
        "id": "5mHSqB3_Kvf3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# PDF 파일 로드. 파일의 경로 입력\n",
        "loader = PyPDFLoader(\"SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
        "\n",
        "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "\n",
        "# 문서를 로드하고 분할합니다.\n",
        "split_docs = loader.load_and_split(text_splitter)\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "private_key = userdata.get('OPEN-AI_KEY') # Your own secret key\n",
        "organization_id = \"org-CsaDwJgaYH1LgSRXtOwVARVC\" # SKI-ML Organization ID\n",
        "project_id = \"proj_OjWVsuIR4h3Yf6fmzDNXCp4H\" # Samsung AI_Expert project ID\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=private_key, organization=organization_id)\n",
        "\n",
        "# VectorStore를 생성합니다.\n",
        "vector = FAISS.from_documents(split_docs, embeddings)\n",
        "\n",
        "# Retriever를 생성합니다.\n",
        "retriever = vector.as_retriever()"
      ],
      "metadata": {
        "id": "hnw_piOXK40_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "retriever 객체의 get_relevant_documents 메소드를 사용"
      ],
      "metadata": {
        "id": "3pklmrBUMez_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PDf 문서에서 Query 에 대한 관련성 높은 Chunk 를 가져옵니다.\n",
        "retriever.get_relevant_documents(\n",
        "    \"YouTube의 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 알려줘\"\n",
        ")[0]"
      ],
      "metadata": {
        "id": "2qhkeX8tMNT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create_retriever_tool 함수\n",
        "- langchain 라이브러리의 tools.retriever 모듈에서 가져온다.\n",
        "\n",
        "- 이 함수는 특정 데이터를 검색하기 위한 도구를 생성하는 데 사용된다.\n",
        "\n",
        "- langchain은 언어 모델과 관련된 다양한 기능을 제공하는 라이브러리로, 이 중 검색 도구 생성 기능은 데이터 검색 및 처리 작업을 용이하게 한다."
      ],
      "metadata": {
        "id": "F6vRGZRVMupo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성하는 함수를 가져옵니다.\n",
        "from langchain.tools.retriever import create_retriever_tool"
      ],
      "metadata": {
        "id": "4excfbIjMiCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_tool = create_retriever_tool(\n",
        "    retriever,  # base retriever\n",
        "    name=\"pdf_search\",  # retriever name\n",
        "    description=\"2023년 12월 AI 관련 정보를 PDF 문서에서 검색합니다. '2023년 12월 AI 산업동향' 과 관련된 질문은 이 도구를 사용해야 합니다!\",\n",
        ")"
      ],
      "metadata": {
        "id": "I1KkwVBWMxL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agent 가 사용할 도구 목록 정의\n",
        "\n",
        "Agent 가 사용할 도구 목록을 리스트 형식으로 만든다.\n",
        "\n",
        "tools 리스트는 search와 retriever_tool을 포함합니다.\n",
        "\n",
        "이 리스트는 검색 및 정보 검색 도구를 저장하는 데 사용됩니다.\n",
        "\n",
        "각 요소는 특정 작업을 수행하는 데 필요한 기능을 제공합니다."
      ],
      "metadata": {
        "id": "gRVXMqfzM6i3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
        "tools = [search, retriever_tool]"
      ],
      "metadata": {
        "id": "O2yOheWIM_lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 에이전트 생성\n",
        "\n",
        "도구를 정의했으니 에이전트를 생성\n",
        "\n",
        "OpenAI-Functions-Agent를 사용할 것임.\n",
        "\n",
        "먼저, 에이전트가 활용할 LLM을 정의.\n",
        "\n",
        "ChatOpenAI 클래스는 langchain_openai 모듈에서 가져온 것으로, OpenAI의 언어 모델을 활용하여 대화형 AI를 구현이 가능\n",
        "\n"
      ],
      "metadata": {
        "id": "4Ez0vILVND5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# ChatOpenAI 클래스를 langchain_openai 모듈에서 가져옵니다.\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0, organization=organization_id)"
      ],
      "metadata": {
        "id": "aNLsTBscNMVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "\n",
        "# hub에서 prompt를 가져옵니다 - 이 부분을 수정할 수 있습니다!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "# prompt 의 messages를 출력합니다.\n",
        "prompt.messages"
      ],
      "metadata": {
        "id": "MHTTQeuaNTzn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " LLM, 프롬프트 및 도구로 에이전트를 초기화\n",
        "\n",
        "에이전트는 입력을 받아 어떤 Action 을 취할지 결정하는 역할을 수행하고 Action 들을 실행하는 것은 AgentExecutor(다음 단계)에 의해 수행"
      ],
      "metadata": {
        "id": "cIOlNAWbNrQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import create_openai_functions_agent\n",
        "\n",
        "# OpenAI 함수 기반 에이전트를 생성합니다.\n",
        "# llm, tools, prompt를 인자로 사용합니다.\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)"
      ],
      "metadata": {
        "id": "z0YdzBcdNZ2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "에이전트(agent)를 AgentExecutor 내부의 도구들과 결합(이는 반복적으로 에이전트를 호출하고 도구들을 실행할 것임).\n",
        "\n",
        "이 코드는 langchain.agents 모듈에서 AgentExecutor 클래스를 가져와 인스턴스를 생성.\n",
        "\n",
        "생성 시, agent, tools 객체를 인자로 전달하고, verbose=True를 설정하여 상세한 로그 출력을 활성화.\n",
        "\n",
        "AgentExecutor는 주어진 에이전트와 도구들을 사용하여 작업을 실행하는 역할 수행."
      ],
      "metadata": {
        "id": "9X9NDlR4OKcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "\n",
        "# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ],
      "metadata": {
        "id": "F1vIKINiNghp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 에이전트 실행하기\n",
        "\n",
        "agent_executor 객체의 invoke 메소드는 딕셔너리 형태의 인자를 받아 처리\n",
        "."
      ],
      "metadata": {
        "id": "VNNcBTkvOiv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'agent_executor' 객체의 'invoke' 메소드를 호출하여,\n",
        "# 'input' 키와 '안녕, 반가워' 값을 가진 딕셔너리를 인자로 전달합니다.\n",
        "response = agent_executor.invoke({\"input\": \"2024년 아시안컵 대한민국의 축구 경기 결과를 알려줘.\"})\n",
        "print(f'답변: {response[\"output\"]}')"
      ],
      "metadata": {
        "id": "hpwKhsuuOfdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QTkbkYKrQ0j3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KWDn12KkQ1s-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'agent_executor' 객체의 'invoke' 메소드를 호출하여, 'langsmith'가 테스팅에 어떻게 도움을 줄 수 있는지에 대한 질문을 입력으로 제공합니다.\n",
        "response = agent_executor.invoke(\n",
        "    {\n",
        "        \"input\": \"YouTube 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 PDF 문서에서 알려줘\"\n",
        "    }\n",
        ")\n",
        "print(f'답변: {response[\"output\"]}')"
      ],
      "metadata": {
        "id": "pSpc6Mi3O_WG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검색 결과를 요청 후 질문에 대한 답변을 출력합니다.\n",
        "response = agent_executor.invoke(\n",
        "    {\"input\": \"판교 카카오 프렌즈샵 아지트점의 전화번호를 검색하여 결과를 알려주세요.\"}\n",
        ")\n",
        "print(f'답변: {response[\"output\"]}')"
      ],
      "metadata": {
        "id": "qnuBp7uiPGlf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "llm = ChatOpenAI(temperature=0,  # 창의성 0으로 설정\n",
        "                 model_name='gpt-4',  # 모델명\n",
        "                 organization=organization_id\n",
        "                )\n",
        "\n",
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm) #llm-math의 경우 나이 계산을 위해 사용\n",
        "agent = initialize_agent(tools,\n",
        "                         llm,\n",
        "                         agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "                         description='위키피이아에서 정보를 검색하고 계산이 필요할 때 사용',\n",
        "                         verbose=True)\n",
        "\n",
        "\n",
        "agent.run(\"gpt-4o는 언제 출시되었어?\")\n",
        "\n",
        "#agent.run(\"에드 시런이 태어난 해는? 2024년도 현재 에드 시런은 몇 살?\")"
      ],
      "metadata": {
        "id": "ikzcw9pQQ2rY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 모듈 import\n",
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, TokenTextSplitter\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader, DirectoryLoader\n",
        "from langchain.tools.retriever import create_retriever_tool\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain import hub\n",
        "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from transformers import AutoTokenizer\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from transformers import GPT2TokenizerFast\n",
        "\n",
        "# TAVILY API KEY를 기입합니다.\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get('TAVILY_API_KEY')\n",
        "private_key = userdata.get('OPEN-AI_KEY') # Your own secret key\n",
        "organization_id = \"org-CsaDwJgaYH1LgSRXtOwVARVC\" # SKI-ML Organization ID\n",
        "project_id = \"proj_OjWVsuIR4h3Yf6fmzDNXCp4H\" # Samsung AI_Expert project ID\n",
        "\n",
        "########## 1. 도구를 정의합니다 ##########\n",
        "\n",
        "### 1-1. Search 도구 ###\n",
        "# TavilySearchResults 클래스의 인스턴스를 생성합니다\n",
        "# k=5은 검색 결과를 5개까지 가져오겠다는 의미입니다\n",
        "search = TavilySearchResults(k=5)\n",
        "\n",
        "### 1-2. PDF 문서 검색 도구 (Retriever) ###\n",
        "# PDF 파일 로드. 파일의 경로 입력\n",
        "# loader = PyPDFLoader(\"data/SPRI_AI_Brief_2023년12월호_F.pdf\")\n",
        "loader = PyPDFDirectoryLoader('./data')\n",
        "\n",
        "model_name = \"gpt-3.5-turbo\" #openai-community/gpt2\"\n",
        "# tokenizer = GPT2TokenizerFast.from_pretrained(model_name)\n",
        "\n",
        "# 텍스트 분할기를 사용하여 문서를 분할합니다.\n",
        "text_splitter = TokenTextSplitter(\n",
        "    chunk_size=50,\n",
        "    chunk_overlap=5\n",
        ")\n",
        "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "\n",
        "# 문서를 로드하고 분할합니다.\n",
        "split_docs = loader.load_and_split(text_splitter)\n",
        "\n",
        "# VectorStore를 생성합니다.\n",
        "embeddings = OpenAIEmbeddings(organization=organization_id)\n",
        "vector = FAISS.from_documents(split_docs, embeddings)\n",
        "\n",
        "# Retriever를 생성합니다.\n",
        "base_retriever = vector.as_retriever(\n",
        "    search_type='similarity_score_threshold',\n",
        "    search_kwargs={'score_threshold': 0.08}\n",
        ")\n",
        "\n",
        "multi_query_retriever = MultiQueryRetriever.from_llm(\n",
        "    retriever=base_retriever,\n",
        "    llm=ChatOpenAI(model=model_name, temperature=0.4, organization=organization_id, max_tokens=500)\n",
        ")\n",
        "\n",
        "# langchain 패키지의 tools 모듈에서 retriever 도구를 생성\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=multi_query_retriever\n",
        ")\n",
        "\n",
        "retriever_tool = create_retriever_tool(\n",
        "    compression_retriever,\n",
        "    name=\"pdf_search\",\n",
        "    # 도구에 대한 설명을 자세히 기입해야 합니다!!!\n",
        "    description=\"2023년 12월 AI 관련 정보를 PDF 문서에서 검색합니다. '2023년 12월 AI 산업동향' 과 관련된 질문은 이 도구를 사용해야 합니다!\",\n",
        ")\n",
        "\n",
        "### 1-3. tools 리스트에 도구 목록을 추가합니다 ###\n",
        "# tools 리스트에 search와 retriever_tool을 추가합니다.\n",
        "tools = [search, retriever_tool]\n",
        "\n",
        "########## 2. LLM 을 정의합니다 ##########\n",
        "# LLM 모델을 생성합니다.\n",
        "llm = ChatOpenAI(model=model_name, temperature=0, organization=organization_id)\n",
        "\n",
        "########## 3. Prompt 를 정의합니다 ##########\n",
        "\n",
        "# hub에서 prompt를 가져옵니다 - 이 부분을 수정할 수 있습니다!\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "########## 4. Agent 를 정의합니다 ##########\n",
        "\n",
        "# OpenAI 함수 기반 에이전트를 생성합니다.\n",
        "# llm, tools, prompt를 인자로 사용합니다.\n",
        "agent = create_openai_functions_agent(llm, tools, prompt)\n",
        "\n",
        "########## 5. AgentExecutor 를 정의합니다 ##########\n",
        "\n",
        "# AgentExecutor 클래스를 사용하여 agent와 tools를 설정하고, 상세한 로그를 출력하도록 verbose를 True로 설정합니다.\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
        "\n",
        "########## 6. 채팅 기록을 수행하는 메모리를 추가합니다. ##########\n",
        "\n",
        "# 채팅 메시지 기록을 관리하는 객체를 생성합니다.\n",
        "message_history = ChatMessageHistory()\n",
        "\n",
        "# 채팅 메시지 기록이 추가된 에이전트를 생성합니다.\n",
        "agent_with_chat_history = RunnableWithMessageHistory(\n",
        "    agent_executor,\n",
        "    # 대부분의 실제 시나리오에서 세션 ID가 필요하기 때문에 이것이 필요합니다\n",
        "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
        "    lambda session_id: message_history,\n",
        "    # 프롬프트의 질문이 입력되는 key: \"input\"\n",
        "    input_messages_key=\"input\",\n",
        "    # 프롬프트의 메시지가 입력되는 key: \"chat_history\"\n",
        "    history_messages_key=\"chat_history\",\n",
        ")\n",
        "\n",
        "########## 7. 질의-응답 테스트를 수행합니다. ##########\n",
        "\n",
        "# 질의에 대한 답변을 출력합니다.\n",
        "response = agent_with_chat_history.invoke(\n",
        "    {\n",
        "        \"input\": \"YouTube 2024년부터 AI 생성콘텐츠 표시 의무화에 대한 내용을 PDF 문서에서 알려줘\"\n",
        "    },\n",
        "    # 세션 ID를 설정합니다.\n",
        "    # 여기서는 간단한 메모리 내 ChatMessageHistory를 사용하기 때문에 실제로 사용되지 않습니다\n",
        "    config={\"configurable\": {\"session_id\": \"MyTestSessionID\"}},\n",
        ")\n",
        "print(f\"답변: {response['output']}\")"
      ],
      "metadata": {
        "id": "D11RNrzXRZ9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_GGfwBxV54lB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}